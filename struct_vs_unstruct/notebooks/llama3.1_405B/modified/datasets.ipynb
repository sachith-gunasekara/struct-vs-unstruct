{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b148d55-5cf1-4ef7-af91-b8ed41830f49",
   "metadata": {},
   "source": [
    "# T4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf294b2b-662b-4a97-9d6a-ad87dc77103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from pyprojroot import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f23bd86-8df9-44cc-aa0b-07a988362db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/non_self_synthesis/t4d/t4d-/t4d_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ccc62e2-c4a5-45db-abd1-98180e91b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8982579-5e58-48ff-9c65-5518b29c7520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['story', 'question', 'answer', 'characters', 'distracting_characters', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 564\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb574f09-b7c9-40e0-8b8f-2fed10d409fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A and B, but since the options do not allow for multiple answers, the most appropriate answer would be to choose one of the individuals who would benefit from receiving helpful information.',\n",
       " 'A and B, however, the options do not provide a way to select both A and B. Given the instructions to select one answer, the best answer would be to acknowledge that the format does not allow for the correct answer to be provided as per the instructions. However, following the instructions to the letter as requested:',\n",
       " \"A and C, but since the format requires a single answer, the most relevant answer is A (as Emily's needs are more specific and related to the banana and corn).\",\n",
       " 'A and C, however, the options do not allow for the selection of multiple answers. Given the instructions to select one answer, I will choose one of the correct answers.',\n",
       " 'A and C.',\n",
       " 'A,C.',\n",
       " 'Abigail',\n",
       " 'Aiden',\n",
       " 'Alexander',\n",
       " 'Amelia',\n",
       " 'Aria',\n",
       " 'Ava',\n",
       " 'Avery',\n",
       " 'B and A, however, the options provided do not allow for the selection of multiple answers. Given the instructions to choose one answer, it is not possible to accurately answer the question as it is presented.',\n",
       " 'B, C.',\n",
       " 'B, but since both Ella and Evelyn would benefit, and there is no option for \"both A and B\", the most accurate answer choice is not explicitly provided. However, following the format, I will select one of the individuals:',\n",
       " 'Benjamin',\n",
       " \"C, but the conclusion also suggests A would benefit. However, the question format requires a single choice. Given the equal relevance of A and C, and the format restrictions, the response is adapted to fit, acknowledging this does not fully capture the analysis's nuance.\",\n",
       " 'Carter',\n",
       " 'Charlotte',\n",
       " 'Chloe',\n",
       " 'Elizabeth',\n",
       " 'Ella',\n",
       " 'Emily',\n",
       " 'Emma',\n",
       " 'Ethan',\n",
       " 'Evelyn',\n",
       " 'Hannah',\n",
       " 'Hunter',\n",
       " 'Isabella',\n",
       " 'Isla',\n",
       " 'Jack',\n",
       " 'Jackson',\n",
       " 'Jacob',\n",
       " 'James',\n",
       " 'Jayden',\n",
       " 'Liam',\n",
       " 'Lily',\n",
       " 'Logan',\n",
       " 'Lucas',\n",
       " 'Mason',\n",
       " 'Mia',\n",
       " 'Mila',\n",
       " 'Nathan',\n",
       " 'Noah',\n",
       " 'None of the above',\n",
       " 'Oliver',\n",
       " 'Olivia',\n",
       " 'Owen',\n",
       " 'Sophia',\n",
       " 'William'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34608422-61a2-4d28-946d-3fbbce2bd0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_choice_text(text, choice_letter):\n",
    "    # Define the pattern to match the choice letter followed by a dot and space\n",
    "    pattern = rf\"{choice_letter}\\.\\s(.*?)(?=\\n|$)\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def map_fn(instance):\n",
    "    answer_pred = str(instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", \".\")))\n",
    "    if len(answer_pred) == 1:\n",
    "        answer = extract_choice_text(instance[\"question\"], answer_pred)\n",
    "    else:\n",
    "        print(instance[\"answer_pred\"])\n",
    "        answer = instance[\"answer_pred\"]\n",
    "        if not answer:\n",
    "            print(\"+++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "    return {\"answer_pred\": answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c668d46-3948-4368-a8d4-acfb928d51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daa94ed9-9e63-434f-9845-ec6b94f6528a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362335222550479e8f6889abb3a61642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(here(\"struct_vs_unstruct/data/modified/non_self_synthesis/t4d/t4d-/t4d_eval\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89058d8c-0190-4439-acc0-e264b015e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "t4d = lambda instance, y, y_pred: instance[y] in instance[y_pred] and instance[y] == instance[y_pred]\n",
    "bbh = lambda instance, y, y_pred: instance[y_pred] and instance[y].translate(str.maketrans(\"\", \"\", \"()\")) == instance[y_pred].translate(str.maketrans(\"\", \"\", \".()\"))\n",
    "\n",
    "\n",
    "def calculate_accuracy(full_dataset, benchmark, y: str, y_pred: str, log_file_path: str):\n",
    "    correct_preds = 0\n",
    "    for instance in tqdm(full_dataset, desc=\"Calculating accuracy\"):\n",
    "        if benchmark == \"t4d\":\n",
    "            eval_fn = t4d\n",
    "        elif benchmark == \"bbh\":\n",
    "            eval_fn = bbh\n",
    "\n",
    "        if eval_fn(instance, y, y_pred):\n",
    "            correct_preds += 1\n",
    "        else:\n",
    "            with open(log_file_path, \"a\") as f:\n",
    "                f.write(f\"{instance[y]}, {instance[y_pred]}\\n\")\n",
    "    return correct_preds / len(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3bd5aaf-601a-4710-8f2c-e89972c1f59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating accuracy: 100%|██████████| 564/564 [00:00<00:00, 6976.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7464539007092199"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(dataset, \"t4d\", \"answer\", \"answer_pred\", here(\"struct_vs_unstruct/logs/modified/non_self_synthesis/evals/t4d/t4d-/t4d_different.txt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
