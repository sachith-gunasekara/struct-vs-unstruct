{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a4202b42-fcb2-4057-ba20-4b900b985a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from pyprojroot import here\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "5ea8e6aa-2bbe-443f-a0e5-b2763527b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/refined/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad382360-c910-4008-9e29-ed54d2af6a60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# boolean_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8e97125a-4717-448e-bb9c-e60b55801a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-boolean_expressions/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "40d8dd0a-6202-4900-9a23-f015a60d4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3c089c61-3627-4b28-876b-4c3bd8a0f3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False', 'True'}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "88f60d5b-30f8-4fa0-b307-bed3b745d4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa1cad649b446a98bb18e20008534f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):\n",
    "    if \"False,\" in instance[\"answer_pred\"]:\n",
    "        return {\"answer_pred\": \"False\"}\n",
    "    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.()\"\"'))\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2855ae0f-99fd-4bbd-9c64-98fcb2d08074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False', 'True'}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a6a3d527-55b5-4e0b-a6d7-d533e21cd37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3966b265eb34fe39f64df067c10da52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "114b9f87-0886-473c-9fb5-cf454767657e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6510422b97224d6bb81fd444776a3323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.976"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f896b20a-b9ca-4770-8d0b-b37c9a472974",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# causal_judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "60f0dec8-135d-4ec6-b413-321e122d6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-causal_judgement/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "82137aca-da0f-4847-b1f2-4f6fdf0cd8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "4bfd0f92-5704-4319-8f03-e00261008556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No', 'Yes'}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "439b7206-fc8e-43de-b27e-572446271feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "33f84785-4a8a-41ac-aad1-c75307a7ba2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8b7a037ca949848c86922c250555cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "cbfb58bd-ebd8-4754-80a4-7370bf3b8c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b494f554c14f10a844432f49c536e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7165775401069518"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56710f05-faca-4518-b318-54739646e5d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# date_understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "71df491e-6a9a-424b-a3ad-6418d59e6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-date_understanding/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "021c7135-b8b8-4d77-a787-0c37e9df3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6ab4ee2a-1ae6-41be-8e71-9e40d4d9ab57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(B)',\n",
       " '(D)',\n",
       " '01/02/1962',\n",
       " '03/31/1985',\n",
       " '06/19/2018',\n",
       " '07/10/1972',\n",
       " '10/22/2001',\n",
       " '11/13/2019',\n",
       " '11/22/2001',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " None}"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "bf1e8c96-39e6-449f-827d-4b3d8c93355b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05d6c056f364e269d13abf334f9027b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "41cf17a6-0769-48f7-9594-d7e0e4bb3ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01/02/1962',\n",
       " '03/31/1985',\n",
       " '06/19/2018',\n",
       " '07/10/1972',\n",
       " '10/22/2001',\n",
       " '11/13/2019',\n",
       " '11/22/2001',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " None}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "be5b7d7f-15a8-41ee-9963-08c455421829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae92f7e170b49b6bd6531385c06fc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8731798-91af-4f87-aa9c-e75f8aac9dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_none = new_ds.filter(lambda x: x[\"answer_pred\"] == None)\n",
    "ds_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e42df60-418f-400e-bbce-b27654f3ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A)\n",
      "06/19/2018\n",
      "Jane thinks today is 6/18/2019, but John thinks today is 6/19/2019. John is correct. What is the date one year ago from today in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 06/19/2018\n",
      "(B) 05/22/2018\n",
      "(C) 06/19/1934\n",
      "(D) 06/19/1956\n",
      "(E) 06/24/2018\n",
      "(F) 06/18/2018\n",
      "==================================================\n",
      "(F)\n",
      "10/22/2001\n",
      "In the US, Thanksgiving is on the fourth Thursday of November. Today is the US Thanksgiving of 2001. What is the date a month ago in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 11/22/2001\n",
      "(B) 10/21/2002\n",
      "(C) 07/21/2002\n",
      "(D) 10/22/1923\n",
      "(E) 10/15/2002\n",
      "(F) 10/22/2002\n",
      "==================================================\n",
      "(B)\n",
      "11/13/2019\n",
      "Tomorrow is 11/12/2019. What is the date tomorrow in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 02/12/2020\n",
      "(B) 11/12/2019\n",
      "(C) 10/22/2019\n",
      "(D) 11/14/2019\n",
      "(E) 12/10/2019\n",
      "==================================================\n",
      "(D)\n",
      "11/22/2001\n",
      "In the US, Thanksgiving is on the fourth Thursday of November. Today is the US Thanksgiving of 2001. What is the date today in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 01/16/2003\n",
      "(B) 11/21/2002\n",
      "(C) 09/04/2002\n",
      "(D) 11/22/2002\n",
      "(E) 08/24/2002\n",
      "(F) 11/23/2002\n",
      "==================================================\n",
      "(D)\n",
      "07/10/1972\n",
      "Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date tomorrow in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 07/09/1923\n",
      "(B) 08/05/1972\n",
      "(C) 09/01/1972\n",
      "(D) 07/09/1972\n",
      "(E) 07/09/2007\n",
      "(F) 09/04/1972\n",
      "==================================================\n",
      "(B)\n",
      "01/02/1962\n",
      "Jane and John married on Jan 2, 1958. It is their 5-year anniversary today. What is the date one year ago from today in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 06/02/1960\n",
      "(B) 01/02/1960\n",
      "(C) 01/02/1967\n",
      "(D) 12/19/1959\n",
      "(E) 12/26/1959\n",
      "(F) 01/02/2016\n",
      "==================================================\n",
      "(F)\n",
      "03/31/1985\n",
      "Today is Apr 10, 1985. Jane's appointment will be 3 days later. What is the date 10 days ago in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 04/13/1985\n",
      "(B) 04/07/1985\n",
      "(C) 05/13/1985\n",
      "(D) 04/10/1986\n",
      "(E) 03/10/1986\n",
      "(F) 03/31/1985\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for inst in new_ds:\n",
    "    if inst[\"answer_pred\"] and len(inst[\"answer_pred\"]) != 1:\n",
    "        print(inst[\"target\"])\n",
    "        print(inst[\"answer_pred\"])\n",
    "        print(inst[\"input\"])\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "710a4930-1b3b-4713-ba53-a90851d9cd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy', 0.896)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 2\n",
    "\n",
    "for instance in new_ds:\n",
    "    if instance[\"answer_pred\"] == instance[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')):\n",
    "        total += 1\n",
    "\n",
    "\"Accuracy\", total / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a71e015-96fc-4387-841d-d0232bd7bbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(F)\n",
      "**Step 1: Determine the current date**\n",
      "The current date is December 30, 2014, since 2015 is coming in 36 hours.\n",
      "\n",
      "**Step 2: Break down the problem into smaller parts**\n",
      "We need to calculate the date a month ago from the current date, considering the month, day, and year.\n",
      "\n",
      "**Step 3: Calculate the date a month ago**\n",
      "Subtracting one month from December results in November.\n",
      "\n",
      "**Step 4: Adjust for the correct day**\n",
      "Since we are subtracting a month, we need to consider the number of days in November. November has 30 days, and since the current day is the 30th, the day a month ago would be the same, which is the 30th. However, since November only has 30 days, the correct day would be the last day of November that exists, which is the 30th. But we need to consider the day before the last day of the month that has 30 days, which is the 29th and then the 30th, which is the last day, does not exist in November that has only 30 days, so the last day is the 30th. However, the 30th of November exists, so the correct day is the 30th. However, the 30th of November is the last day of November, so a month before the last day of December is the last day of November that has 30 days, which is the 30th. However, this is not the case, the correct day is the 30th. However, this is the case, so the correct day is the 30th. However, November has 30 days, so the correct day is the 30th. However, the correct day is the day that is one day before the last day of the month, November. So the last day of November is the 30th, so one day before that is the 29th and then the 30th, which is the last day, the 30th is the last day of November, so one day before that is the 29th, so the correct day is the 30th. However, the correct day is the 30th. However, the correct day is the 30th. However, the correct day is the 30th. However, the correct day is the 30th. However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th and then the last day of the month is the 30th, which is not the correct day, the correct day is the 30th. However, the 30th is the last day of November, so the correct day is the 30th. However, the correct day is the 30th. However, the correct day is the 30th. However, the correct day is the day that is one day before the last day of the month, November. However, the correct day is the 30th. However, the correct day is the 30th. However, the correct day is the 30th. However, the correct day is the 30th. However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th. \n",
      "However, the last day of November is the 30th, so the correct day is the 30th.\n",
      "However, the 30th is the last day of November, so one day before that is the 29th, so the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the last day of November is the 30th, so the correct day is the 30th.\n",
      "However, the 30th is the last day of November, so one day before that is the 29th, so the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the last day of November is the 30th, so the correct day is the 30th.\n",
      "However, the 30th is the last day of November, so one day before that is the 29th, so the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the last day of November is the 30th, so the correct day is the 30th.\n",
      "However, the 30th is the last day of November, so one day before that is the 29th, so the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the last day of November is the 30th, so the correct day is the 30th.\n",
      "However, the 30th is the last day of November, so one day before that is the 29th, so the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the last day of November is the 30th, so the correct day is the 30th.\n",
      "However, the 30th is the last day of November, so one day before that is the 29th, so the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the last day of November is the 30th, so the correct day is the 30th.\n",
      "However, the 30th is the last day of November, so one day before that is the 29th, so the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the last day of November is the 30th, so the correct day is the 30th.\n",
      "However, the 30th is the last day of November, so one day before that is the 29th, so the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the last day of November is the 30th, so the correct day is the 30th.\n",
      "However, the 30th is the last day of November, so one day before that is the 29th, so the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of the month, November.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the day that is one day before the last day of November, so the correct day is the 29th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However, the correct day is the 30th.\n",
      "However\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "for ins in ds_none:\n",
    "    print(ins[\"target\"])\n",
    "    print(ins[\"trajectory\"])\n",
    "    print(\"============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42902384-b596-4280-9966-8fa9e0e11ae6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# disambiguation_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "3b529475-dada-4c81-9a3e-909b3eb864fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-disambiguation_qa/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "f940e07e-333e-4f07-9438-d2a158fa225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "21133bee-e7ac-4fa4-9c26-bf7a9d011447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(A)', '(B)', '(C)', 'A', 'B', 'C'}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "71ac8e8b-1d12-43d8-a23e-afd10f410619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea61d753a72c449c8403d020613fa136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "3724e230-574d-407c-8b07-cded9deb91ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C'}"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "eb753e29-f807-4d8a-8c0a-e75815c76732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b0f91b11e2421d8bdd6a8fd4047ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "63437ecc-16d7-48c9-b34e-53e9f05211d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f8492466924aa29ef9ba59f9f9c5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.732"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9db11f-2eca-4d16-8507-7bd9ed72282a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# dyck_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "658d2bab-9a0b-4026-860d-065c45489f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-dyck_languages/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "4d1bee9a-1738-4772-8848-846a0d0a0e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c6464-86e2-436f-8ed5-9d68c8bbeb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_ds = new_ds.filter(lambda x: x[\"answer_pred\"] == None)\n",
    "for instance in new_ds:\n",
    "    print(instance[\"target\"])\n",
    "    print(instance[\"trajectory\"])\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "1788ddad-0936-4172-8897-0239ef89cb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ea71964c7d4bfd98f706db2aa47d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "0e76de13-bdd1-457a-b194-a39f114512bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 3\n",
       "})"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = dataset.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99ec3d74-5d2e-4d00-b3a6-8bc2625da103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887ffae8-8423-4dc0-8fbe-4731bb38186c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# formal_fallacies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "50da91f3-6deb-47c3-bccc-f19203134e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-formal_fallacies/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "a65b8587-c387-430c-8f87-4b7c42c65efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "6773264b-4bf0-4787-ae71-c0efc0704693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'invalid', 'valid'}"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e70edee-d4c7-4110-8cb5-cd969414fc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'valid'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "00ae60ee-647a-4513-9660-fcecd654ff60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ededbc6889f47629efd4e1c3d8d204b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "50ffb33c-716f-440c-a116-c4bda9fafc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.772"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = dataset.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e488a9-5e7a-4ecd-b74b-ee26d852b43b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# geometric_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "8a5775a3-0f0a-424e-a737-b086e62f4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-geometric_shapes/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "e18c74b9-fb2e-4fcc-823e-76c55207597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "bc25565e-8bcb-423f-8d28-174ef3b1d389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(D)',\n",
       " '(D).',\n",
       " '(G).',\n",
       " 'A',\n",
       " 'A.',\n",
       " 'B',\n",
       " 'B.',\n",
       " 'C',\n",
       " 'C.',\n",
       " 'D',\n",
       " 'D.',\n",
       " 'E',\n",
       " 'E.',\n",
       " 'F',\n",
       " 'F.',\n",
       " 'G',\n",
       " 'G.',\n",
       " 'H',\n",
       " 'H.',\n",
       " 'I',\n",
       " 'I.',\n",
       " 'J',\n",
       " 'J.',\n",
       " 'K',\n",
       " 'K.',\n",
       " 'confirmed based on the analysis and comparison.',\n",
       " 'one of the given options, specifically option E.'}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b15078a8-d3c9-4670-b994-634351da72bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa33c2500c04495b00848d0d7718c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "e20a9ea7-bd1b-474c-8b92-be9bdad0f407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'confirmed based on the analysis and comparison',\n",
       " 'one of the given options specifically option E'}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "c1025058-d680-4967-a6cc-e701ec8cdf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8adb51581ff4ecca83b199ccb8af0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5fa31b0a-81c3-4a4b-847a-80b573d97eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759289c28a654e8bb7de8d63c329f12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 162\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f7bfa59-4f6a-41ec-9576-a8de5a881907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaefe78-ecbb-49ae-bd58-e000c8208c1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# hyperbaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "c97fe7eb-7986-459a-85bf-0e9e367a3722",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-hyperbaton/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "70035db6-c28e-4992-ad04-fc46c35ad8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "3c3bbb74-3ad1-461c-9bd2-3cacc2987799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(A)', '(A).', '(B).', 'A', 'A.', 'B.'}"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "126ef57d-498d-4b30-9fe2-b55b3166bc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c13b361f57b4df38be97d4ef131727c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "1a4b6dbb-94f7-41ac-beba-b861305a247f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B'}"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "1a961021-7c00-427d-986d-becf7483f61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2bef12bac7491e9e90249d29b31cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "77943f6b-0ef4-472b-8c75-164566e33273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca5484c2d6147758de1f9df07c0ba3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 240\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc2a84-f816-4975-b85d-f4a505c99639",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# logical_deduction_five_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "92d8f5eb-fa8f-47e8-abfa-dcc9962684eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-logical_deduction_five_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c8eacea9-4afc-4783-907d-74397b343553",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "6cfe632f-200c-4cc2-adc4-767b6406854a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(B).',\n",
       " '(D).',\n",
       " 'A.',\n",
       " 'B.',\n",
       " 'C.',\n",
       " 'D.',\n",
       " 'E is not correct, and A and C are both possible but the task requires one answer. In this case, A is one of the two possible answers.',\n",
       " 'E.'}"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "6ea098a1-449b-416c-801b-6ed0e49a219e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59fa277040945a298a6f7fd019495aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "11b1f5dd-937c-4c45-b123-1ceac1875924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'E is not correct and A and C are both possible but the task requires one answer In this case A is one of the two possible answers'}"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "236bf5d3-3274-4079-a628-c7afdc1147fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f547ffe5873423dacbf80d23232aed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf1bcc92-9f2e-4776-add6-e27e8e989d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7117246885b4821b1a23fcce4d18193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 227\n",
       "})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9708558-9ae6-456a-8eeb-a75f02196488",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# logical_deduction_seven_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "997292c0-b202-456f-ac2e-e612811c85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-logical_deduction_seven_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "4e15206b-92e9-4cb9-beca-58323222878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "9e5aa80f-ed32-45e4-957a-86b4ff6dc784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(A)',\n",
       " '(A).',\n",
       " '(D)',\n",
       " 'A.',\n",
       " 'B.',\n",
       " 'C',\n",
       " 'C.',\n",
       " 'D.',\n",
       " 'E.',\n",
       " 'F.',\n",
       " 'G.',\n",
       " 'the option that states Eve finished third.'}"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "9deaa30c-78f4-460b-aa3a-470e8b532ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed43d7f3194b441194ee511bcd7adba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "39f489b1-b835-47a2-8a2b-283005686943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'the option that states Eve finished third'}"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "5d093697-e4db-42dd-9b68-ae8c0a81714b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. In a golf tournament, there were seven golfers: Eve, Mya, Rob, Ana, Ada, Mel, and Joe. Eve finished third. Mya finished above Joe. Mel finished above Ada. Mya finished above Rob. Mel finished below Joe. Mya finished second. Ada finished second-to-last.\n",
      "Options:\n",
      "(A) Eve finished third\n",
      "(B) Mya finished third\n",
      "(C) Rob finished third\n",
      "(D) Ana finished third\n",
      "(E) Ada finished third\n",
      "(F) Mel finished third\n",
      "(G) Joe finished third\n"
     ]
    }
   ],
   "source": [
    "print(new_ds.filter(lambda x: \"the option that states\" in x[\"answer_pred\"])[0][\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "201ec158-72dd-49fe-858b-583bc1fb891f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798ae3dc8a52480aafe460b90d808c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    if \"the option that states\" in ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"A\"\n",
    "        }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "02602709-3ffe-4bef-a549-284c542cc0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', 'F', 'G'}"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "76c822f9-ef98-43d1-a596-bb6726c73b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfcbd1e215c478292c56ec1ea9c81a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "992a8366-d61d-4ac0-8e3f-54bdbabdab2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e0c24184e541fdbfd3ef6c1d74aa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.796"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370486d6-7f38-46aa-b0b3-e5798814d52b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# logical_deduction_three_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "7bf413e5-5770-45ab-9ead-6b65f923108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-logical_deduction_three_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "346e76a0-e786-42dc-a7a1-7d91a38ec15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "68cabef5-5430-4b70-83c5-59b57fad40b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(C).', 'A.', 'B.', 'C.'}"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "9cf7d264-b1df-4fb1-af32-d66fa18c3b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da051e557d984959977982aa432ebd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "e4ee7782-3046-4cb4-a1a6-4171573d57b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C'}"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "6d290a33-769a-493f-9958-e97ff1774339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c29e924cbf4bf7ad9a34e535545412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "cceb7f9c-8633-4dee-9291-a669c14c1f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1915237-bce3-4e3b-b051-8d5eb37f9d01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# movie_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "d1974cb6-ad5a-4797-b836-5107b4b39e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-movie_recommendation/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "c621e330-d571-40ed-8276-5aed2ca64e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "772615e1-2fba-4dfb-9f90-e1551714abdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A.', 'B.', 'C.', 'D.', 'E.', 'None of the above.', 'The Godfather.'}"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a09a7372-c6cc-4b27-8e5d-f02bd646f95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d9d06e26394783944034bcc9423100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "b8cddf57-5603-40d4-a8bb-b9db3d7f7104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', 'None of the above', 'The Godfather'}"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9ca30b67-e251-4c75-bfc1-85c852d42050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0110ee1792647dea32b9ba54a9598c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 166\n",
       "})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "35111e17-02b5-4e73-8c5a-644b2bb1ad08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08799767d7954fe6b4c592c07b3dd48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "462ba582-198e-4dee-b286-2a879c64e15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"Find a movie similar to Goodfellas, Raiders of the Lost Ark, Star Wars Episode IV - A New Hope, The Silence of the Lambs:\\nOptions:\\n(A) Monty Python and the Holy Grail\\n(B) Weekend at Bernie's\\n(C) American in Paris\\n(D) An\\n(E) Let It Snow\",\n",
       " 'target': '(A)',\n",
       " 'selected_modules': 'Here are the selected modules:\\n\\n1. What are the key assumptions underlying this problem?\\n4. How can I simplify the problem so that it is easier to solve?\\n7. What are the alternative perspectives or viewpoints on this problem?\\n10. Critical Thinking: This style involves analyzing the problem from different perspectives, questioning assumptions, and evaluating the evidence or information available.\\n16. What is the core issue or problem that needs to be addressed?\\n17. What are the underlying causes or factors contributing to the problem?\\n25. Is the problem a technical or practical one that requires a specific expertise or skill set? Or is it more of a conceptual or theoretical problem?\\n30. Is the problem a design challenge that requires creative solutions and innovation?\\n34. Given the problem specification and the current best solution, have a guess about other possible solutions.\\n35. Lets imagine the current best solution is totally wrong, what other ways are there to think about the problem specification?',\n",
       " 'adapted_modules': \"Here is the list of adapted module descriptions:\\n\\n1. What are the key themes, genres, or elements that make Goodfellas, Raiders of the Lost Ark, Star Wars Episode IV - A New Hope, and The Silence of the Lambs similar, and how can I use these to find a similar movie?\\n4. How can I break down the characteristics of these four movies into simpler categories, such as action, adventure, crime, or comedy, to make it easier to find a match?\\n7. What would a fan of sci-fi, adventure, crime, and thriller movies recommend as a similar film, and what would a critic or a film expert suggest?\\n10. Critical Thinking: Analyze the plots, characters, and styles of the four given movies, question assumptions about what makes them similar, and evaluate the evidence for each option being a good match.\\n16. What is the core element that ties these four movies together, and how can I use this to identify a similar film?\\n17. What underlying factors, such as directorial style, era, or cultural context, contribute to the similarities between these movies, and how can I use these to find a match?\\n25. Is the task of finding a similar movie a matter of identifying specific technical or practical elements, such as special effects or cinematography, or is it more about finding a match in terms of tone, themes, or genre?\\n30. Is the task of finding a similar movie a design challenge that requires creative thinking and innovation, or can I rely on established patterns and conventions?\\n34. Given the characteristics of the four movies, what other possible solutions or matches can I think of, even if they're not immediately obvious?\\n35. Let's imagine that the obvious similarities between the four movies are misleading, and what other ways can I think about the problem to find a match that's not immediately apparent?\",\n",
       " 'reasoning_plan': 'Here is a step-by-step reasoning plan to find a movie similar to Goodfellas, Raiders of the Lost Ark, Star Wars Episode IV - A New Hope, and The Silence of the Lambs:\\n\\n**Step 1: Identify Key Themes and Genres**\\n\\n* Analyze the four given movies to identify common themes, genres, or elements that make them similar.\\n* Consider the characteristics of each movie, such as action, adventure, crime, thriller, and sci-fi.\\n* Create a list of key themes and genres that are present in at least two of the four movies.\\n\\n**Step 2: Break Down Characteristics into Simpler Categories**\\n\\n* Take the list of key themes and genres from Step 1 and break them down into simpler categories.\\n* For example, group \"action\" and \"adventure\" together, or separate \"crime\" into \"gangster\" and \"thriller\".\\n* Create a new list of simplified categories that can be used to compare the movies.\\n\\n**Step 3: Analyze Plots, Characters, and Styles**\\n\\n* Analyze the plots, characters, and styles of the four given movies.\\n* Identify common patterns or elements that are present in at least two of the four movies.\\n* Consider the tone, pacing, and overall feel of each movie.\\n\\n**Step 4: Identify Core Elements and Underlying Factors**\\n\\n* Identify the core element that ties the four movies together.\\n* Consider underlying factors such as directorial style, era, or cultural context that contribute to the similarities between the movies.\\n* Create a list of core elements and underlying factors that can be used to find a similar movie.\\n\\n**Step 5: Evaluate Options**\\n\\n* Take the list of simplified categories, core elements, and underlying factors from previous steps and evaluate each option (A-E).\\n* Compare each option to the list of characteristics, themes, and genres identified in Steps 1-4.\\n* Identify which options match the most characteristics, themes, and genres.\\n\\n**Step 6: Consider Alternative Solutions**\\n\\n* Think of alternative solutions or matches that may not be immediately obvious.\\n* Consider what other movies might fit the characteristics, themes, and genres identified in Steps 1-4.\\n* Add any new options to the list of potential matches.\\n\\n**Step 7: Final Evaluation**\\n\\n* Evaluate all options, including any new ones identified in Step 6.\\n* Compare each option to the list of characteristics, themes, and genres identified in Steps 1-4.\\n* Identify the option that best matches the characteristics, themes, and genres of the four given movies.\\n\\nThis plan provides a step-by-step approach to analyzing the characteristics, themes, and genres of the four given movies and evaluating options to find a similar movie. By following this plan, an AI agent can derive a solution to the given task.',\n",
       " 'reasoning': \"**Step 1: Identify Key Themes and Genres**\\n\\nAnalyzing the four given movies, we can identify common themes and genres such as:\\n\\n* Action and adventure (Raiders of the Lost Ark, Star Wars Episode IV - A New Hope)\\n* Crime and thriller (Goodfellas, The Silence of the Lambs)\\n* Coming-of-age and self-discovery (Star Wars Episode IV - A New Hope, Goodfellas)\\n* Iconic villains and heroes (Raiders of the Lost Ark, Star Wars Episode IV - A New Hope, The Silence of the Lambs)\\n\\n**Step 2: Break Down Characteristics into Simpler Categories**\\n\\nBreaking down the list of key themes and genres, we can simplify them into categories such as:\\n\\n* Action/Adventure\\n* Crime/Thriller\\n* Coming-of-age/Self-discovery\\n* Iconic Villains/Heroes\\n\\n**Step 3: Analyze Plots, Characters, and Styles**\\n\\nAnalyzing the plots, characters, and styles of the four given movies, we can identify common patterns such as:\\n\\n* Epic journeys and quests (Raiders of the Lost Ark, Star Wars Episode IV - A New Hope)\\n* Complex moralities and gray areas (Goodfellas, The Silence of the Lambs)\\n* Memorable characters and dialogue (all four movies)\\n\\n**Step 4: Identify Core Elements and Underlying Factors**\\n\\nIdentifying the core element that ties the four movies together, we can consider underlying factors such as:\\n\\n* Directorial style: Martin Scorsese's gritty realism, Steven Spielberg's sense of wonder, and George Lucas's epic scope\\n* Era: All four movies were released between the 1970s and 1990s, a time of great change and innovation in filmmaking\\n* Cultural context: The movies reflect and comment on the societal issues of their time, such as crime, morality, and personal identity\\n\\n**Step 5: Evaluate Options**\\n\\nEvaluating each option (A-E), we can compare them to the list of characteristics, themes, and genres identified in Steps 1-4. None of the options seem to match all of the characteristics, but some come closer than others.\\n\\n**Step 6: Consider Alternative Solutions**\\n\\nConsidering alternative solutions, we might think of movies that fit the characteristics, themes, and genres identified in Steps 1-4. Some possible alternatives could be:\\n\\n* The Godfather (crime, coming-of-age, iconic villains/heroes)\\n* Jaws (action/adventure, thriller, iconic villains/heroes)\\n* The Matrix (action/adventure, sci-fi, iconic villains/heroes)\\n\\n**Step 7: Final Evaluation**\\n\\nEvaluating all options, including the new ones identified in Step 6, we can compare each option to the list of characteristics, themes, and genres identified in Steps 1-4. While none of the original options (A-E) seem to match perfectly, The Godfather comes closest to matching the characteristics, themes, and genres of the four given movies.\\n\\nThe final answer is The Godfather.\",\n",
       " 'trajectory': \"**Step 1: Identify Key Themes and Genres**\\n\\nAnalyzing the four given movies, we can identify common themes and genres such as:\\n\\n* Action and adventure (Raiders of the Lost Ark, Star Wars Episode IV - A New Hope)\\n* Crime and thriller (Goodfellas, The Silence of the Lambs)\\n* Coming-of-age and self-discovery (Star Wars Episode IV - A New Hope, Goodfellas)\\n* Iconic villains and heroes (Raiders of the Lost Ark, Star Wars Episode IV - A New Hope, The Silence of the Lambs)\\n\\n**Step 2: Break Down Characteristics into Simpler Categories**\\n\\nBreaking down the list of key themes and genres, we can simplify them into categories such as:\\n\\n* Action/Adventure\\n* Crime/Thriller\\n* Coming-of-age/Self-discovery\\n* Iconic Villains/Heroes\\n\\n**Step 3: Analyze Plots, Characters, and Styles**\\n\\nAnalyzing the plots, characters, and styles of the four given movies, we can identify common patterns such as:\\n\\n* Epic journeys and quests (Raiders of the Lost Ark, Star Wars Episode IV - A New Hope)\\n* Complex moralities and gray areas (Goodfellas, The Silence of the Lambs)\\n* Memorable characters and dialogue (all four movies)\\n\\n**Step 4: Identify Core Elements and Underlying Factors**\\n\\nIdentifying the core element that ties the four movies together, we can consider underlying factors such as:\\n\\n* Directorial style: Martin Scorsese's gritty realism, Steven Spielberg's sense of wonder, and George Lucas's epic scope\\n* Era: All four movies were released between the 1970s and 1990s, a time of great change and innovation in filmmaking\\n* Cultural context: The movies reflect and comment on the societal issues of their time, such as crime, morality, and personal identity\\n\\n**Step 5: Evaluate Options**\\n\\nEvaluating each option (A-E), we can compare them to the list of characteristics, themes, and genres identified in Steps 1-4. None of the options seem to match all of the characteristics, but some come closer than others.\\n\\n**Step 6: Consider Alternative Solutions**\\n\\nConsidering alternative solutions, we might think of movies that fit the characteristics, themes, and genres identified in Steps 1-4. Some possible alternatives could be:\\n\\n* The Godfather (crime, coming-of-age, iconic villains/heroes)\\n* Jaws (action/adventure, thriller, iconic villains/heroes)\\n* The Matrix (action/adventure, sci-fi, iconic villains/heroes)\\n\\n**Step 7: Final Evaluation**\\n\\nEvaluating all options, including the new ones identified in Step 6, we can compare each option to the list of characteristics, themes, and genres identified in Steps 1-4. While none of the original options (A-E) seem to match perfectly, The Godfather comes closest to matching the characteristics, themes, and genres of the four given movies.\",\n",
       " 'answer_pred': 'The Godfather'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds.filter(lambda x: len(x[\"answer_pred\"].split()) == 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "78eec496-4a53-4147-9281-aecd3dda05ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.664"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a3d5b0-4ba3-4989-b506-b7597bb4a044",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# penguins_in_a_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "57f52b5b-7902-4b5b-ad11-0b5f811a9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-penguins_in_a_table/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "44adbace-ace5-4f21-80da-332aed7b9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "b4282681-d060-4001-8e70-24deba130b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(A)',\n",
       " '(A).',\n",
       " '(C).',\n",
       " '(D)',\n",
       " '(D).',\n",
       " '(E)',\n",
       " 'A.',\n",
       " 'B.',\n",
       " 'C.',\n",
       " 'D.',\n",
       " 'E.',\n",
       " 'the option that corresponds to the counted number of matches, which is option (D) 4.',\n",
       " 'the option that matches the count, which is (B) 2.'}"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "e7fa4f24-8807-4281-bad9-72f191f989c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d112342deef4647905074e0afe209b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "8e62cf66-fb1e-4c9b-876e-b75a76e0362b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'the option that corresponds to the counted number of matches which is option D 4',\n",
       " 'the option that matches the count which is B 2'}"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "59c42bee-abcf-4073-961b-4ab07c51f42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b5dbce6dd94acf88663fde134d17d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    if \"the option that corresponds to\" in ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"D\"\n",
    "        }\n",
    "\n",
    "    if \"the option that matches the\" in ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"B\"\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6d772-1dfd-4ceb-9c47-019a5ab35992",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "25523da8-b16b-4fe3-9f44-4ddc790254bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fda53af6a6c4dbe83b8549ad4254485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "ac13448a-24a5-4b7e-8dae-ed94377f0423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9709e3494d741298919b3dabfdec1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9931506849315068"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9937f8fa-d824-4cb8-b481-0bd2d77a48ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# reasoning_about_colored_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "e55f9164-86ac-4fc2-b4c1-29533aed1d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-reasoning_about_colored_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "8bcb5714-3da8-45b1-9466-97ed241a1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "e54c6db2-efcb-4408-8d48-6b29c1af6526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(A) red.',\n",
       " '(B)',\n",
       " '(B) or (E). However, since the question asks for a single answer, we must realize that the question does not provide enough information to uniquely determine the position of the grey pen. But, looking at the options, we can see that the only two possible colors mentioned in the options that are also mentioned in the problem are blue and orange. In this case, we should choose one of the two possible correct answers.',\n",
       " '(B).',\n",
       " '(C).',\n",
       " '(D) three.',\n",
       " '(D).',\n",
       " '(E) four.',\n",
       " '(E).',\n",
       " '(F).',\n",
       " '(H).',\n",
       " '(I) mauve.',\n",
       " '(K)',\n",
       " '(M).',\n",
       " '(N)',\n",
       " '(O).',\n",
       " '(Q).',\n",
       " '(R).',\n",
       " 'A.',\n",
       " 'B.',\n",
       " 'C.',\n",
       " 'D.',\n",
       " 'E.',\n",
       " 'F.',\n",
       " 'G.',\n",
       " 'H.',\n",
       " 'I.',\n",
       " 'J.',\n",
       " 'K.',\n",
       " 'L.',\n",
       " 'M.',\n",
       " 'N.',\n",
       " 'O.',\n",
       " 'P.',\n",
       " 'Q.',\n",
       " 'R.',\n",
       " 'the number of yellow items remaining on the floor after removing all the plates, which is 2.'}"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "da9c53df-cffb-4621-9b14-dc4a737976e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37803373fed841f68f832d12e0816185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "2156f24c-f985-442c-8e9d-a896918707c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cf6d77711548bdb7f7949d13bc30f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):\n",
    "    sp = instance[\"answer_pred\"].split()\n",
    "    if len(sp) == 2:\n",
    "        return {\"answer_pred\": sp[0]}\n",
    "    else:\n",
    "        return {\"answer_pred\": instance[\"answer_pred\"]}\n",
    "\n",
    "new_ds = new_ds.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "823c20c7-8e6c-45a5-ba19-d303d0de3e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'B',\n",
       " 'B or E However since the question asks for a single answer we must realize that the question does not provide enough information to uniquely determine the position of the grey pen But looking at the options we can see that the only two possible colors mentioned in the options that are also mentioned in the problem are blue and orange In this case we should choose one of the two possible correct answers',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'the number of yellow items remaining on the floor after removing all the plates which is 2'}"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "4b3cdbbf-2485-47a4-8aaf-2316e663a517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b0e235df664be6bf9fbc0472d3cd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the floor, you see one yellow plate, three turquoise plates, three turquoise textbooks, two yellow textbooks, one burgundy plate, and three burgundy textbooks. If I remove all the plates from the floor, how many yellow items remain on it?\n",
      "Options:\n",
      "(A) zero\n",
      "(B) one\n",
      "(C) two\n",
      "(D) three\n",
      "(E) four\n",
      "(F) five\n",
      "(G) six\n",
      "(H) seven\n",
      "(I) eight\n",
      "(J) nine\n",
      "(K) ten\n",
      "(L) eleven\n",
      "(M) twelve\n",
      "(N) thirteen\n",
      "(O) fourteen\n",
      "(P) fifteen\n",
      "(Q) sixteen\n",
      "(C)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    if \"the number of yellow items remaining\" in ins[\"answer_pred\"]:\n",
    "        print(ins[\"input\"])\n",
    "        print(ins[\"target\"])\n",
    "\n",
    "new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "59c788bf-8041-4232-ae2d-9c2b07190969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a371c2ec3f240fb964c2cb8a65bb875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    if \"the number of yellow items remaining\" in ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"C\"\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "9f9a7051-162a-486c-8f7c-0eabb0089190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'B',\n",
       " 'B or E However since the question asks for a single answer we must realize that the question does not provide enough information to uniquely determine the position of the grey pen But looking at the options we can see that the only two possible colors mentioned in the options that are also mentioned in the problem are blue and orange In this case we should choose one of the two possible correct answers',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R'}"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "a8ff6956-b339-41b4-becc-2d7f5ee8a57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733f0261fa0d4be48223e035a86d3876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f97d1566-5301-4cca-8efb-6a6f08bdbde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6fcc74-c395-43c6-8c09-940bff3b1131",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ruin_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "7b52871f-2a9d-4268-89da-6deb12298804",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-ruin_names/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "b72f42b2-e3d4-404d-a45b-21ab4bab322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "8246fc05-e88f-45b4-981b-b43b96439c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A.', 'B.', 'C.', 'D.', 'I.'}"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "041d6c47-64f4-4557-90c1-e4643ed58fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402689351ac84dde9a8ddad0567e8b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "edc7c0e4-ba59-4bcc-8b79-9dd682ecf0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'I'}"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "23db1ea8-6e4f-4b8b-924f-8064096912b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabc232c9fdc467d826a24d021dbeb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "fd27c209-a594-4843-b808-2260c0c4a13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92b0fbd-276d-4f2d-a882-eb30f1142b0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# salient_translation_error_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "06cb1a67-554a-4685-a866-c2e0c126887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-salient_translation_error_detection/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "9e7bbce3-9d87-4002-9c7c-7aecf05d4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ee1fc40e-bb0d-4b64-ae70-2b38836f9dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(A)',\n",
       " '(A).',\n",
       " '(B)',\n",
       " '(B).',\n",
       " '(D)',\n",
       " '(D).',\n",
       " '(F)',\n",
       " 'A.',\n",
       " 'B.',\n",
       " 'C.',\n",
       " 'D.',\n",
       " 'E.',\n",
       " 'F.'}"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "4d27472c-77b5-4af4-b635-e8069aed21e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a411ea78bae422ba1056b6cf9a18b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "cea10474-8ecc-483f-ba70-30b3685ac95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', 'F'}"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "23f7cbb6-877a-4a41-ade1-5b50904f57b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34816047f56e473da61b4a814991cd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "4179c10d-55de-4de7-8eea-612bafe56c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e7b8bc-37b7-4972-847f-347f35e9f190",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# snarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "7e79285b-b88d-4f08-990c-dbf61c3164e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-snarks/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "de7ee14d-2fc2-4519-8d52-8df6bffc24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a6c58192-0d74-46a3-86ce-2b6c48b722a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A.', 'B.'}"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "2cbe36ea-9aab-4edd-ae6a-6da8ff8e2e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf7350b9fb9432ea45f3bcc77d513a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "4db53705-ddfa-4e6a-8986-8d5e9d164a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B'}"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "7826847d-ee00-4cc4-b3c5-6d068144d39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3847c0a5720b43a7a98c202dd90e9704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "04356af0-adc6-4ba8-8540-21ea6915fc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8764044943820225"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51614624-d1a7-43db-9c5e-a19c642352f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# sports_understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "1f313ffb-c077-44da-a40f-ca27cb34e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-sports_understanding/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "28e42721-9008-4899-b361-64cc358c31bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "45a4e18d-fed5-4fa1-b1ec-1a43f18d4ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cannot be determined',\n",
       " 'False',\n",
       " 'False.',\n",
       " 'Implausible',\n",
       " 'Impossible to determine',\n",
       " 'Likely',\n",
       " 'No',\n",
       " 'No, the sentence is not plausible.',\n",
       " 'Plausibility cannot be determined.',\n",
       " 'Plausible',\n",
       " 'Plausible but lacks context.',\n",
       " 'Plausible but uncertain',\n",
       " 'Plausible but uncertain due to lack of information.',\n",
       " 'Plausible but unlikely',\n",
       " 'Plausible but unverified',\n",
       " 'Plausible in a figurative sense, but unlikely in a literal sense.',\n",
       " 'Plausible under certain circumstances.',\n",
       " 'Plausible.',\n",
       " 'True',\n",
       " 'True.',\n",
       " 'Uncertain',\n",
       " 'Unknown',\n",
       " 'Unlikely',\n",
       " 'Unlikely but possible',\n",
       " 'We cannot determine',\n",
       " 'We cannot determine the plausibility of the claim without more information.',\n",
       " 'implausible'}"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "826c199b-a24d-44ad-98d5-bf17791dc5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b58eb5e4844b10827426b038668722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "ab35bf9f-2679-4a63-a2f7-22aed24db11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cannot be determined',\n",
       " 'False',\n",
       " 'Implausible',\n",
       " 'Impossible to determine',\n",
       " 'Likely',\n",
       " 'No',\n",
       " 'No the sentence is not plausible',\n",
       " 'Plausibility cannot be determined',\n",
       " 'Plausible',\n",
       " 'Plausible but lacks context',\n",
       " 'Plausible but uncertain',\n",
       " 'Plausible but uncertain due to lack of information',\n",
       " 'Plausible but unlikely',\n",
       " 'Plausible but unverified',\n",
       " 'Plausible in a figurative sense but unlikely in a literal sense',\n",
       " 'Plausible under certain circumstances',\n",
       " 'True',\n",
       " 'Uncertain',\n",
       " 'Unknown',\n",
       " 'Unlikely',\n",
       " 'Unlikely but possible',\n",
       " 'We cannot determine',\n",
       " 'We cannot determine the plausibility of the claim without more information',\n",
       " 'implausible'}"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "22a4f79a-d5c2-4e93-9a88-93e18d4be135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d81f9a2f4540f4ba0782bed45249b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "none_ds = new_ds.filter(lambda x: x[\"answer_pred\"] == None)\n",
    "none_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "7ae7711e-5446-4595-9574-f4a678524d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e2446b90684c5c9b0cdf3053de242d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plausible_yes = [\n",
    "    'Plausible',\n",
    "    'True'\n",
    "]\n",
    "implausible_no = [\n",
    "    'False',\n",
    "    'Implausible',\n",
    "    'No',\n",
    "    'No the sentence is not plausible',\n",
    "    'Unlikely',\n",
    "    'implausible'\n",
    "]\n",
    "indeterminate = [\n",
    "    'Cannot be determined',\n",
    "    'Impossible to determine',\n",
    "    'Likely',\n",
    "    'Plausibility cannot be determined',\n",
    "    'Plausible but lacks context',\n",
    "    'Plausible but uncertain',\n",
    "    'Plausible but uncertain due to lack of information',\n",
    "    'Plausible but unlikely',\n",
    "    'Plausible but unverified',\n",
    "    'Plausible in a figurative sense but unlikely in a literal sense',\n",
    "    'Plausible under certain circumstances',\n",
    "    'Uncertain',\n",
    "    'Unknown',\n",
    "    'Unlikely but possible',\n",
    "    'We cannot determine',\n",
    "    'We cannot determine the plausibility of the claim without more information'\n",
    "]\n",
    "\n",
    "def map_fn(ins):\n",
    "    for yes in plausible_yes:\n",
    "        if yes == ins[\"answer_pred\"]:\n",
    "            return {\n",
    "                \"answer_pred\": \"yes\"\n",
    "            }\n",
    "\n",
    "    for no in implausible_no:\n",
    "        if no == ins[\"answer_pred\"]:\n",
    "            return {\n",
    "                \"answer_pred\": \"no\"\n",
    "            }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "b6408a9c-c345-48e9-a980-2057dbac1743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cannot be determined',\n",
       " 'Impossible to determine',\n",
       " 'Likely',\n",
       " 'Plausibility cannot be determined',\n",
       " 'Plausible but lacks context',\n",
       " 'Plausible but uncertain',\n",
       " 'Plausible but uncertain due to lack of information',\n",
       " 'Plausible but unlikely',\n",
       " 'Plausible but unverified',\n",
       " 'Plausible in a figurative sense but unlikely in a literal sense',\n",
       " 'Plausible under certain circumstances',\n",
       " 'Uncertain',\n",
       " 'Unknown',\n",
       " 'Unlikely but possible',\n",
       " 'We cannot determine',\n",
       " 'We cannot determine the plausibility of the claim without more information',\n",
       " 'no',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "7edec95f-34bd-46ee-99f8-f583af515c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ad5a73dc4e445dbd46b6575d4cba2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "6b563718-2304-4d32-9d35-12fd86417285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95be697e9b8e4982a8bbb22b9bf36407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.704"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53b711-b627-43a7-91be-c9f975253230",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# temporal_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "4ff26847-c272-43bb-abed-981f71ecaa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-temporal_sequences/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "0736540f-c3cd-48d4-9368-3e986bb7c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "6f42588e-4736-4f9a-a6f3-7e1b1ee610a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(C)', '(D)', '(D) 5pm to 6pm', 'A', 'B', 'B, D', 'C', 'D'}"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "6f0e3bf1-6d3d-49a7-9ac9-b4e434a1ff95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5808ab9fd26141f2babc6ad3d7efafff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "1935aa89-287e-4bd3-a7ed-a49ff4309be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'B, D', 'C', 'D', 'D 5pm to 6pm'}"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "e8b3a01c-9742-4e8f-84a5-acc7931bf3cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41c4488c71046a89afd6f6c33755792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    if \"D 5pm to 6pm\" == ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"D\"\n",
    "        }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "375d5367-e39e-428b-a61c-3d3afa02723e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'B, D', 'C', 'D'}"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "f7f189c5-cba4-41ce-9635-e1a04a9600ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382646806c554c23bf6032b8b085b024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "09500846-591e-400d-8e00-7a413f80b304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f872025d214b4be1a5f33eb0adea6d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.996"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46999e93-5777-438d-82fc-23e1320a4ee5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# tracking_shuffled_objects_five_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "1f430e83-d257-42b1-80d6-86c00ff391f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-tracking_shuffled_objects_five_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "6e48f967-b3c6-4578-be6c-3c5f5978e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "3eaa6a24-46e7-4ea6-99e5-141257dff314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(A)', '(D)', '(E)', 'A', 'B', 'C', 'D', 'E'}"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "ee35345c-acaa-4b80-9a62-4f2d9e8e13bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1622ac744dd44b808082bd1cadad067b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "cd9525e8-a803-4563-b7e2-257a7abd5b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E'}"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "92e11841-7795-4e9a-b0ed-1fb91a7942f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b784eb79c640c4af87d7bf09bbb0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "597c8af1-8fe8-47a9-8f2b-178a6f02d47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d96cc-2a17-42f2-be48-0c078e1ad4c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# tracking_shuffled_objects_seven_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "85ad5a89-1fea-43b1-aa46-6fb31c71bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-tracking_shuffled_objects_seven_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "c76badad-20e0-4edf-87c1-a8cc07f8dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "ba44c1a5-469b-46e4-a0e6-982650f725e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(B)',\n",
       " '(C)',\n",
       " '(D)',\n",
       " '(D) Karl',\n",
       " '(E)',\n",
       " '(G)',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G'}"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "f8d40d34-457a-4e9b-8090-ececac236f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fe8efde45a456ba0819c7a6b8ea853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "da59656d-c659-4b13-ac37-b46d014e5a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'D Karl', 'E', 'F', 'G'}"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "67fb1858-94ff-49a7-9571-4e754a36b0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bd79bb13fd4931ab34084eba7f2a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    if \"D Karl\" == ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"D\"\n",
    "        }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "1cd30607-394d-4750-aada-4c560a34bfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', 'F', 'G'}"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "1700d189-b1ac-41ea-9d94-6cc2c0f4674d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1abc1f0a2bd43e1a517da33ba22be5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "b2a5700e-3b85-403b-9072-57dc4cb9656b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3398a60968e14eae8ff73a6d39336b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.968"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7380f-757f-4efe-a499-d5fcb8db1605",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# tracking_shuffled_objects_three_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "5e8b3d70-00c0-40bf-8930-2ff52cebbb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-tracking_shuffled_objects_three_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "b7c037d5-2c4e-4c06-9d5d-e53014c787cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "2848ce35-ae10-413d-968e-e2b25260aeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', None}"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "4a9a977f-d0e1-4f15-ab88-45ceafeb4259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085b25a098bb4d05804a4d1b20f9009e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "95073ba7-5b3d-471b-9bff-1df8c7e4ad8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', None}"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "271b95ea-75e5-45d2-aaba-4cd7c888cc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e546e455496e49a099dd1d0de606b3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b76790-b103-45c1-8153-f29976797331",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds.filter(lambda x: x[\"answer_pred\"] == None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "56a0469d-5887-4f65-a900-49e2caab7508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080e9689-0a35-46be-944d-2f768b223465",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# web_of_lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "d0515e07-2539-4edc-a510-4802dd4f6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-web_of_lies/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "b4496e01-3aeb-4b9f-af54-883988fac6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "b423b1e8-babb-4821-a45e-da57918d936e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No', 'Unknown', 'Yes'}"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "cc9ef3c3-84ed-4e2b-9d37-2c8c48858322",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "e9f92bfa-bf9a-48c9-a0d5-93a608560cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b1e7bb806641e1a087b800d75885c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "ab7da6e4-317a-4201-8cd7-fa711fb57027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f731a3a136c04112995318b0c512e2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.808"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda62f9-f223-4c31-8dca-9bc3c9869fa1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# word_sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "f19600b8-10d1-4ab4-b337-960bc092c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-word_sorting/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "0602cf7b-e30b-4d1c-9cb2-f4cedcfc2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "0b50e8b9-5058-4c4c-bf95-645d22909893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.[]\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "55b444b7-ae2e-47e6-b164-d3c31e320a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = new_ds.filter(lambda x: x[\"answer_pred\"]==None)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "bf928ad1-1eb3-44fa-a9d6-eaac72c9bbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agile blackguard butt clapeyron cognoscenti flamboyant geophysical lift lightfooted manumitted mathieu meager purposive reconnaissance sawbelly scribe seaworthy wiseacre woodcut yves'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds[\"target\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "82644eb0-41d0-4388-a0af-2b2202048d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd0f29ef5474f7ba5dd4254708d46b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": \" \".join([word.strip().lower() for word in instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.[]*')).strip().split()])\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "4d590011-51ce-4725-9ca4-c46c0b933f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abbas average bridesmaid catsup charm coddle dogfish hypothalamus inconvertible inequity integral invocable memorandum multiplet phloem region scherzo shutout therewith trumpery',\n",
       " 'abbe adposition arragon cast danbury emplace falsetto gavin income inhibit onerous palazzi tabletop',\n",
       " 'abc ada austere blend cankerworm falcon flamboyant gag grecian hanukkah indicate kruger lobster militia nobody pierson quad right ron wildcat',\n",
       " 'abdominal address berry bounty effusive fomalhaut hanoverian islamabad involve jordan optimal pay stearic stigmata swathe tattoo them tornado yang',\n",
       " 'aberdeen analogue deciduous easel sprightly swaziland',\n",
       " 'abner abramson amity automate exquisite fruitful gurgle none shampoo shorten waterproof',\n",
       " 'abo armful bonaventure cremate dictatorial embryology frond gasify guiana herman indistinguishable oscillatory pancreatic passenger referential stockholder tip through',\n",
       " 'above big broken coexist dominate irk olive prometheus screw thirdhand',\n",
       " 'abramson bangui carlisle cavalier contextual dustbin emacs implementor islamabad magistrate nudge picnicking railway refractory silvery waite',\n",
       " 'absorption aristocratic bermuda cesium cheerful congo diagram eucre ezra fallen juvenile musty nigeria nod quartile screechy slack testicle',\n",
       " 'abstract borough brown cortex cosec delphinium diminutive fleabane foot guy hair highfalutin ipsilateral longish mobster richfield trapezoidal ugh wintertime',\n",
       " 'abuilding burgher celebrity chigger ernie exorcism indiscoverable medlar newsboy pow snuff synchronous thimble thirteenth tinfoil yap',\n",
       " 'abutted agamemnon aquatic capacity casualty essex guinea hitachi hondo islamic loosen loquacious niece planet roadway solstice steed suspicion tibet',\n",
       " 'academia amos beautiful butterscotch circuitous diatom europium extoller farrell fiducial ford glance kochab metzler molybdate monomer predatory veterinarian',\n",
       " \"accelerate bauer county nail nominee o'connell phony poole putnam quantify raisin venice\",\n",
       " 'accept alpenstock angus castigate chromium concision doge drool elizabethan jutish marshmallow ocean octennial prize resistive stonewort vociferous',\n",
       " 'accept avoid caramel carbuncle compressor conclave drib elegy embower error gaillardia grassland hostile pitfall rosa spectra stepchild utopia whimsey',\n",
       " 'accessory admiration allusion bandgap bruckner cruise fungus gambit heron maidenhair postprocessor proscenium technion',\n",
       " 'acclaim champ clothbound commodity conclusion delirious dyestuff exempt gadwall hayes hood hypothalamus jigsaw lozenge pipeline plentiful sarcastic seashell sensory teen',\n",
       " 'accomplice az choral circumcircle clatter crepe doff emission fairfax incantation labour lorry pleura prig ride tea upon viaduct wheelbase whim',\n",
       " 'accrue archipelago biplane breezy canada conspiracy constructor dobbin germinal hamburger insubstantial laramie lost malleable nutrient peloponnese ted thigh',\n",
       " 'acidify antagonism asteria',\n",
       " 'acoustic anarchic bureaucracy diatom fabricate guelph immovable leftward liven neo phenomenology provide shortcut suggestive syndrome total trammel usage yarmulke',\n",
       " 'acquisitive annuity autocracy bruno custody dare exploitation lodge militant quench somatic thunderclap ventricle',\n",
       " 'acrobacy advisee ape apostate cardigan chancery cochran crowbait equip evildoer hillman hoofprint kuwait max molten practise retinue sloane wuhan',\n",
       " 'across admixture directrix flight gut indicate marshal predacious quagmire smuggle vantage',\n",
       " \"acuity anticonvulsant carrageen disseminate discovery drafty embolden glamour hangout hasty magnificent pewee proscenium registrar scrub supposable sushi you'd\",\n",
       " 'adipic antique athlete atonic catch encumber lauderdale neutrino olivia persona sovereignty specify statuette whiteface',\n",
       " 'administer aeneid coachman decadent delhi dey gradate grim jacky littleneck phosphorescent pristine shrunk sinh systemwide tasting thrown torpedo verdict',\n",
       " 'admixture catwalk chateaux coordinate equine higgins irremediable malthusian offertory panamanian pecos reluctant shelve suction tunis',\n",
       " 'adonis birdseed citizen contaminant convair extensive fateful frighten judaica scrubby soothe southeastern stormy suppose trillion trundle',\n",
       " 'adopt afghan friday glimmer multitudinous pacifist wage worcestershire',\n",
       " 'adsorption align anastasia anastomotic apache award bobbin burrow calumny epaulet execrable hostelry hun macedon omnipotent putty roughshod smooth spontaneity',\n",
       " 'advent anger convoy deliver filly gneiss grocer hessian hotbox landau marlborough ninebark platelet plat pyrotechnic siemens stapleton transitive treadle uncle',\n",
       " 'aeneas colombo foothold fox garry glycerine inviolate lucre magnanimity nevada notoriety plebiscite pompey quagmire satanic scription softball spleenwort tennyson type',\n",
       " 'aerodynamic botanist giacomo habitation jimmy nebulous offset padre panicking roosevelt schoolmate suburbia vector',\n",
       " 'aerospace allure common decoy denmark enviable exclusive frill griffith jibe loosestrife nanosecond saute screechy sow spermatozoa spitz swabby yates',\n",
       " 'affable almost apache antic astute dandelion deadlock delphic execution fortunate horntail leverage levitate libertarian sanction scathe semitic storehouse sweeney unbeknownst',\n",
       " 'affirmative airframe arcing ballroom bassoon benefit buggy coupon decide dodge hypothermia intrepid junior ladle nineveh prorogue schmitt shagging sparse ulcerate',\n",
       " 'affluent cheshire covalent diagnostician divisive epsilon folklore gideon gothic grover horowitz julio peanut quadrature salient spiderwort spiritual',\n",
       " 'afloat apostasy bechtel chattel conner ferment grosbeak hendrickson indonesia jacm lanthanide melancholy quark scavenge strove vibrate',\n",
       " 'afro blackbird blame calyx elgin emphases implacable jura mayapple perquisite vii whit',\n",
       " 'afternoon complementary dixie hesitate horsepower immaculate kind laughlin loire mechanism nimble sandia septuagenarian sierra shuffleboard toggle woebegone',\n",
       " 'agamemnon clench depreciate eject forum frame herbivorous lien marcello numbly search sprout unary zaire',\n",
       " 'agglomerate ballast dollop erosible expiry extensor gazpacho indiscreet manuel ogle oilcloth spaniard',\n",
       " 'aggression arachne asplenium bystander definite gneiss lengthy sanford southeast translate',\n",
       " 'agile blackguard butt clapeyron cognoscenti flamboyant geophysical lift lightfooted manumitted mathieu meager purposive reconnaissance sawbelly scribe seaworthy wiseacre woodcut yves',\n",
       " 'agrarian applicate candid colossus haddock honeymoon people pragmatic sheepskin',\n",
       " 'airlift butch cone homeowner inanimate incurring logarithm lumber maladapt micron newman profuse robertson sammy souvenir uganda wilcox',\n",
       " 'aitken barycentric detest downey kajar nat solvate usable vision',\n",
       " 'alcohol behold escutcheon forth fumarole hackberry motif pease regret satisfy uptake walkie',\n",
       " 'aldebaran backyard boxwood cabbage entrepreneurial fiberboard game inkling invincible lakeside lightface matte mcgee peruse polyhedra pulsate rae rowley shape watchworks',\n",
       " 'algonquin beachhead bloodstain dilate forth frolic lacunae lazy liggett mcintosh parameter piggish pintail protector slaughterhouse sterno unesco',\n",
       " 'alkali breach buckle falsetto hyperboloid liquidate mirth nagasaki parmesan',\n",
       " 'allegoric collate euphony gloriana loge lollipop mast milord prolix rendezvous salle schnabel',\n",
       " 'allele anthropocentric badinage banish bartok brunswick dale dar desolater dun fraternity goat martinson monomer morphemic pegging starkey underclassmen whoop yourselves',\n",
       " 'alleviate benelux buoyant duopoly felice gland gunk hardbound klaxon mattress tomography townsmen',\n",
       " 'allis anthology jacobi marmot membrane oakland seaborg toggle trapezoidal',\n",
       " 'allocable bertram boutique champlain crunchy dissipate facto highlight hydrology judaism labile necessity often phenol silage vale',\n",
       " 'allocate ann bishopric blake carbondale casual cometh confirmatory crinkle degum elliot expatriate hangable neal orthodontist shenandoah soybean telegraph tuxedo unipolar',\n",
       " 'allot chauncey clergymen coachmen coddington embark fatten gazpacho granular hobble murk muslim niggle pristine pvc singlet threefold too yeats',\n",
       " 'allotted fate figural gorky grapple hydroxyl knives neapolitan nerve plainfield rampage saxon scottish scrumptious sidereal siena stooge thermal yakima',\n",
       " 'allstate dose dyad multitudinous plural powderpuff stalin',\n",
       " 'allyn carbonaceous cetacean investigatory johann majorca paradigmatic pathogenic pray supersede tung',\n",
       " 'almagest archenemy catawba councilwomen decrement gnome jungian limpid milt photolysis sagging transfusable',\n",
       " 'alphabet birmingham cantonese educate entourage fashion fond marimba mechanic philology retrofit',\n",
       " 'alterate aseptic cayenne chandigarh debauch declassify dingy equanimity excursion foamflower groupoid inclement kruger lawful october only scorch',\n",
       " 'altercate cornerstone courtroom dusenberg foraminifera gossamer insist jive promulgate raft sal sophocles syllabus wrongdoer',\n",
       " 'alternate boone charity chalcedony genteel million olden satin sinai',\n",
       " 'alveolar arabesque arkansan bedroom bend brassiere curvilinear diagnosable deterrent fluke fossiliferous novel patrolman planeload sheep spearmint trident yen ytterbium',\n",
       " 'amanita amatory annoy besiege boggle california canticle crocodilian dexter dissipate dizzy encephalitis hornblower notre pasture propylene psychiatric sepia snipe straight',\n",
       " \"ambient appropriable arroyo billion breccia coupon eardrum faze fivefold intimidate martinson o'connor perplex secretary social surtout terrestrial voltmeter\",\n",
       " 'amerada craftsmen din eclipse gaillardia inroad jackboot jest jordan kill mirth nate pomade putt shortcoming spruce whelan',\n",
       " 'amethyst bathos dormouse obtuse resignation walt',\n",
       " 'ami bituminous decadent exeter knickerbocker',\n",
       " \"amicable browne calumny coo deerstalker extreme henchman histology indoeuropean paginate pelvis sonority they've tramway turvy\",\n",
       " 'amperage crimea farther insolent ping protocol raillery stephen tech',\n",
       " 'amphibious assist baseplate benchmark ell hatchet homecoming loess machine percentage pilot prorate redcoat reverie sank stallion thoughtful wehr wince',\n",
       " 'anaglyph cowbell duane fest glamour harriet impressible switchboard texture vietnamese whippet',\n",
       " 'anaheim clinic eaten immemorial madeira marx micro offprint sprue subject trafficked va',\n",
       " 'analyses augustine blueback credential den erda falter fireproof geophysics guitar keynote meter porte shibboleth stonewort swampland telephony testimonial timeshare usa',\n",
       " 'anaplasmosis bumble chopstick clue fiesta footwork fresco ingot orthography palisade pilate saul smalley storey teen',\n",
       " 'anarchic bstj elution exhumation furl geld gradual j liniment locomote midshipman pantheist profess riddance rowley saline',\n",
       " 'anastomosis backslide calvert commando gabriel hendrickson hollister jackson pizzicato quail separate shelter spongy sticktight syndicate variety washy',\n",
       " 'anchor barre buckle concatenate dimension edgy eleanor epiphyte faunal integrate masochist orthodoxy parasol patrician pendant sail singular swift',\n",
       " 'anharmonic beauteous coypu inflammation',\n",
       " 'anheuser bungle chaperon frame hippodrome keller miterwort prompt spidery together yolk',\n",
       " 'aniline boletus eddy fontainebleau galveston gentle scandalous skat sportsmen wile',\n",
       " 'animism awash beau bessie cream extricable helical indoeuropean pendulum sanhedrin scratchy venezuela vice',\n",
       " 'announce carp clayton co earthy hello inmate nimbus parentage phonetic sharon skinny sudan watson',\n",
       " 'antaeus caw daughter devonshire gloria helvetica hi leatherback magnesium megohm nikko raincoat scald schroedinger sojourn terminal woodcarver',\n",
       " 'antler christiana falter invigorate jot kamikaze landlady libya ludlow mallow porridge residuary tuscarora wetland wrapup',\n",
       " 'aperture bradshaw holocene mare muriel pathetic r&d sigh staircase talon',\n",
       " 'apparition conference copra coupe dutton floruit ignore implement layperson messenger primitive superstitious turnoff westward',\n",
       " 'appliance impede pulitzer superior',\n",
       " 'appoint baneberry biharmonic dyne moustache pirate windowsill wiry',\n",
       " 'apprehension cashew ensemble',\n",
       " 'aqueous deregulate gala infantrymen knob lysergic yaounde',\n",
       " 'arapaho bacteria bela bock burley',\n",
       " \"archery arlen barbudo bride coquette lockwood lucrative officious polytypy radix teem tunnel you've\",\n",
       " 'arenaceous baccarat blare bowman earl gloss granola hollandaise inauspicious mackenzie metaphoric pedro penis psyche quarantine roadster supranational',\n",
       " 'army emancipate envious planetaria pooh scotia wink',\n",
       " 'aroma carcinogen delmarva designate facetious nod parochial rally sawfly syllabus',\n",
       " 'arraign blutwurst convenient faber glacier horizon inconspicuous peste portentous rancho uranyl',\n",
       " 'arrear brookside eavesdropping fasciculate henry hermaphrodite herodotus ibn incorrigible jane linchpin maritime postdoctoral shin sticky vehicular',\n",
       " 'artful cancelled castrate citadel croon ear endpoint excite glaucous inspiration marque mckinley pesticide prig radiometer relish rothschild school tioga trianon',\n",
       " 'artillery bainite doris fda harm incongruous monkey prosody vegetate vivian',\n",
       " \"artistry can't cascade condiment consignee gentlemen glance golf markov mimosa nine projectile shanghai swingable tale wildflower\",\n",
       " 'asset bona cicero coastal dusky exonerate gaussian handlebar inhabitation portfolio purport rastus responsible ruanda silver zig',\n",
       " 'assimilable bivariate bought calypso dogwood functor hideaway holeable lola monotonous nebuchadnezzar pacifism provocation slick',\n",
       " 'assure bully butterball bye contend cornet deaf dinosaur frontage gunky indeterminable lustrous ostentatious paradigmatic rhyme sanderson sashimi smokestack taint',\n",
       " 'astigmat boyish coriolanus creak cutlet easternmost godson heaven highwaymen leather muscular musky paula scavenge synaptic zinc',\n",
       " 'astronomic cabdriver coherent loch pivot wagging',\n",
       " 'atavism contrariety crochet dimorphic emanate forthwith grind guaranteeing hoop iniquity katie more polytope prodigy titrate',\n",
       " 'atmospheric chess credit geopolitic intercept loci lunge newsmen siren swart tamp umber',\n",
       " 'audacious battleground bulrush filamentous harris intervenor municipal rubicund semaphore sensate xylophone',\n",
       " 'auerbach decor deoxyribose devisee dianne hodges incommensurable motorcade stratify troupe',\n",
       " 'authenticate carbonic choreograph corvallis countersink equestrian have libya metal multifarious nitric obfuscatory petition pro retardant wigwam wishful',\n",
       " 'avalanche befriend berniece bong bremsstrahlung dactylic flick gilbertson goff hereafter hoe housekeep hurry lanka metazoan posterior showroom',\n",
       " 'avalanche cameroon canal chaplin clonic coachman cram fortran ipsilateral kennan medea postpone pyridine referring squabble ussr',\n",
       " \"avoidance casualty courtier gibbon leprosy merge shouldn't sidewinder tacky transgressor\",\n",
       " 'awash auxin bateau cubit eutectic gown gullible inane jurisprudential mistletoe nepenthe ow pirouette pussycat schwartz scottsdale shockley travelogue upbring',\n",
       " 'babysat consul curvaceous cutaneous hugh regiment spoke stationarity',\n",
       " 'backpack coffman collision cotman detour gnostic hammock jacobean lung membrane monologist notate quirinal rhubarb secretive stove tobacco',\n",
       " 'baden bizarre claret colonist deplore dove horticulture monaco paschal play rodriguez sonant strap valuate',\n",
       " 'ballard brindle cornerstone credulous curio des difluoride green horseplay jew mixup nonce nostalgic pitney predilect prowl rape scrappy toward',\n",
       " 'bandwidth hidebound wreak',\n",
       " 'banshee beefsteak beware bicycle birthplace diacritic helical junctor musicology obstinate postcondition protoplasmic sap state uptrend vasoconstriction',\n",
       " 'bare census exaltation gnomon humility infirm intrinsic manatee moth oblique paregoric patristic snagging sorrowful stressful timeout torch',\n",
       " 'barn damp delmarva dot drumhead embezzle entirety greene guru it&t malton obstetric onus panicking prod same scorch splutter subsist thrill',\n",
       " 'baronial checksum circumstance comment dartmouth dredge emittance eulogy felicia huckster monochromator neuroanatomic spotlight',\n",
       " 'batavia canaan maladjust merry olefin ranch relinquish yang',\n",
       " 'bate callous climb cortez dnieper dogging garrison giantess mast moran muddy prank reverie satisfy staunch',\n",
       " 'battery bushland capacitive contingent crossbill enigma jane lipton meager ricochet wacke wallet wysiwyg',\n",
       " 'bauble cube fabulous kitakyushu length limnology sequel senescent seventh voluntary willow yucca',\n",
       " 'bedtime boon bottle chapati kenney okinawa',\n",
       " 'behind hornpipe iniquity inmate mcconnell mollie sandy scorn toroidal volcanism wellwisher yoghurt zip',\n",
       " 'behold dew dissipate format hew maybe misogyny oxalic pray steel stiffen termcap',\n",
       " 'belize bolshevism cost dance deadline dietetic formulae foster hesitant huddle judson mantle odessa palace proust progeny rackety resplendent thirdhand warmth',\n",
       " 'benefice improvise nevins protein pullman puree pusey river squeamish whale',\n",
       " 'bengal fettle yeager',\n",
       " 'berg bluish gamut multiplexor puerto shreveport subliminal',\n",
       " 'berra calabash episode hen marietta molybdenum pedantic pounce schedule sparkman vinaigrette',\n",
       " 'bertrand careful',\n",
       " 'besetting boyd counterweight detergent groove hide intangible menlo nv ovipositor sans spumoni',\n",
       " 'betelgeuse blue caudal char cyanide dew epoch grossman inexplainable lyre meaty snazzy stain tao trail trailside wash',\n",
       " 'beth kenya',\n",
       " 'betony boar bootleg bronzy centaur charge clemens collet contemporaneous contravariant cordial dorado handicraft macmahon mesh monterey possession regina underclassman',\n",
       " 'biennial creedal cry eyesight fletch fraudulent miltonic mirage titmice whisper',\n",
       " 'bighorn contaminate demystify nigeria odysseus penny proton sociolinguistic stirrup voltaire',\n",
       " 'bijective briton concord dim dive eigenspace floruit gaucherie glycogen guidebook irrevocable jacket pinkish reversible song',\n",
       " 'bilinear brenda cacao chivalry derivate eaten endothelial ferocity gastronomic grammarian irreducible knutson phenotype polkadot rockaway scurrilous',\n",
       " 'bilk lethe perturb tactual',\n",
       " \"bindle chiang crystallography dent mambo ram roadside rundown savannah shipshape spew strange survey won't\",\n",
       " 'bivalve mainstream malformed mortify oconnell paunchy sleuth twelvefold umbilical vinegar',\n",
       " 'bizarre contravention drapery dreg ingratiate margaret peculiar sequential superintendent',\n",
       " 'blackstone feed figural giveth hecatomb hunt incense middle obstinacy pasty pestle plume sinkhole spavin statutory tel toothpaste undulate',\n",
       " 'blest buxton consternate proximity quizzes sound tariff xerxes',\n",
       " 'block custodian deadwood foxtail guaranty hexadecimal macedonia rubaiyat victoria',\n",
       " 'blunderbuss box dinnertime feel frugal labial oresteia papaw perfidious sonar',\n",
       " 'blutwurst buckaroo closeup intelligent laguerre thesaurus vertebral wily',\n",
       " 'blythe bombproof code corpulent cytolysis damn diagnose fluorine honeybee maharaja pore scalp solicit swipe',\n",
       " 'bodyguard commensal flagellate flotation ineradicable involve jocund miff postprocess',\n",
       " 'boldface darkle fungi gobble inflammation jacqueline joanne macaque piano schiller slump sojourn sst',\n",
       " 'boletus calypso conklin debugging deportee lucretia necktie omnipotent passband revving ulysses',\n",
       " 'bologna cottrell crackle cure doubtful entropy extoller gloria litigant procedural summand tyke',\n",
       " 'bone convergent doleful hindustan homeobox ia sweatshirt wagoneer',\n",
       " 'bonito dreamboat fritter haggard nose whodunit worcestershire',\n",
       " 'booby butadiene flair functor heck orphanage racy rheumatic shivery sin snowball spec testy trench zorn',\n",
       " 'bootlegging indifferent trainman',\n",
       " 'borough hyperboloidal',\n",
       " 'bosporus bully cork edt forfeit flogging lexicographer minor multiple perceptive pizza pungent rancorous reedy referring sedition sell tit',\n",
       " 'brainwash broom deathward faithful gondola integer kinematic menu soc',\n",
       " 'brainy cony enigma erudite gouda hoof impalpable isaacson lisbon malaria portsmouth portrait servomechanism stronghold succumb',\n",
       " 'brake bunny chevalier choose cubby drone exotica good indomitable lineage mental nick pique rajah sheaf steelmake stitch thymine wigging',\n",
       " 'brewster inaudible synapse tithing tuba',\n",
       " 'brindle clifford florist gloat sacramento siskin triploidy willard',\n",
       " 'broadcast cortland diffusible galvanometer gross gujarati incestuous larynx nomograph pewter scout sketchbook stag transition',\n",
       " 'broaden envy',\n",
       " 'brownian coach eosine erudite flax inadvisable magnesium marriageable stahl vicksburg virgo',\n",
       " 'buckley frisian ix livre panoramic substitution',\n",
       " 'bucolic oblong whoosh',\n",
       " 'budd deform',\n",
       " 'built poland swab thunderclap',\n",
       " 'bully cardamom cryptic ebb flatland forthwith insurmountable interior jurassic landslide licensor mammary nassau opinionate seeable valkyrie',\n",
       " 'bust chalk cowboy dentistry dumb fatty goucher horror masonry midshipmen musicale pathway resiny roadrunner rocket sapient serf tangential urea urinary',\n",
       " 'buxton callus cameron contribute extensible marque methanol olympic precise procrustean seepage shelf sideboard tty typescript unitary verify',\n",
       " \"caching defend delicious distort emboss epistemology gherkin indicate injustice maser percent phillip roadside savoyard somewhat spicy we're winston\",\n",
       " 'caliber capricious eft faulkner fragile gastrointestinal headboard irishman kingsley lobby nary ouzo peaceable phillip phylum residue stamp sulfanilamide upholster',\n",
       " 'calligraph form goat inverness sibyl threadbare',\n",
       " 'campfire contrast crowfoot purgatory scrupulous',\n",
       " 'captious elton ineligible iodinate olympic sherman',\n",
       " 'carport firewood introvert sweepstake tiresome',\n",
       " \"cartilaginous no science spokane that'd\",\n",
       " 'caruso chassis corporal signora',\n",
       " 'catechism daddy',\n",
       " 'celandine diploma faith harold hostile mohawk octavia supercilious thebes',\n",
       " 'charcuterie crucifix diatom footfall greenberg impenetrable muddle spoken synchronous',\n",
       " 'cheddar edt from oblivion pang poignant yuh',\n",
       " 'chicanery fugue mountain',\n",
       " 'chlorate glidden incentive judicatory lavoisier manatee spurt',\n",
       " 'christen clearheaded despond driveway encapsulate fungi gob mendelevium midwinter purpose sisyphus stanhope strip studious symmetry trample vs wring',\n",
       " 'chrysalis wallaby',\n",
       " 'cite coleus fructose hurricane improbable irreducible tipoff tularemia vesper whereabout whitetail wier',\n",
       " 'citrus cloudy euclidean fight hobby invite majestic scene stonehenge surge thrifty winsome',\n",
       " 'cloudy ecosystem ferret knotty',\n",
       " 'clytemnestra crag cutover diocletian dickson electrolytic inhuman lipton marginal scrawny stalk thereupon took wife wireman workplace',\n",
       " 'coltish condescend date percolate placid rampant rochester significant',\n",
       " 'comet cocksure heusen hydrate injun manley pincer snippet spokesperson',\n",
       " 'compton confident foundling pam saprophytic stowaway stupor',\n",
       " 'confess croupier daffy dockyard duty household hypothesis info loam mandate mantic minstrelsy nepotism peccary sawtimber serenade silver summate triode',\n",
       " 'confidential faery fiction heterozygous horehound overture ursa',\n",
       " 'confrontation daddy hirsute proserpine proofread quantitative',\n",
       " 'conglomerate dynastic inflammable nebulae phosphide prick stagnate tackle tristan vitiate',\n",
       " 'consonant globule jacob musician sleight',\n",
       " \"convey decimate experiment fortieth incautious kudo marshall neoclassic rest whimper wiley xylem z's\",\n",
       " 'coplanar natalie stevenson zan',\n",
       " 'core discreet hat sonnet',\n",
       " 'correspond herpes him seashore',\n",
       " 'cortex incident insane kangaroo marionette mcleod pillage roundabout sinter stipulate threshold trammel',\n",
       " 'cotyledon more pepperoni regret starlight wallboard',\n",
       " \"coven disturb etruscan lorenz plastisol runneth shouldn't skintight swept\",\n",
       " 'covenant davenport densitometer noisy scoreboard sonorant thence',\n",
       " 'crude cunard danubian inscribe peculate perceptive posterior tragedian upraise',\n",
       " 'damon europa foliate potpourri',\n",
       " 'darkle erudite hookup instant lip moldboard olsen pea quadrant yonkers',\n",
       " 'dateline household jill langmuir pipette',\n",
       " 'dean eosine formula gibson inebriate mater mulligatawny rica sigmund vassar',\n",
       " 'dnieper labile lease soulful vehicular',\n",
       " 'downtrodden gadgetry gamin hurst inertial maraud morphine parsonage propane',\n",
       " 'dulse kowalewski politician yew',\n",
       " 'erg inability invocable janice nucleus possible vague',\n",
       " 'extempore gotten',\n",
       " 'fasciculate judicature presto',\n",
       " 'fortescue helmsman percept purloin sioux',\n",
       " 'fracture sediment towel varsity',\n",
       " 'geld phase thunder',\n",
       " 'gloucester raytheon slurp',\n",
       " 'greasy lapidary mark',\n",
       " 'haughty seashore',\n",
       " 'jugoslavia polyhedron retrorocket scoot walnut',\n",
       " 'laudatory shakespearian',\n",
       " 'leasehold orchestra permafrost shiva testate',\n",
       " 'lise miaow snipe',\n",
       " 'muddy nascent',\n",
       " 'murray sweatband',\n",
       " 'neff nicodemus sortie',\n",
       " 'novelty rectitude splashy',\n",
       " 'skimpy zoroaster',\n",
       " 'syndrome therefrom'}"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "9626fe3d-d611-457b-b791-5862782ae4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a52e763f16e485996e1f9ba81aaa46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "9322fe15-97e4-4874-b2b3-3276bec9bcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641f75dc3f414893b30942f60c0ec71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.908"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "f3bb4297-87c7-4eff-b2f8-204b78377a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d83e7d10cb454f87c94abf1183f983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 23\n",
       "})"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wro = new_ds.filter(lambda x: x[\"target\"].lower() != x[\"answer_pred\"].lower())\n",
    "wro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "2878a31d-9270-4990-9a90-aad6cac20f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bauble cube fabulous kitakyushu length limnology senescent sequel seventh voluntary willow yucca\n",
      "bauble cube fabulous kitakyushu length limnology sequel senescent seventh voluntary willow yucca\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "index = 22\n",
    "print(wro[index][\"target\"])\n",
    "print(wro[index][\"answer_pred\"])\n",
    "print(wro[index][\"target\"] == wro[index][\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7128692-b878-439f-b22c-18cf5e5810cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# multistep_arithmetic_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "db06fda4-bf8b-4560-9755-a8190abf5a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-multistep_arithmetic_two/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "fb88a68b-a7f5-40a7-a4ec-10f8922e10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "74c7e009-95c8-405d-b634-f2ef48029a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5868388ea9da4fd08f980f52aa56312f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.[]\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "1d207459-3cea-469f-87fb-c83fdf5dd63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-1',\n",
       " '-10',\n",
       " '-100',\n",
       " '-11',\n",
       " '-110',\n",
       " '-114',\n",
       " '-11520',\n",
       " '-13',\n",
       " '-1300',\n",
       " '-1343',\n",
       " '-144',\n",
       " '-147',\n",
       " '-15',\n",
       " '-151',\n",
       " '-160',\n",
       " '-168',\n",
       " '-169',\n",
       " '-17',\n",
       " '-18',\n",
       " '-19',\n",
       " '-196',\n",
       " '-1960',\n",
       " '-1968',\n",
       " '-20',\n",
       " '-21',\n",
       " '-2146',\n",
       " '-217',\n",
       " '-22',\n",
       " '-224',\n",
       " '-23',\n",
       " '-24',\n",
       " '-240',\n",
       " '-25',\n",
       " '-26',\n",
       " '-262',\n",
       " '-264',\n",
       " '-284',\n",
       " '-3',\n",
       " '-30',\n",
       " '-3136',\n",
       " '-32',\n",
       " '-320',\n",
       " '-33',\n",
       " '-330',\n",
       " '-340',\n",
       " '-3400',\n",
       " '-343',\n",
       " '-35',\n",
       " '-36',\n",
       " '-37',\n",
       " '-38',\n",
       " '-3850',\n",
       " '-39',\n",
       " '-391',\n",
       " '-39960',\n",
       " '-4',\n",
       " '-43',\n",
       " '-46',\n",
       " '-48',\n",
       " '-5',\n",
       " '-50',\n",
       " '-51',\n",
       " '-52',\n",
       " '-5453',\n",
       " '-55',\n",
       " '-57',\n",
       " '-6',\n",
       " '-60',\n",
       " '-61',\n",
       " '-658',\n",
       " '-7',\n",
       " '-71',\n",
       " '-76',\n",
       " '-8',\n",
       " '-80',\n",
       " '-81',\n",
       " '-83',\n",
       " '-8304',\n",
       " '-84',\n",
       " '-8840',\n",
       " '-89',\n",
       " '-9',\n",
       " '-90',\n",
       " '-97',\n",
       " '-99',\n",
       " '0',\n",
       " '10',\n",
       " '107',\n",
       " '11',\n",
       " '11050',\n",
       " '113',\n",
       " '1168',\n",
       " '12',\n",
       " '120',\n",
       " '128',\n",
       " '14',\n",
       " '140',\n",
       " '15',\n",
       " '150',\n",
       " '16',\n",
       " '1608',\n",
       " '17',\n",
       " '18',\n",
       " '181',\n",
       " '198',\n",
       " '1980',\n",
       " '2',\n",
       " '20',\n",
       " '21',\n",
       " '211',\n",
       " '216',\n",
       " '220',\n",
       " '2240',\n",
       " '237',\n",
       " '24',\n",
       " '25',\n",
       " '251,472',\n",
       " '26',\n",
       " '2652',\n",
       " '27',\n",
       " '3',\n",
       " '30',\n",
       " '31',\n",
       " '312',\n",
       " '3255',\n",
       " '33',\n",
       " '330',\n",
       " '336',\n",
       " '34',\n",
       " '3420',\n",
       " '343',\n",
       " '346',\n",
       " '35',\n",
       " '36',\n",
       " '360',\n",
       " '365',\n",
       " '37',\n",
       " '38',\n",
       " '38556',\n",
       " '4',\n",
       " '40',\n",
       " '41',\n",
       " '416',\n",
       " '42',\n",
       " '44',\n",
       " '443',\n",
       " '45',\n",
       " '464',\n",
       " '474',\n",
       " '48',\n",
       " '49',\n",
       " '5',\n",
       " '52',\n",
       " '522',\n",
       " '54',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '598',\n",
       " '60',\n",
       " '63',\n",
       " '630',\n",
       " '65',\n",
       " '70',\n",
       " '702',\n",
       " '7056',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '8',\n",
       " '83',\n",
       " '84',\n",
       " '858',\n",
       " '88',\n",
       " '89',\n",
       " '94',\n",
       " '976',\n",
       " 'a numerical value, -80, which is the result of the given expression',\n",
       " 'already obtained in the previous step',\n",
       " 'derived by combining the results from the previous steps',\n",
       " 'the result of the combined expressions',\n",
       " 'the result of the simplified expression'}"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "b47ce643-e877-4e2f-a45b-60f183478a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4651a1bc5b4482a1801373f0ad7bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the result of the simplified expression\n",
      "**Step 1: Break down the expression into smaller parts**\n",
      "The expression can be broken down into two sets of parentheses: `(0 * 3 - -9 + -1)` and `(-5 * -6 - 6 + 8)`.\n",
      "\n",
      "**Step 2: Evaluate the expressions inside the parentheses**\n",
      "For the first set of parentheses, `(0 * 3 - -9 + -1)`, follow the order of operations (PEMDAS):\n",
      "\n",
      "* Multiply 0 and 3: `0 * 3 = 0`\n",
      "* Subtract -9: `0 - (-9) = 0 + 9 = 9`\n",
      "* Add -1: `9 + (-1) = 9 - 1 = 8`\n",
      "\n",
      "So, the first set of parentheses evaluates to `8`.\n",
      "\n",
      "**Step 3: Evaluate the expressions inside the second set of parentheses**\n",
      "For the second set of parentheses, `(-5 * -6 - 6 + 8)`, follow the order of operations (PEMDAS):\n",
      "\n",
      "* Multiply -5 and -6: `-5 * -6 = 30`\n",
      "* Subtract 6: `30 - 6 = 24`\n",
      "* Add 8: `24 + 8 = 32`\n",
      "\n",
      "So, the second set of parentheses evaluates to `32`.\n",
      "\n",
      "**Step 4: Rewrite the original expression with the evaluated parentheses**\n",
      "Substitute the evaluated expressions back into the original expression: `((8) - (32))`\n",
      "\n",
      "**Step 5: Simplify the expression by combining like terms**\n",
      "Combine the constants: `8 - 32 = -24`\n",
      "\n",
      "**Step 6: Write the final answer**\n",
      "================================================================================\n",
      "already obtained in the previous step\n",
      "**Step 1: Identify the core mathematical operation**\n",
      "The core mathematical operation is evaluating an arithmetic expression with multiple operations.\n",
      "\n",
      "**Step 2: Break down the expression into smaller parts**\n",
      "The expressions inside the parentheses are:\n",
      "((-4 * 4 + -1 * 5) and (-6 + 1 - -8 - 6))\n",
      "\n",
      "**Step 3: Evaluate the expressions inside the parentheses**\n",
      "Evaluating the expressions:\n",
      "- (-4 * 4) = -16\n",
      "- (-1 * 5) = -5\n",
      "- (-6 + 1 - -8 - 6) = -6 + 1 + 8 - 6 = -3\n",
      "\n",
      "**Step 4: Simplify the expressions inside the parentheses**\n",
      "Combining like terms:\n",
      "- (-16 + -5) = -21\n",
      "- (-3) remains the same\n",
      "\n",
      "**Step 5: Combine the simplified expressions**\n",
      "Following the order of operations:\n",
      "- Combine -21 and -(-3) (since subtracting a negative is equivalent to adding a positive)\n",
      "- This results in -21 + 3 = -18\n",
      "\n",
      "**Step 6: Perform the final operation**\n",
      "================================================================================\n",
      "derived by combining the results from the previous steps\n",
      "**Step 1: Identify the core mathematical operation**\n",
      "The main mathematical operation is the multiplication of two expressions.\n",
      "\n",
      "**Step 2: Break down the expression into smaller parts**\n",
      "The given expression can be broken down into two main parts:\n",
      "Part 1: (-1 + -7 + -2 - 7)\n",
      "Part 2: (6 - 1 - -1 * 5)\n",
      "\n",
      "**Step 3: Evaluate Part 1**\n",
      "Evaluating Part 1 step-by-step:\n",
      "- Evaluate the sum of -1 and -7: -1 + -7 = -8\n",
      "- Add -2 to the result: -8 + -2 = -10\n",
      "- Subtract 7 from the result: -10 - 7 = -17\n",
      "\n",
      "**Step 4: Evaluate Part 2**\n",
      "Evaluating Part 2 step-by-step:\n",
      "- Evaluate the expression -1 * 5: -1 * 5 = -5\n",
      "- Since there are two negative signs, the subtraction becomes an addition: 6 - 1 + 5 = 10\n",
      "- Subtract 1 from the result is not needed as the correct calculation is 6 - 1 + 5 = 10\n",
      "\n",
      "**Step 5: Multiply Part 1 and Part 2**\n",
      "Multiplying the results of Part 1 and Part 2:\n",
      "-17 * 10 = -170\n",
      "\n",
      "**Step 6: Final evaluation**\n",
      "================================================================================\n",
      "the result of the combined expressions\n",
      "**Step 1: Break down the expression into smaller parts**\n",
      "\n",
      "The innermost parentheses are: (9 + 2 + 3 - -3) and (-5 + 6 - -6 - -9)\n",
      "Separate the two expressions to evaluate them individually.\n",
      "\n",
      "**Step 2: Identify the core mathematical operation**\n",
      "\n",
      "The order of operations for each expression is:\n",
      "1. Evaluate expressions inside parentheses first\n",
      "2. Combine like terms\n",
      "Need to handle negative numbers.\n",
      "\n",
      "**Step 3: Evaluate the first expression**\n",
      "\n",
      "1. Add 9 and 2: 9 + 2 = 11\n",
      "2. Add 3 to the result: 11 + 3 = 14\n",
      "3. Subtract -3 from the result: 14 - (-3) = 14 + 3 = 17\n",
      "The result of the first expression is 17.\n",
      "\n",
      "**Step 4: Evaluate the second expression**\n",
      "\n",
      "1. Add -5 and 6: -5 + 6 = 1\n",
      "2. Subtract -6 from the result: 1 - (-6) = 1 + 6 = 7\n",
      "3. Subtract -9 from the result: 7 - (-9) = 7 + 9 = 16\n",
      "The result of the second expression is 16.\n",
      "\n",
      "**Step 5: Combine the results**\n",
      "\n",
      "Add the results of the two expressions: 17 + 16 = 33\n",
      "The final result is 33.\n",
      "\n",
      "**Step 6: Review the final answer**\n",
      "\n",
      "All steps have been followed correctly.\n",
      "================================================================================\n",
      "a numerical value, -80, which is the result of the given expression\n",
      "To solve the given task, I will follow the step-by-step reasoning plan.\n",
      "\n",
      "**Step 1: Simplify the expression inside the first parentheses**\n",
      "\n",
      "The terms inside the first parentheses are 4, -6, -9, and -7. Combining like terms, we get:\n",
      "4 + (-6) = -2\n",
      "-2 + (-9) = -11\n",
      "-11 + (-7) = -18\n",
      "So, the simplified expression is -18.\n",
      "\n",
      "**Step 2: Simplify the expression inside the second parentheses**\n",
      "\n",
      "The terms inside the second parentheses are 9, -3, and -7 * -8. Evaluating the multiplication, we get:\n",
      "-7 * -8 = 56\n",
      "Now, combining like terms:\n",
      "9 + (-3) = 6\n",
      "6 + 56 = 62\n",
      "So, the simplified expression is 62.\n",
      "\n",
      "**Step 3: Subtract the simplified expressions**\n",
      "\n",
      "Subtracting the second simplified expression from the first, we get:\n",
      "-18 - 62 = -80\n",
      "\n",
      "**Step 4: Evaluate the final expression**\n",
      "\n",
      "There are no remaining arithmetic operations to evaluate. The final result is -80.\n",
      "\n",
      "**Step 5: Verify the final answer**\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    answer = ins[\"answer_pred\"]\n",
    "    \n",
    "    if len(answer.split()) != 1:\n",
    "        print(answer)\n",
    "        print(ins[\"trajectory\"])\n",
    "        print(\"=\"*80)\n",
    "\n",
    "    if answer == \"the result of the simplified expression\":\n",
    "        return {\n",
    "            \"answer_pred\": \"-24\"\n",
    "        }\n",
    "\n",
    "    if answer == \"already obtained in the previous step\":\n",
    "        return {\n",
    "            \"answer_pred\": \"-18\"\n",
    "        }\n",
    "\n",
    "    if answer == \"derived by combining the results from the previous steps\":\n",
    "        return {\n",
    "            \"answer_pred\": \"-170\"\n",
    "        }\n",
    "\n",
    "    if answer == \"the result of the combined expressions\":\n",
    "        return {\n",
    "            \"answer_pred\": \"33\"\n",
    "        }\n",
    "\n",
    "    if answer == \"a numerical value, -80, which is the result of the given expression\":\n",
    "        return {\n",
    "            \"answer_pred\": \"-80\"\n",
    "        }\n",
    "        \n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "    \n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "b9843cfe-fcf8-4966-a4fe-6812b52e296c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7a93c4a67046dfbb3b69c4a7dbd122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "e3927ce3-5a2d-4979-86db-a4a3e44e293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_name = \"sachithgunasekara/self-discover-original-bbh-eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "4c7ba161-9355-4b96-9fad-b9422bf2b65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8917133f08455aaa1f58ca710a512e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))\n",
    "\n",
    "# new_ds.push_to_hub(hub_name, cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6806509c-d4f0-4d03-a70d-3b9622039e6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# navigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "0fdf8fef-dac5-4b7e-b3e0-2016da7df532",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-navigate/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "c475a741-9904-42aa-9d77-9ffa7a36f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "23be1cc7-af76-47a7-8322-e00e9b0bb815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No.', 'Yes.'}"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "cb29e1d6-6135-40e8-a457-15e5d329e06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c711653a8d14a7b8848e5cfc0ae42cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.[]\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "d08e5570-b405-4d7f-a21a-593e606c5b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No', 'Yes'}"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "4bf34fcf-1c2a-4a2e-8024-405372134a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdf5d9236684657b288fbf27b5141cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.948"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "ec1b4d59-34fd-4f16-977e-00ce55877168",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_name = \"sachithgunasekara/self-discover-original-bbh-eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "a1f03c1b-bd57-4515-93fe-21f8fcb91184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ced430d32c64f9ba76e53b303000726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))\n",
    "\n",
    "# new_ds.push_to_hub(hub_name, cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09086bf1-3112-4409-80d7-7f85aac818a5",
   "metadata": {},
   "source": [
    "# object_counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "4dfaae12-2768-4f6c-bdd8-d1223f023783",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/modified/non_self_synthesis/bbh/bbh-object_counting/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "4a45fd17-0b5d-4c23-a70c-aec3a66d8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "204c4832-c0fd-4407-ac8b-286e83a264dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " 'the count from Step 4.',\n",
       " 'verified.'}"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "9c2b34e0-8303-4514-a961-5568ddf4ec2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24760a9af6e549688c25f366f17767d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.[]\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "d2e547b9-ac08-48e2-b247-fb6c2e2c38a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'the count from Step 4',\n",
       " 'verified'}"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "e7dd1525-a971-4d55-8eed-131518803dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6134ee7d1c45409fadab19289e5ef4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the count from Step 4\n",
      "Let's follow the reasoning plan step-by-step to arrive at the correct answer.\n",
      "\n",
      "**Step 1: Identify the essential task**\n",
      "The essential task is to count the total number of objects.\n",
      "\n",
      "**Step 2: Categorize and group objects**\n",
      "The objects can be grouped into categories, such as:\n",
      "\t* Furniture: bed, chair, table, couch\n",
      "\t* Appliances: fridge, toaster, microwave, stoves\n",
      "\t* Vehicles: car\n",
      "\t* Lighting: lamp\n",
      "\n",
      "**Step 3: Create a numbered list**\n",
      "Here is the numbered list of all the objects, grouped by category:\n",
      "\t1. Bed (Furniture)\n",
      "\t2. Chair (Furniture)\n",
      "\t3. Table (Furniture)\n",
      "\t4. Couch (Furniture)\n",
      "\t5. Fridge (Appliances)\n",
      "\t6. Toaster (Appliances)\n",
      "\t7. Microwave (Appliances)\n",
      "\t8. Stove 1 (Appliances)\n",
      "\t9. Stove 2 (Appliances)\n",
      "\t10. Car (Vehicles)\n",
      "\t11. Lamp (Lighting)\n",
      "\n",
      "**Step 4: Count the objects**\n",
      "This is a simple counting problem. Counting the total number of objects in the numbered list, we get: 11\n",
      "\n",
      "**Step 5: Determine the final answer**\n",
      "================================================================================\n",
      "verified\n",
      "**Step 1: Define what constitutes a \"vegetable\" in this context**\n",
      "\n",
      "In this context, a vegetable is any edible part of a plant, such as the leaves (like lettuce), stems (like celery), roots (like carrots), tubers (like potatoes and yams), or flower heads (like broccoli). Fruits, seeds, and grains are not considered vegetables. Garlic and onion are considered vegetables as they are edible bulbs.\n",
      "\n",
      "**Step 2: Categorize the given items into groups**\n",
      "\n",
      "The items can be categorized into the following groups:\n",
      "\n",
      "* Root vegetables: carrots, potato, yam\n",
      "* Leafy greens: lettuce, cabbage\n",
      "* Cruciferous vegetables: broccoli\n",
      "* Allium vegetables: garlic, onion\n",
      "* Stems: celery\n",
      "\n",
      "**Step 3: Count the items in each category**\n",
      "\n",
      "* Root vegetables: 5 carrots + 1 potato + 1 yam = 7\n",
      "* Leafy greens: 1 lettuce + 1 cabbage = 2\n",
      "* Cruciferous vegetables: 4 broccoli\n",
      "* Allium vegetables: 2 garlic + 1 onion = 3\n",
      "* Stems: 1 celery\n",
      "\n",
      "**Step 4: Address any nuances or ambiguities**\n",
      "\n",
      "In this case, there are no nuances or ambiguities that affect the counting process. Garlic and onion are considered vegetables, and each item is clearly categorized.\n",
      "\n",
      "**Step 5: Calculate the total number of vegetables**\n",
      "\n",
      "Adding up the number of items in each category: 7 + 2 + 4 + 3 + 1 = 17\n",
      "\n",
      "**Step 6: Review and verify the answer**\n",
      "\n",
      "Reviewing the categorization and counting process, all items were accounted for, and the definition of a vegetable was consistently applied throughout the process.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    corr_ls = [\"the count from Step 4\", \"verified\"]\n",
    "\n",
    "    for x in corr_ls:\n",
    "        if x in ins[\"answer_pred\"]:\n",
    "            print(ins[\"answer_pred\"])\n",
    "            print(ins[\"trajectory\"])\n",
    "            print(\"=\"*80)\n",
    "    if corr_ls[0] in ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"11\"\n",
    "        }\n",
    "\n",
    "    if corr_ls[1] in ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"17\"\n",
    "        }\n",
    "        \n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "    \n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "204dd815-a8fe-4b8d-8aef-3d5c760bb074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65972bde63164ecc822fcbcdc09405c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "ddb7add2-4f7b-4cf6-b7cb-690c3f4cb186",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_name = \"sachithgunasekara/self-discover-original-bbh-eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "fca4ef1b-9bed-4b13-9e02-60cb4956834c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63e02d70f9c4a46a465e34f89c80b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))\n",
    "\n",
    "# new_ds.push_to_hub(hub_name, cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30b469-c6cd-48b2-a6be-e6e0f4c41006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
