{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getenv(\"NVIDIA_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAITAM4DASIAAhEBAxEB/8QAHQABAAMBAQEBAQEAAAAAAAAAAAUGBwQIAwIBCf/EAFAQAAEDAwEDBQkMBwYFBQEAAAEAAgMEBQYRBxIhExUxQZQIFBYXIlFW0tMjMjZUVWFxdHWTs9E3gZGVsrTUNUJSYmOhCSUzorEkNIKjweH/xAAbAQEAAwEBAQEAAAAAAAAAAAAAAQIDBQQGB//EADsRAQABAgEIBwYEBQUAAAAAAAABAhEDEhQhMVFScZEEE0FhYqHRBTOSscHSFSMy4SJCQ2OBU4Ky8PH/2gAMAwEAAhEDEQA/AP8AVNERAREQEREBEUXfb061sghp4DWXGqcY6amDt0OIGpc92h3I2ji52h6gA5zmtNqaZqm0CTc4MaXOIDQNST1KOkyWzxOLX3WhY4dIdUMB/wDKi2YPTXF7ajIJTfarUO5OdulLGR1RwaloGvW7ed0auOgUhHiNiiYGMstvYwdDW0sYA/2W1sKNczPCPX0TofrwqsvyxQdpZ+aeFVl+WKDtLPzTwVsvyPQdmZ+SeCtl+R6DszPyT8nv8k6DwqsvyxQdpZ+aeFVl+WKDtLPzTwVsvyPQdmZ+SeCtl+R6DszPyT8nv8jQeFVl+WKDtLPzTwqsvyxQdpZ+aeCtl+R6DszPyTwVsvyPQdmZ+Sfk9/kaH1p7/bKyQMguNJO8nQNjna4n9QK71DVOF4/WRGOosVsnjOurJKONw49PAhcHgvPjgE+PTSshZxfaJpS+nlHWIy7UxO826Qzzt46hk4VWimZie/Vz/ZGhaEXFaLrBeqCOqgD2tdq10crd18bwdHMcOpwIII+ZdqwmJpm0oERFAIiICIiAiIgIiICIiAqvjel1yXILpJo4wTi2U3+SNjWuf9BMjn66dIYzXo0FoVYwwd6VuSUDtRJDc5JhqNN5krWyhw841c4fS0+ZejD/AEVzGu3ldMapWdERedDku92orBaq253GpiorfRQvqKipmdusijY0uc9x6gACSfmWOZt3V+JWTZNf82x41WQMthhYKZ9BV02+6U+5uO/DqGEauD9N06aa6kLT8/oqC5YLkNJdLVUX22z2+eOptdIzemq4zG4OijGo1c4atHEcSOI6V5ZlsWeZlsN2r4lbrdk9yxqloaPwYbllD3pdZHMdyk9Lo4NdK1gjYGPe3Ul2m8/TVB6Eu23jDLFi1tyG4V1wo7dcpXwUrZbNWipkewneHe/I8sNN0nUsA049BBX5r+6B2fW3GseyCbJIDZ8glfBbKqGGWUVMrWvc6MBjCQ/yHN3SAS4boG8QFnG07PL7mfgTW0dp2gWXBqiarZfIbTaqimvHKtjjNMwsYOXjhc4y7z49OLWguAOpoGyzBL9TTbMqWsxa/wBHDatoV7rZmXWnklkp6eWmqZYJZZfKa4EyxjlN4gyajeLgUGxM7p/H5drdow2Ohu3e1ytLbhFXOs9eH8q+dkUcbojBrGzRxc6R5DWnQO3StnWH5zUXDCe6SseWSY9erxYq3GZrIaiy0L6x1PU99xyt5VrASxhbr5Z4ajitwQEREFYpdLRtAqaRmjYLtRmu3Br/ANaFzI5HebymyQD/AOHzqzqsVDe/dpNEWg7tvtcxkOnDWeWIM4/RTycPoVnXoxf5ZnXbT9PKyZERF50CIiAiIgIiICIiAiIgKAvdvqKO5x3y3Q8vUxxchVUwOjqmAEuAb1coxxcW68DvPadN7ebPor0VTRN0q9cLdjW0/HpaK40VFkFolc3lqKugEjQ9pDg2SJ41a5p0O64Ag9QVYHc2bJxrps3xYa9P/KIPVVuu2H2u71ffkkL6ev0A79o5n08xA6A57CC4Dj5LtRxPDiVw+BEzdAzJ78xo6B3xG7/d0ZP+61ycKrVVbjHp6QaEZY9hGzjGbtTXS0YJj1suVM7fgq6S2wxyxO001a4N1B0J6Fe1V/Amo9Kr999D7JPAmo9Kr999D7JOrw9/yktG1aEWV7V7fdcM2b5FfLdlN4NdQUb54RUSwmPeA4b3uY4frCtngTUelV+++h9knV4e/wCUlo2rQs4k7m7ZTK9z37OMWc9xJLjaYCSfP71T/gTUelV+++h9kngTUelV+++h9knV4e/5SWjar7u5s2UOcS7ZviznHiSbTASf+1W643mgxmClt9PE19UYxHR2um0D3tbwAa3+6wcNXHRrR0lcPgM6QBs+R36dnW3vtsev642NP7CpWy43bceZIKClbE+XQyzOc6SWUjoL5HEud+slLYVOmZv/AN2/saHyxyzS2yKpqKx7JbnXScvVSR67gduhoYzXjuNa0AefidAXFTCIsaqprm8oERFUEREBERAREQEREBERAREQEREBERBnvdBkDYnmZcSG82y6kfR9I/8AK0JZ73QWviTzPTQHm2X32mnR168P2rQkBERAREQEREBERAREQEREBERAREQEREBERAREQEREGed0KNdiOaguDRzZLxcNQOC0NZ53QuniRzXXgObJega9XmWhoCIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAirl9yiopa82200cddcGMbLMaiYxQwMcSG7zg1xLjoSGgdA1Jbq3WL59zD4hY+1zezXqp6PXVF9EcZhNl3RUjn3MPiFj7XN7NOfcw+IWPtc3s1bNa9sc4LMK7u3uiqzYxizLDNh77vacmopaaO7srxEIJgfKjdGYna+SWuB146uGnk8dX7mvbbVd0Fs1bmE+My4vTz1csFLTy1XfHLxMDRyoduM0Bfvt00PvNdePCrbf8AZXeO6D2cVeJXmms9Gx8sdRT1sNRK6SmlYeD2gx6HUFzSPM4q34bb79geKWnHbPabFTWy2UzKWnjFXLqGNGmp9y4k9JPWSSma17Y5wWaeipHPuYfELH2ub2ac+5h8Qsfa5vZpmte2OcFl3RUkX3MAeNvshHmFZMNf/qU9j2Q89CognpzR3ClIE9Nvb4Adruva7QbzHaHQ6DoIIBBCzrwK6Iyptbum5ZMIiLzoEREBERAREQEREBERAREQEREFCt51zXLteqopwPo72jP/AOlTShLd8Ncv+s0/8tGptdev+XhT8oTIiIs0CKHteXWm9X+92Sjq+WudldC2vg5N7eRMrOUj8ogNdq3j5JOnXoVMKARfxzgxpc4hrQNSSdAAuOzXqgyK101ztdZDcLfVMEkFVTPD45WHoc1w4EHzhSO1RmPnTaPdh57TSa/P7tUf/wB/aVJqMx/9I92+yaX8aoVv6dfD6wtHauyIi5SoiIgIiICIiAiIgIiICIiAiIgoNu+GuX/Waf8Alo1NqEt3w1y/6zT/AMtGptdev+XhT/xhMvPW1mS9YdtZhyrJbpkcezvWggpp8fuRghtlRy268VtMNOWilc+Nu/5RaCRoNQ4UimO1fa/cs3vOPV8lDXWy/VtptzvCqWjp6DveTdjbNQNpHxzagB7uUeS4P4Fg009B5HsRwrLsqjyK8WXv66sdC7efVTCGQxHWIvhDxG8tPEbzTovhe9geBZDlcmSVtga67zSRyzyw1U8MdQ+PTcdLEx4jlcNBoXtJ4BeeaZQxbJs4vezmfukcjoWQ+EFBR2eRpY3fjildQtaZACOLWEl3EcQ3ium2Wrars2pqzLmVJr7JR2Ovra2mr8tmvff8jKZ0lO+Fj6WIREyNaDybg0tedG8At5qNmeMVeU3DI5rPBLd7jQG11szi4sqqYke5yx67j+jTVzSQNQDoSFF4NsOwnZvXyVmPWY0U76d1KDJWT1DY4S4OMUbZXubGwlrTusAHAcOCZMik7Ndm8l52dW/JrlnWVXy432x8vWOF4kZSvdPDvEwxM0bDulx3DHukaDiSvr3HWN01l7n/AA6rgrLhUvuNsp5pGVlfLURxODdN2Jj3FsTf8rAB8ytuJbBsFwS/NvFhsXN1ZGZDE2OrndBBymu/yUDnmOPXU+8aOlSeC7KsX2aPuBxq2utbK54fNAyqmfC0hznaRxveWRDV7jowNHHoUxGmBbFGY/8ApHu32TS/jVCk1GY/+ke7fZNL+NULX+nXw+sLR2rsiIuUqIiICIiAiIgIiICIiAiIgIiIKDbvhrl/1mn/AJaNTa5L3Zrjbr1UXW10ouMdY1jamj5URyBzRoJGFxDT5OgLSR0Ag9IUfztfvQy69qovbrr6MSIqpmNURpmI1REdsrWum0UJztfvQy69qovbpztfvQy69qovbpkeKPij1LJtFU8jzevxOxV15uuKXWlt1FEZp5uXpH7jB0ndbMSf1BSPO1+9DLr2qi9umR4o+KPUsm0UJztfvQy69qovbpztfvQy69qovbpkeKPij1LJtRmP/pHu32TS/jVC+DbpfnHTwOubfndVUen+05U1i1jq6WrrbrcgyOvrGRxCnieXtghYXFrd7hq8l7y4gAcQ3ju7xrXbDw6rzGmLaJie2NhqWNERcpUREQEREBERAREQEREBERAREQEREBERBn+38b2xbMhprrbpeGmvV5tD/wCCtAWe90G3f2J5m3Qu1tso0aNSeHmWhICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIM87oUgbEc1JOg5sl1OmvV5utaGs+7oHeOxTM9wvDubZdDGNXa6dXzrQUBERAREQEREBERAREQEREBERAREQEREBERARfCur6a10ktVWVEVJSxDeknneGMYPOXHgFXnbUcPaSDlFoBHAjv2P81rRhYmJpopmeEJiJnUtCKreNLDvSm0dtj/ADTxpYd6U2jtsf5q+b425PKU5M7FL7pjOMaseyrK7TdMgtVvudTa5Hw0NXWxxTytOoBaxzg5wJa4cOsHzLSMcyuyZhRSVlhvFvvdJHIYX1FuqmVEbZAASwuYSA7RzTp06EedeNv+IbguN7ZNndBkGN3e2XHK7DJoympalj5qqleQHxtAOri12jgPNv8AnWt9yza8K2EbFbFjLsms4ubmd+3JwrY/KqpAC/8Avf3QGs+hgTN8bcnlJkzseg0VW8aWHelNo7bH+aeNLDvSm0dtj/NM3xtyeUmTOxaUVZj2nYhM8NZk9oLiQP8A3sfWdB1+fQKytcHtDmkOaRqCOgrOvDrw/wBdMxxRMTGt/URFmgREQEREBERAREQEREBERAREQUi/Ftzz6GjqBytPQ0DKuKJw1aJXyPZv6dBIazQEjhvO06SpRRNf+k2r+x6f8adSy6s6KaY7oTIiIqoEREBERB/HND2lrgCDwIPWuTZ+/vaa/wBrj8mjoKxraaLqiY+GN5Y3/KHOcQOAAIAAAC7FwYL8IMv+uw/ysSVacKvhHzhaNUrkiIuYqIiICIiAiIgIiICIiAiIgIiIKNX/AKTav7Hp/wAadSyia/8ASbV/Y9P+NOpZdarVTwj5Jln22DaXc9mduoq2is9ruFNK57Z6m8X+C0wQEabrd+Rrt5ztXaADTyTqRwVZi7pKC/Ybg9yxfHqi+3/MOW5vsr6pkAjEGoqXyz6Oa1kZGm8A7eLm6A6ru2nbM8ive0nHcwsEdhukltt9Tb+b8jMohp3Svjd3zDuMd7oAwsIIGrTpvBUnHe59zjCMewSps1zsFRlWI1V0iYKoTR0Nxoq2YyOD91pfDIDuEAb4BaeJBWEzVdD9bPNqeYW+x7U7zcrOypuNBljqY2y6ZDHDSW6HvSmJ0qZAWtiDiXANZqTJ70ElSdB3VDLvs4GQ27HIrhdI8lp8YmttNd4pYDPM+NrXxVTWlkjC2VjgdG66kHTRQkvc+5zXRVt1uEmL115fmYyhtollnNtqI+8mU4ilcYy4PY5pe1264atadBro2t7QdneX4Fi9ZUVstgluN/2iWO7UTaISsp4Z3SwRmKRpGu410TPKadXAuO6w6BVvVA0DM9uWUW/Fto9omxyHHM7seOy3uiay5NqqWam0e01EcphGro3McTG+MakNGujt4aLsevmRZFs9s1fk9vpqC4zU0Lx3rWmqE7DEwiVxMUe65xLtWAED/EdeFFptjOUZpc82vedV9ppbpfMdkxeipbFyssFFSv33Pe58jWukkc94PvWgBgHHXVXnZHacsx/DKG05c2zmst8MVJBNZpZXsmijja0PeJGNLXEgndGoHnKvF76RdVwYL8IMv+uw/wArEu9cGC/CDL/rsP8AKxLSfd18PrC0apXJERctUREQEREBERAREQEREBERAREQUav/AEm1f2PT/jTqWUXf92155FW1J5KmraBlJHM46M5Vkj37hPQCQ8kanjunToUourOmmme6EyIiKqBERAREQFwYL8IMv+uw/wArEu572xsLnuDWjiS46ALk2fs75lv11j8qjuFY19NJ1TRshjZyjf8AKXNdoeIIAcCQ4JVowq57o+cLRqlb0RFzFRERAREQEREBERAREQEREBERB8K2ip7lSyU1XTxVVNIN18MzA9jh5iDwKrztluGucXHFLKSTqTzfF6qtCLWjFxMPRRVMcJTeYVbxV4Z6J2T93xeqnirwz0Tsn7vi9VWlFfOMbfnnJedrHduWzvF7Vshy2rocetVBWQ2+R8VTT0cUckbtODmu0Gh+fUK8+KvDPROyfu+L1VD90CSNimZlrt1wtsuh48OHzcf2LQUzjG355yXnaq3irwz0Tsn7vi9VPFXhnonZP3fF6qtKJnGNvzzkvO1WYdmWIU8gfFi1mY8cQW0EQPn/AMPnVlADQABoB0AL+os68SvE/XMzxLzIiIs0CIiAiIgIiICIiAiIgIiICIiAiIgIiIM97oMF2xPMwGcoTbZfI4+Vw6OHFaEs87oRpfsSzRoa55NtlG63pPDqWhoCIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIM97oIA7E8zBDSDbZeDtdOjr04/sWhLyV/xC9q2ebLNntO6xW+z12J3pj7ZcpaynldUU0rhqwtc2VrQHNBA1adC08eIWudy/tAzTansgtmV5xb7Za7ldHvnpaa1wyxMFLwEbnNke87ziHO1103S3h5w1lERAREQEREBERAREQEREBERByXa5w2W1VlwqN7vekhfPJuDV261pcdB1nQKmiLI7tGKmov9RZ5JdHd52+CBzIRx8kulieXEDTV3DUjUAA6KV2p/oxy/wCx6z8F6+q6GBEU4eXaJmZnXF9VtvFbVF0JzPffTS8dmof6dOZ776aXjs1D/TqbRb9Z4Y+Gn0RdCcz3300vHZqH+nTme++ml47NQ/06m0TrPDHw0+hdCcz3300vHZqH+nTme++ml47NQ/06m0TrPDHw0+hdCcz3300vHZqH+nTme++ml47NQ/06m0TrPDHw0+hdRc82VN2m4tW45k2R3W62WsDRPSvho2b264OGjmwBwIIHEEKYoMZutroaaipMuutPSU0bYYYY6WhDY2NADWgd78AAAFYkTrPDHw0+hdCcz3300vHZqH+nTme++ml47NQ/06m0TrPDHw0+hdCcz3300vHZqH+nTme++ml47NQ/06m0TrPDHw0+hdCcz3300vHZqH+nTme++ml47NQ/06m0TrPDHw0+hdCcz3300vHZqH+nTme++ml47NQ/06m0TrPDHw0+hdCi5XfE3R1Vbd5b3bXSsinbVwxMliD3BokY6JjQQCRq0t6NSCNNDfVnW0D4JV30xfitWirzdIiJpprtaZvGjRqt6pnVcREXhVEREFX2p/oxy/7HrPwXr6r5bU/0Y5f9j1n4L19V0cL3McZ+ULdgig86+BGQ/Z1R+E5eY9m2KWvDqXuaMgtFOaO8X6lZS3arEj3SV0clqklLZSSd8NexhaDwbugN0A0SZsq9KbPM8t+0vEqXIbXDUwUVTLPEyOra1sgMUz4XahrnDQujcRx6COjoVkWNdyPWQT7EbfTRzRyVFHcbnDUwtcC+GTv+oduvHS06EHQ9RB618e6rtcV8xjCLdO+WOCrzSzwSOgkMbw10+h3XNILToTxB1HUov/DcbWi8l7WsHt8O2PGMApxjGN4SLFPcLfbr7RSvttVXmpPL6Rx1EAdK1hY4bxdoHvIGvFfC8YtR0mLYJs9r6/Gc5iu9dc6+23e6Szi0W6mh3S6BjBUOdOWmQtY10vkhp4+Qoyh67ReJsax8Z5sPxuGfIcfvcON5NdoaayXu4Pit17p45JWsibIXud7mxzXxFxkDQG66jip3Ga/B9sOZYrHk9Ey34EMIhrbDY7zVltO2YVEkdQ8uLtJJI2MiAcSSGu3hpvaplD14onIcg8H22482XC59+VsVFpb4OVMHKHTlpeI3Ym9LncdB1LyJsrs1JtMyPZRQZLHLf7FzTkkdGLhI94raKKvgbSmUE+6t5MMID9Qd1jukAr70dopDieAMkhE78b2tz2a1TTEvkpqQVswETXHU7ujGDTzMaOpMoeyl/HODGlziGtA1JJ0AC8WXvFLXSbLdp2cxUxblln2gVj7fdeUfy1KBdowWRnXyGOD37zRoHb5JBPFfLadiLM+zvaNj1VZZr9nlTfqMWS+mdjqK3UJbTuMDyX6R7reWL4d0mTlWnR28CmX3D2yiAaBeV8hxzZzfNtm2qbaA63Rw0dBapYZ62oEUlM3vWTelh8oFrwQ3RzeOug14q0zYehH55b49o0OFmGp50ltT7w2YNbyAhZMyItJ3t7f3ng6bummvHqVkXknZBl9woMw2c3vL5ZpLtPsunkInP/qKxzKmGTdaHcXymNocR0niT1qv7He9bPtj2SXq0eDeP0+Z0dfLPZbJVzz1LoDSmaLvyWSVwmka5rfK3GkODxq5Vyx7WReKsFxS12LZPsfzShpzBlNRmdPQzXQSPM0lNLXzQPgLif8ApcnoNz3o0101XtVWpm4ru0D4JV30xfitWirOtoHwSrvpi/FatFUdI91Rxn5UrdgiIueqIiIKvtT/AEY5f9j1n4L19V89qDDJs0y1reLnWirA+5ev2CHAEHUHoIXRwvcxxn5Qt2PzPBFVQSQzRsmhkaWPjkaHNc0jQgg9II6lHR4rZYYbRDHZ6BkVo05tjbSsDaLRhjHIjT3PRhLfJ08kkdClEUqqffNnj6mofPjt9qcJmqJXz1z7LQUJdXSuDQHzGaCQlwDdARoeJ110Gn8suz6oglByPI63NYo5Y6ilhvVDQhtLPG7eZNHyNPGQ8HoJJ06tFcUSwickxGxZlQtosgstuvtG14kbT3KljqIw4dDg14I1+dc1y2f4vebLSWe4Y3aK600jg6noKmhikghI6CyNzS1pGp6B1qfRLCs3DZhht2o5KSuxKx1lLJUd9vgqLbDIx0261vKlpboX7rWje6dGgdQXRfMCxjJ7dSW+8Y5abtQUene1LXUMU0UGg0G41zSG6AAcPMp5EtAj24/a2VtFWNttG2rooXU1LUCBgkgidu70bHaatadxmrRoDujzBc4w6wNiZGLHbRGyuNzawUkejasuLjUAacJS5xO/77Uk68VMIgh5MOsE1trbdJY7a+31tQ6rqqR1JGYqiZzw90kjNNHPLwHFxBJIB6VjW1TuVm7VMou1fWXiy09Dc9wSE4rSSXOBrWtbpDXEh7T5Ooc5ri3XgdAAN9RRMROsZ9Ns3yZ0rzBtTyWmhLiWQtorW8Rt6mhz6QuOg4auJJ6ySoy0dz7Yxm1+yTJmUOaVdyjoGxPvNqgfLTvp4jGZA4N3d55IcdxjANOA82qIloHBXWG2XOsoKust1JV1VA8yUk88DXvpnEaF0biNWEjhqNOCirds0xC0T8vQYrZKKbvkVnKU9uhjdy4BAl1DR5YDneV0+UePFWRFNhDx4dYIbbRW6Ox21lvoqhtXS0jaSMRU8zXl7ZI2aaNeHkuDgAQST0qYREFd2gfBKu+mL8Vq0VZ3n41xOsA6S6ID5zyrFoir0j3VHGflSt2CIi56oiIg+c8EdVBJDMxssUjSx7HjUOaRoQR5lTziV/trBT2u70UlFGA2FtxpZJJo2joaZGyDf0GgBI3tBxLiSVdEW2Hi1Yf6fVN7KTzDmHynY+wze2TmHMPlOx9hm9srsi2zrE2RygupPMOYfKdj7DN7ZOYcw+U7H2Gb2yuyJnWJsjlBdSeYcw+U7H2Gb2ycw5h8p2PsM3tldkTOsTZHKC6k8w5h8p2PsM3tk5hzD5TsfYZvbK7ImdYmyOUF2U5/XZdgmF3nIX1NlrW22mfUGnZSTNMm6OgHlTp+xWDmHMPlOx9hm9suPuhHBmxLNHEbwFtlOnDjw+fULQkzrE2RygupPMOYfKdj7DN7ZOYcw+U7H2Gb2yuyJnWJsjlBdSeYcw+U7H2Gb2ycw5h8p2PsM3tldkTOsTZHKC6k8w5h8p2PsM3tk5hzD5TsfYZvbK7ImdYmyOUF1J5hzD5TsfYZvbJzDmHynY+wze2V2RM6xNkcoLqhRYhc6yqhkv1xpaqmgeJWUlDTOhY97SC0yOdI4uAIBDRoNQNdVb0RYYmLViTeovcREWSBERAREQEREBERAREQEREGe90Gd3YnmZD+TItsvl6kacOngtCWe90I8x7Es0eOJbbZT0kdXzLQkBERAREQEREBERAREQEREBERAREQEREBERAREQEREGed0LoNiOaagEc2y672unR16cVoawHuutumFbN8AvGNZDepLXer1bJTb4+8qmRsx13eEscbmAg9ILgRqDpxC03ZZtexPbVjkt+wy6OvFpiqXUjqk0s1P7q1rXOaGysYToHt4gacSNdQdAuKIiAiIgIiICIiAiIgIiICq1btBpYaqWGittyvAicWPmooW8kHDgWh73NDtDwO7qAQQeIIEzkNRJS2C5zxOLJY6WV7HDpBDCQVWMViZBi9ojjbusZRwtaB1DcC9mDh0zTNdcX7E977+MST0Wvv3dP7ZPGJJ6LX37un9su1Fvk4W55yXjY4vGJJ6LX37un9snjEk9Fr793T+2XaiZOFuecl42OLxiSei19+7p/bJ4xJPRa+/d0/tl2omThbnnJeNji8Yknotffu6f2yeMST0Wvv3dP7ZdqJk4W55yXjY4vGJJ6LX37un9snjEk9Fr793T+2XaiZOFuecl42PPndh7NJO6Q2YNtNBjV0pckt9Q2qttVVshbG0nRskbnCQkNc3jwB4satB2M0lHsb2ZY/iFuxa+OittMGSTCKActMfKkkPu3955cfmGg6loSJk4W55yXjY4vGJJ6LX37un9snjEk9Fr793T+2XaiZOFuecl42OLxiSei19+7p/bJ4xJPRa+/d0/tl2omThbnnJeNji8Yknotffu6f2yeMST0Wvv3dP7ZdqJk4W55yXjY4vGJJ6LX37un9snjEk9Fr793T+2XaiZOFuecl42OLxiSei19+7p/bJ4xJPRa+/d0/tl2omThbnnJeNj92bM6S7VraKWlrLZWPaXRw10YYZQAC7dc0lriNeIB169NAVYFn2Yu5GitkzR7pHd7cGu82/VxRu/a17h+taCvPj4dNMRXTqm/l/wCk7UXlXwYvH1Ob+AqvY18HLV9Ui/gCsOVfBi8fU5v4Cq9jXwctX1SL+ALbB9zPH6HYkkXyqxO6lmFM6NlSWO5J0rS5gfpwLgCCRrpqAR9K8jbLMivGz7A8v2jXWhs2Q5re8jmsVvmhhmhmmqH3B9OIpZXyP0p2ubGWMaBusZp5ROqTNkPXyLyttyz7LKfZ7tNwTNorNNcZcPnvVDcLFHLFDJE14ilifHK5zg9rnxkEOIcHdAI0V4lr4bV3S9srahxbT02zupmkcBro1tZASf2BRlDcUXnqxbcs7fasIy+82yw02G5jX09DSUlNyxr6BtVqKSWV5dycoJ3N9rWs03+BOhXwtPdUVUMOB0V6tlO29Vt0qrbk7aRrxFauRqO8xJxcS1r6mWm0LifJe7rGoZUD0YiomyLO6/aPaL1ep4aaK0m8VdJZ3wNcHT0kL+SEryXHUukZKRoAN3d4dZjttu0DI8GOFUuMUdurK/IL/HZ3C57/ACcbHwTyGQFhB1aYmnr1AI4Egib6LjTEXnjN9u+WYxlcWGQPtU1/oKCOuut0jx26VtKTK+QRRR09KZHxndZqXySaf4Q7iG/q77fcnk2fYld4m2TEb5dHVUU9qyC3XCpqZnwv3Aaalha2dzHAF+85urWuZqCSoyoHoVF5pre6cyG5YJs2v1DTWTGabJRVR3C85AyeS30NRC/k2wksLCzlXtfuukIADeIJ4K33DaNn2S5tc8WwyDGmVlgtlJV3auuonlgnqahrnRwU4jc0hu7GSZHF2m83ySmVA2dF55xfb1mG1a843QYhR2O0C64wb5PJeo5qg0s7Kk08sIbG9m+N8aA6t0AJ4+9XFDtNue0N+wq/V9otDYLne6qlqadwndNSV0MNXG6WB7ZGt3PcZBuyMfweOsaplQPSaLzlY9vGeTY5YMwuNFjvgxXZKcfno6aOcVbWGufRtqA8vLBo8NJj3XajUhw13R88g2+5yX116tFNj1PitHmMeJvp6qKaa4uIqmU8k43ZGs1LnHdj013SHb3UmVA9IoiwW77UtpVVetpz8fp8YkteF1TWMo66Co75rmCjiqHs5Vsm7G7yyGu3HDiAQNNTaZsN6ReftluYwZZtfzXKqIx0tNcsMsNzh79fusibI2rkbyjuoAEan5iubZd3Rl8yTPBjt1msN5p6201NxobpYKGtp6cPgcwOj3qgbs7CJARLE7TyeIGoVcqB6KReecB2451cbfsrv+SUePNsWcSMoxT2yOdtTSTvppJo3773lrmOMLtWboLN4DefpqfQymJuIDNv7LoPti1/z0C0JZ7m39l0H2xa/wCegWhKvSPd08Z+i3Yi8q+DF4+pzfwFV7Gvg5avqkX8AVhyr4MXj6nN/AVXsa+Dlq+qRfwBWwfczx+iOxJLJY+5+pX7KrlhlRepjJPd6i9Ut0poBHLSVD6x1XE5rSXAmN5aOJ8oA8Brw1pFNroYtP3OlTlbMqqc4yyTIrxe7G/Ho6ujoG0MVFSOcXu5OLffq9z91xc5x13GgAAaKXpdjVyGT4nkNblPft0tlpmsl1LrcxsV2pXua/Tc3/cXBzGneaTrxGmhWpIoyYGIY93N9dbJMWtVxzSe7YTitayvtFjdb2RzMfFr3u2apDyZWxa+SAxupa3UnRTM/c541U3LabWSbxkzuFkNVo3TvUNh3NY+PBxfrKTw8rTzArVkTJgZ1beV2M4ljeKWTD77k9FbqCKmbU2rvNrQWNDSXieojO84guOgI49K47haK7a9c8Yra2yXnDPBe9RXdkd3ipZe/vcJ4jGwwVMm5pyoJc75gAdSRqKJYZjmeyK63DPRmeIZWcTvs9C23V4mt7a6mrIWOLoy6MvYWyMLnaPDug6EEL4X3Y/f63IMcyS2Zt3llFutMlnrLlV2mKobWwvcx7niIOY2KTfjBBGo46FpC1VEtAxCj7n7JbFszpMIsu0COC1xmviqHXCxRVZq4KmV0gbIDI0b7C94Dm6NO9xZwC/dP3O1yxF1G/A82nxibmSksddJV29lf31HTMcyCYAvZuTNa9w3uLdCPJ4LbETJgZds92C27Zrk9kuFpuEpoLVjfg9HRzR70khNQJ3VDpNffOdrq0N6XE6joXDjvc/cwWXZ/b+fuX8E73WXnlO893vrlzVHk9OUO5u99e+8rXc6Brw19EyYGQQdz9yGy214dz9vd45C2/d+95+/0uLq3ktzlOHvtze3j0b2nUsVybGcisO3K8X7HcYrb7e5b2yogp7ph0jaN4Jawysr2VIgZux72kpjEnDiCTqfZKKJpiRnr9qd7Y9zRsszJ4B03mvteh+fjWrKLdsszjOsu2txw5BXYJj9/uMDainms7Jaiphdb6dkhgnL91p99GXNEgBadDqNV6ZRTMX1jIK/ucrfJcriy3Xee2Y7dMWZilfaGQteXwRxyRwSRyk6sexsrh0ODuHALlx/YLkFDk+MXm8Z0y7OsNuqbRBSw2ZlNE6mlia3oEhIk3o4nF2paQzQMbrqtpRMmBk1r2Dc24Xsrx/nzlPAatp6zvjvTTv3kqeaHd3d/wBz15be11dpu6aHXUayiKYiwgM2/sug+2LX/PQLQlnubf2XQfbFr/noFoSp0j3dPGfot2Oe40bbjb6mkeS1k8TonEdQcCP/ANWeUOQRYxQUtsvUdRR1tJE2FzhTSPil3QBvse1paQdNdOka6EAhaWixwsaMOJpqi8cvVETtZ34f2P41L2Wb1E8P7H8al7LN6i0RFvnGFuTzj7U6Gd+H9j+NS9lm9RPD+x/GpeyzeotERM4wtyecfaaGd+H9j+NS9lm9RPD+x/GpeyzeotERM4wtyecfaaGd+H9j+NS9lm9RPD+x/GpeyzeotERM4wtyecfaaGd+H9j+NS9lm9RPD+x/GpeyzeotERM4wtyecfaaGbVW0nHaKnknqLgYIIxvPllp5WtaPOSW6BfXw/sfxqXss3qL+90KAdiOah2u7zZLrp9C0NM4wtyecfaaGd+H9j+NS9lm9RPD+x/GpeyzeotERM4wtyecfaaGd+H9j+NS9lm9RPD+x/GpeyzeotERM4wtyecfaaGd+H9j+NS9lm9RPD+x/GpeyzeotERM4wtyecfaaGd+H9j+NS9lm9RPD+x/GpeyzeotERM4wtyecfaaGd+H9j+NS9lm9RPD+x/GpeyzeotERM4wtyecfaaGdPmGbz0FJb453UkNZBWVNXLA+KNrYZGSta0uaN9znNaNB0DeJIIAOioi82Li9ZaIi0QiZERFggREQEREBERAREQEREGe90F+hPM9QD/y2XgSB1fPw/atCWe90GQNiWaFxIAtsupB0PR59CtCQEREBERAREQEREBERAREQEREBERAREQEREBERAREQZ53QuniQzXXTTmyX32unR8y0NZ53QgDtiOaA9Btkv8AeDerznoWhoCIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiyTPNrVSaqa2Y3NHEInGOe5uYHlrwdC2Jp8kkHpc4EdWh4kZnVuqbi8yVtxuFdIddXVFZI79g3tAPmAAX0HRvY+LjURXXOTE806I1vU6LyfzZB/q/fP/ADTmyD/V++f+a9n4D/d8v3ReEB/xK8YzKm2fUGZ4rkt9ttvoT3jerbb7jPFTywSO9zldExwaSHncJI1Iezqatk7j3FMsxfYVZZM2v12v2RXYm6TvvFZJUy0zZGt5OEOkcSAGNaS3qc56zWqsVFW074KiJ08Eg0fHLI5zXDzEE6FfXmyD/V++f+afgP8Ad8v3Lw9YIvJ/NkH+r98/805tgHXL98/80/Af7vl+5eHrBF5ettxudkkbJbbvX0T29DRUOkjP0xvJaf2LYNne08ZLOLVdmR0t4DS6J8QIhq2geVuAklrx0lhJ4cQSA7d53S/ZON0amcSmcqI5x/hOidTQURFxECIiAiIgIiICIiAiIgIiICpm1vIZsfwuoNLKYaytkZRQyNOjmF58pwPUWsD3D5wFc1mm3ulfLi9qqR/0qS6RSSHqAdHJEP8Aulavd0GimvpOHTXqvCY1siijbDGyNg3WMAa0DqAX6RF+lMxVzKtoeP4VNTwXevMFRUNL46eGCSolLR0v3I2ucGj/ABEafOrGsQz7HprZtaqr7cqDKK+y3C2QU0M+L1FS2Snlie8mORkD2uLXB+ocdQDr0akrz49dWHTejz7EtArtreJUENslfeGTNukD6mhFJDLUOqWMLQ7cbG1xcQXDVoGvSdNGnT7VG1DFqXE6fJZLxCLNUPEcNQGPc6STeLeTbGBvl+oI3A3e4HhwKo+NYhHZM9wSS02a50FnjtFykkbXb8j6eWaWCQslkJdo9xLzoXHoOnQqtRWK843cLPkM2P3Kvt1pyq+SzUNNSufOIqh7xDURxEavaPO3Xg/Uaryzj40a4jlPh08NM7NQ0/ZptJG0O6ZWKcxPtlsro6aklbDJFI9pgY93KNfxDg9zhpo3TToV7WabJDVVuTbQLrPa7ha6a4XOCWmbcaV0D5GCliYXBrurVp+joOh1C0terAqqqovVOm8/OQX4ldPGGTUshhq4HtmgkB0LZGnVp+jUcR1jUL9r+SPbExz3kNa0EknqC9GvRJGh6Vxq8syLHrbdI27jaymjn3Ndd3eaCR+rXRSSq2y2jkodnWOwygtk7yjeWnpG8N7T9WuitK/LcammjFqpp1RMrzrERFigREQEREBERAREQEREBR2QWOnySyVtrqweQqojG5zffN8zh5iDoQfOApFFamqaZiqnXA8x3ez1uN3SS2XJm5VMBcx497OzXQSM+Y9Y6QeB6taXctlOGXivnra7FbPWVk7i+Weeije97j1kkakr15kOMWvKqHvS60bKuEHeYTq18bv8THghzD87SCs9rNgkO+e8MhrqdnEhlTFHPu/MDo06fSSfnX2WB7X6Pi0RHSYtPC8Fol5+dsZwN51dh1jcdANTQRdA4D+6rHZbHbsct0dBaqGnt1DGSWU9LGI42knU6NHDiSStT8Qdb6VH93t9dPEHW+lR/d7fXXrp9o9Apm9NUR/ifQye9nSLRfEHW+lR/d7fXTxB1vpUf3e311p+K9C/1PKfQye9kmRYjY8uihivdoortHC4ujZWwNlDCeBIDgdFBeJfAfQyx/u+L1VvHiDrfSo/u9vrp4g6z0qP7vb66zq9oez6pvVVE/7Z9DJ72NY/s9xjFK19ZZcfttqqnxmJ01HSsieWEglpLQDpqAdPmCvOG4fNnd272DHNtNO8GuqRqG6DQ8g09b3Dp09606kglgdfrZsHt0UjXXO7V9zaOmBu7BG76dwb37HBaNb7dS2miho6KnipKWFu7HDCwNY0fMAuf0r2vhUUTR0WNM9trRH7kRZ0NaGNDWgNaBoABwAX9RF8gCIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiD/2Q==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from struct_vs_unstruct.experiments.self_discover import create_self_discover_graph\n",
    "\n",
    "app = create_self_discover_graph(modified)\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"\"\"Story:\n",
    "Charlotte entered the master bedroom. Mila entered the master bedroom. Alexander entered the master bedroom. The hat is in the container. Alexander exited the master bedroom. Charlotte moved the hat to the crate. Alexander entered the garage. Alexander and Charlotte plan to use the hat soon.\n",
    "\n",
    "Question:\n",
    "Who among the individuals would benefit from receiving helpful information? \n",
    "A. Alexander \n",
    "B. Charlotte \n",
    "C. Mila \n",
    "D. None of the above\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct_vs_unstruct.experiments.self_discover import self_discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "[400] Bad Request\nInference error\nRequestID: 847ffe2b-69ee-4c2e-9d7c-cf1f8d37233e",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/struct-vs-unstruct/struct_vs_unstruct/experiments/self_discover.py:255\u001b[0m, in \u001b[0;36mself_discover\u001b[0;34m(task_description, modified)\u001b[0m\n\u001b[1;32m    251\u001b[0m reasoning_modules_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(reasoning_modules)\n\u001b[1;32m    253\u001b[0m app \u001b[38;5;241m=\u001b[39m create_self_discover_graph(modified)\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtask_description\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_modules\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_modules_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1551\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1550\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1551\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1290\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1285\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   1286\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   1287\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   1288\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1289\u001b[0m     ):\n\u001b[0;32m-> 1290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1297\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langgraph/pregel/runner.py:56\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m     54\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langgraph/pregel/retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:385\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:167\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 167\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/struct-vs-unstruct/struct_vs_unstruct/experiments/self_discover.py:116\u001b[0m, in \u001b[0;36mselect\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(inputs):\n\u001b[1;32m    114\u001b[0m     select_chain \u001b[38;5;241m=\u001b[39m select_prompt \u001b[38;5;241m|\u001b[39m model\n\u001b[0;32m--> 116\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mselect_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     log_token_usage(result)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselected_modules\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_parser(result)}\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:2879\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2878\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2879\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2881\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:277\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    274\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    276\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 277\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    287\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:777\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    771\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    775\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    776\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 777\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:634\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    633\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 634\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    635\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    636\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    638\u001b[0m ]\n\u001b[1;32m    639\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:624\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 624\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m         )\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:846\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 846\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/chat_models.py:289\u001b[0m, in \u001b[0;36mChatNVIDIA._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    285\u001b[0m     _nv_vlm_adjust_input(message)\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m [convert_message_to_dict(message) \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[1;32m    287\u001b[0m ]\n\u001b[1;32m    288\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_payload(inputs\u001b[38;5;241m=\u001b[39minputs, stop\u001b[38;5;241m=\u001b[39mstop, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 289\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_req\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m responses, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpostprocess(response)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_callback_out(responses, run_manager)\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_common.py:449\u001b[0m, in \u001b[0;36m_NVIDIAClient.get_req\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_req\u001b[39m(\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    446\u001b[0m     payload: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m {},\n\u001b[1;32m    447\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m    448\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Post to the API.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     response, session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait(response, session)\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_common.py:346\u001b[0m, in \u001b[0;36m_NVIDIAClient._post\u001b[0;34m(self, invoke_url, payload)\u001b[0m\n\u001b[1;32m    342\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_session_fn()\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__add_authorization(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_inputs)\n\u001b[1;32m    345\u001b[0m )\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response, session\n",
      "File \u001b[0;32m~/struct-vs-unstruct/venv/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_common.py:439\u001b[0m, in \u001b[0;36m_NVIDIAClient._try_raise\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    437\u001b[0m     body \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease check or regenerate your API key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# todo: raise as an HTTPError\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheader\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mbody\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: [400] Bad Request\nInference error\nRequestID: 847ffe2b-69ee-4c2e-9d7c-cf1f8d37233e"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out = self_discover(task, modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['reasoning_modules', 'task_description', 'selected_modules', 'adapted_modules', 'reasoning_plan', 'answer'])\n"
     ]
    }
   ],
   "source": [
    "print(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the given task, the following reasoning modules are crucial:\n",
      "\n",
      "1. What are the key assumptions underlying this problem?\n",
      "   - Assumption: The task is to determine who would benefit from receiving helpful information based on the given story.\n",
      "\n",
      "2. How can I simplify the problem so that it is easier to solve?\n",
      "   - Simplification: Identify the actions and intentions of each individual in the story.\n",
      "\n",
      "3. What are the alternative perspectives or viewpoints on this problem?\n",
      "   - Perspective: Consider the story from the viewpoint of each character to understand their needs and potential benefits.\n",
      "\n",
      "4. What are the potential risks and drawbacks of each solution?\n",
      "   - Risk: Evaluate the potential risks of providing information to each character and how it might impact their actions.\n",
      "\n",
      "5. What are the long-term implications of this problem and its solutions?\n",
      "   - Implication: Consider the long-term benefits of providing information to each character and how it might affect their future actions.\n",
      "\n",
      "6. How can I break down this problem into smaller, more manageable parts?\n",
      "   - Breakdown: Analyze the story in parts, focusing on each character's actions and intentions.\n",
      "\n",
      "7. Critical Thinking: Analyze the problem from different perspectives, question assumptions, and evaluate the evidence or information available.\n",
      "   - Critical Thinking: Evaluate the story critically to determine who would benefit from receiving helpful information.\n",
      "\n",
      "8. Use Risk Analysis: Evaluate potential risks, uncertainties, and tradeoffs associated with different solutions or approaches to a problem.\n",
      "   - Risk Analysis: Evaluate the potential risks and benefits of providing information to each character.\n",
      "\n",
      "9. What are the potential obstacles or challenges that might arise in solving this problem?\n",
      "   - Obstacle: Consider any potential challenges in determining who would benefit from receiving helpful information.\n",
      "\n",
      "10. Are there any relevant data or information that can provide insights into the problem? If yes, what data sources are available, and how can they be analyzed?\n",
      "    - Data Analysis: Analyze the given story to extract relevant information about each character's actions and intentions.\n",
      "\n",
      "Based on the given story, the reasoning modules above can help determine who among the individuals would benefit from receiving helpful information.\n"
     ]
    }
   ],
   "source": [
    "print(out[\"selected_modules\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Key Underlying Assumptions:\n",
      "   - Assumption: The task is to determine which individual, based on their actions and intentions in the given story, would benefit most from receiving additional, helpful information.\n",
      "\n",
      "2. Problem Simplification:\n",
      "   - Simplification: Break down the story into individual actions and intentions of each character to understand their roles and potential needs.\n",
      "\n",
      "3. Alternative Perspectives:\n",
      "   - Perspective: Analyze the story from each character's viewpoint to understand their motivations, needs, and potential benefits from receiving additional information.\n",
      "\n",
      "4. Solution Risk Assessment:\n",
      "   - Risk: Evaluate the potential risks or negative impacts of providing information to each character, considering how it might alter their actions or intentions.\n",
      "\n",
      "5. Long-term Implications:\n",
      "   - Implication: Consider the long-term benefits of providing information to each character, and how it might influence their future actions or decisions.\n",
      "\n",
      "6. Problem Decomposition:\n",
      "   - Breakdown: Divide the story into smaller parts, focusing on each character's actions and intentions to identify who might benefit from additional information.\n",
      "\n",
      "7. Critical Evaluation:\n",
      "   - Critical Thinking: Evaluate the story critically, questioning assumptions and analyzing the evidence to determine who would benefit most from receiving helpful information.\n",
      "\n",
      "8. Risk Analysis:\n",
      "   - Risk Analysis: Evaluate the potential risks, uncertainties, and tradeoffs associated with providing information to each character, considering how it might impact their actions or decisions.\n",
      "\n",
      "9. Potential Obstacles:\n",
      "   - Obstacle: Consider any potential challenges or obstacles in determining who would benefit most from receiving helpful information, based on the actions and intentions of each character.\n",
      "\n",
      "10. Data Analysis:\n",
      "    - Data Analysis: Analyze the given story to extract relevant information about each character's actions, intentions, and potential needs for additional information.\n",
      "\n",
      "Based on these adapted reasoning modules, we can analyze the given story to determine who among the individuals would benefit most from receiving helpful information.\n",
      "\n",
      "Story:\n",
      "Charlotte entered the master bedroom. Mila entered the master bedroom. Alexander entered the master bedroom. The hat is in the container. Alexander exited the master bedroom. Charlotte moved the hat to the crate. Alexander entered the garage. Alexander and Charlotte plan to use the hat soon.\n",
      "\n",
      "Question:\n",
      "Who among the individuals would benefit from receiving helpful information?\n",
      "A. Alexander\n",
      "B. Charlotte\n",
      "C. Mila\n",
      "D. None of the above\n"
     ]
    }
   ],
   "source": [
    "print(out[\"adapted_modules\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning Plan:\n",
      "\n",
      "1. Data Analysis:\n",
      "   - Analyze the story to identify each character's actions, intentions, and potential needs for additional information.\n",
      "   - Identify the objects and locations mentioned in the story.\n",
      "\n",
      "2. Problem Decomposition:\n",
      "   - Break down the story into individual actions and intentions of each character (Charlotte, Mila, and Alexander).\n",
      "   - Focus on each character's actions and intentions to identify who might benefit from additional information.\n",
      "\n",
      "3. Alternative Perspectives:\n",
      "   - Analyze the story from each character's viewpoint to understand their motivations, needs, and potential benefits from receiving additional information.\n",
      "\n",
      "4. Solution Risk Assessment:\n",
      "   - Evaluate the potential risks or negative impacts of providing information to each character, considering how it might alter their actions or intentions.\n",
      "\n",
      "5. Long-term Implications:\n",
      "   - Consider the long-term benefits of providing information to each character, and how it might influence their future actions or decisions.\n",
      "\n",
      "6. Critical Evaluation:\n",
      "   - Evaluate the story critically, questioning assumptions and analyzing the evidence to determine who would benefit most from receiving helpful information.\n",
      "\n",
      "7. Risk Analysis:\n",
      "   - Evaluate the potential risks, uncertainties, and tradeoffs associated with providing information to each character, considering how it might impact their actions or decisions.\n",
      "\n",
      "8. Potential Obstacles:\n",
      "   - Consider any potential challenges or obstacles in determining who would benefit most from receiving helpful information, based on the actions and intentions of each character.\n",
      "\n",
      "9. Key Underlying Assumptions:\n",
      "   - Identify any underlying assumptions made while analyzing the story and evaluating the characters' needs for additional information.\n",
      "\n",
      "10. Final Decision:\n",
      "    - Based on the analysis, determine who among the individuals (Charlotte, Mila, or Alexander) would benefit most from receiving helpful information.\n",
      "\n",
      "By following this reasoning plan, solvers can systematically analyze the given story and determine who among the individuals would benefit most from receiving helpful information.\n"
     ]
    }
   ],
   "source": [
    "print(out[\"reasoning_plan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning Plan:\n",
      "\n",
      "1. Data Analysis:\n",
      "   - Charlotte, Mila, and Alexander are the characters in the story.\n",
      "   - The objects mentioned are the hat, container, and crate.\n",
      "   - The locations mentioned are the master bedroom and the garage.\n",
      "\n",
      "2. Problem Decomposition:\n",
      "   - Charlotte moved the hat from the container to the crate.\n",
      "   - Alexander and Charlotte plan to use the hat soon.\n",
      "   - Mila's actions and intentions are not clear from the story.\n",
      "\n",
      "3. Alternative Perspectives:\n",
      "   - Charlotte might benefit from knowing Alexander's plans for using the hat.\n",
      "   - Alexander might benefit from knowing the current location of the hat.\n",
      "   - Mila's potential benefits are unclear due to lack of information about her actions and intentions.\n",
      "\n",
      "4. Solution Risk Assessment:\n",
      "   - Providing information to Charlotte about Alexander's plans might not change her actions, as she already knows they plan to use the hat.\n",
      "   - Providing information to Alexander about the hat's location might change his actions, as he currently does not know where the hat is.\n",
      "   - Providing information to Mila might not have any impact, as her actions and intentions are unclear.\n",
      "\n",
      "5. Long-term Implications:\n",
      "   - Providing information to Charlotte might not have significant long-term benefits, as she already knows they plan to use the hat.\n",
      "   - Providing information to Alexander might have significant long-term benefits, as knowing the hat's location could help him in future plans involving the hat.\n",
      "   - Providing information to Mila might not have any long-term benefits, as her actions and intentions are unclear.\n",
      "\n",
      "6. Critical Evaluation:\n",
      "   - The story does not provide enough information about Mila's actions and intentions, making it difficult to determine if she would benefit from additional information.\n",
      "   - Charlotte and Alexander both have clear actions and intentions, making it easier to determine if they would benefit from additional information.\n",
      "\n",
      "7. Risk Analysis:\n",
      "   - Providing information to Charlotte might not have any risks, as she already knows they plan to use the hat.\n",
      "   - Providing information to Alexander might have some risks, as it could potentially change his actions or decisions.\n",
      "   - Providing information to Mila might not have any risks, as her actions and intentions are unclear.\n",
      "\n",
      "8. Potential Obstacles:\n",
      "   - The main obstacle is the lack of information about Mila's actions and intentions, making it difficult to determine if she would benefit from additional information.\n",
      "\n",
      "9. Key Underlying Assumptions:\n",
      "   - The assumption is that providing information to Alexander about the hat's location would be beneficial, as he and Charlotte plan to use the hat soon.\n",
      "\n",
      "10. Final Decision:\n",
      "    - Based on the analysis, Alexander would benefit most from receiving helpful information about the hat's location.\n"
     ]
    }
   ],
   "source": [
    "print(out[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Self-Discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self_discover' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mself_discover\u001b[49m(task, \u001b[38;5;129;01mnot\u001b[39;00m modified)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self_discover' is not defined"
     ]
    }
   ],
   "source": [
    "out = self_discover(task, not modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a step-by-step reasoning plan in JSON format based on the given reasoning modules:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"Key Underlying Assumptions\": {\n",
      "        \"Assumption\": \"The task is to identify who, among the individuals in the story, is unaware of crucial information that would impact their intended actions, specifically regarding the location of the hat.\"\n",
      "    },\n",
      "    \"Problem Simplification\": {\n",
      "        \"Simplification\": \"Break down the story into individual actions and intentions to understand who is aware of the hat's location and who is not.\"\n",
      "    },\n",
      "    \"Alternative Perspectives\": {\n",
      "        \"Perspective\": \"Consider the potential benefits of receiving information about the hat's location for each individual, based on their actions and intentions.\"\n",
      "    },\n",
      "    \"Potential Risks and Drawbacks\": {\n",
      "        \"Risk\": \"Evaluate the potential risks or drawbacks of not providing helpful information about the hat's location to each individual.\"\n",
      "    },\n",
      "    \"Long-term Implications\": {\n",
      "        \"Implication\": \"Consider the long-term consequences for each individual if they do not receive helpful information about the hat's location.\"\n",
      "    },\n",
      "    \"Problem Decomposition\": {\n",
      "        \"Breakdown\": {\n",
      "            \"Alexander\": \"Analyze Alexander's actions and intentions to determine if he is unaware of the hat's location and would benefit from receiving helpful information.\",\n",
      "            \"Charlotte\": \"Analyze Charlotte's actions and intentions to determine if she is unaware of the hat's location and would benefit from receiving helpful information.\",\n",
      "            \"Mila\": \"Analyze Mila's actions and intentions to determine if she is unaware of the hat's location and would benefit from receiving helpful information.\"\n",
      "        }\n",
      "    },\n",
      "    \"Critical Thinking\": {\n",
      "        \"Critical Thinking\": \"Evaluate the story and the actions of each individual critically to determine who is unaware of the hat's location and would benefit from receiving helpful information.\"\n",
      "    },\n",
      "    \"Conclusion\": {\n",
      "        \"Who would benefit from receiving helpful information\": \"\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "This plan can be filled out with the specific details from the story to arrive at the correct conclusion.\n"
     ]
    }
   ],
   "source": [
    "print(out[\"reasoning_structure\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Key Underlying Assumptions\": {\n",
      "        \"Assumption\": \"The task is to identify who, among the individuals in the story, is unaware of crucial information that would impact their intended actions, specifically regarding the location of the hat.\"\n",
      "    },\n",
      "    \"Problem Simplification\": {\n",
      "        \"Simplification\": \"Break down the story into individual actions and intentions to understand who is aware of the hat's location and who is not.\"\n",
      "    },\n",
      "    \"Alternative Perspectives\": {\n",
      "        \"Perspective\": \"Consider the potential benefits of receiving information about the hat's location for each individual, based on their actions and intentions.\"\n",
      "    },\n",
      "    \"Potential Risks and Drawbacks\": {\n",
      "        \"Risk\": \"Evaluate the potential risks or drawbacks of not providing helpful information about the hat's location to each individual.\"\n",
      "    },\n",
      "    \"Long-term Implications\": {\n",
      "        \"Implication\": \"Consider the long-term consequences for each individual if they do not receive helpful information about the hat's location.\"\n",
      "    },\n",
      "    \"Problem Decomposition\": {\n",
      "        \"Breakdown\": {\n",
      "            \"Alexander\": \"Alexander exited the master bedroom before Charlotte moved the hat to the crate. He is unaware of the hat's new location and would benefit from receiving helpful information.\",\n",
      "            \"Charlotte\": \"Charlotte moved the hat to the crate and is aware of its location. She does not need additional information.\",\n",
      "            \"Mila\": \"Mila did not interact with the hat and is not involved in the plan to use it. She does not need additional information.\"\n",
      "        }\n",
      "    },\n",
      "    \"Critical Thinking\": {\n",
      "        \"Critical Thinking\": \"Evaluating the story and the actions of each individual, it is clear that Alexander is unaware of the hat's location and would benefit from receiving helpful information.\"\n",
      "    },\n",
      "    \"Conclusion\": {\n",
      "        \"Who would benefit from receiving helpful information\": \"A. Alexander\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(out[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
