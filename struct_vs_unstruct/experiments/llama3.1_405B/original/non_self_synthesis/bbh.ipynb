{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "a4202b42-fcb2-4057-ba20-4b900b985a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from pyprojroot import here\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "5a87172d-a31f-4bf9-8eac-cfb89b9f6f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/jupyter/struct-vs-unstruct/struct_vs_unstruct/data/original/non_self_synthesis/bbh/refined')"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/refined/\")\n",
    "par_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad382360-c910-4008-9e29-ed54d2af6a60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# boolean_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "8e97125a-4717-448e-bb9c-e60b55801a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-boolean_expressions/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "40d8dd0a-6202-4900-9a23-f015a60d4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "88f60d5b-30f8-4fa0-b307-bed3b745d4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326905ff9ff2490589fe55a7b69159fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):\n",
    "    if \"False,\" in instance[\"answer_pred\"]:\n",
    "        return {\"answer_pred\": \"False\"}\n",
    "    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.\"\"'))\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "2855ae0f-99fd-4bbd-9c64-98fcb2d08074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False',\n",
       " 'Not True and Not False',\n",
       " 'True',\n",
       " 'justified based on the correct application of logical operations in the given order'}"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "9180b583-58e5-41c0-b848-c551363d515d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['True']"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds.filter(lambda x: \"True because both\" in x[\"answer_pred\"])[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "8946cad8-42d3-4f9d-9906-72d955568da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560e96e01afe47b18430e6be513f264e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    corr_ls = [\"True because both\", \"based on the application \", \"justified by evaluating the expression\"]\n",
    "    for string in corr_ls:\n",
    "        if string in ins[\"answer_pred\"]:\n",
    "            return {\n",
    "                \"answer_pred\": \"True\"\n",
    "            }\n",
    "\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "71698ea6-7042-4127-8f95-a0eb5477ac7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481c9a1fc969492a97223a30a012af77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_ds.save_to_disk(os.path.join(par_dir, \"boolean_expressions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c02dc813-116d-4514-aa52-6021f14700b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy', 0.976)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 3\n",
    "for instance in new_ds:\n",
    "    if instance[\"answer_pred\"] == instance[\"target\"]:\n",
    "        total += 1\n",
    "\n",
    "\"Accuracy\", total / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a8edf20-8db8-4864-aeac-bbb4697f1f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "based on the application of the 'or' and 'not' operators, as well as the simplification of the inner parentheses,\n",
      "```\n",
      "{\n",
      "    \"Step 1: Analyze the logical expression\": {\n",
      "        \"Identify the logical operators used\": \"The logical operators used are 'or' and 'not'.\",\n",
      "        \"Identify the truth values involved\": \"The truth values involved are True and False.\",\n",
      "        \"Initial interpretation of the expression\": \"The expression involves a combination of 'or' and 'not' operators with True and False values.\"\n",
      "    },\n",
      "    \"Step 2: Simplify the logical expression\": {\n",
      "        \"Apply De Morgan's laws or distributive property if applicable\": \"De Morgan's laws are not applicable in this case, but we can start by evaluating the inner parentheses.\",\n",
      "        \"Simplify any inner parentheses or nested expressions\": \"The inner parentheses contain 'True or False', which simplifies to True.\",\n",
      "        \"Expression after simplification\": \"( True ) or not True\"\n",
      "    },\n",
      "    \"Step 3: Evaluate the inner parentheses\": {\n",
      "        \"Truth value of the expression inside the parentheses\": \"The expression inside the parentheses is simply True.\",\n",
      "        \"Effect of the inner parentheses on the overall expression\": \"Since the inner parentheses simplify to True, the overall expression becomes 'True or not True'.\",\n",
      "        \"Expression after evaluating inner parentheses\": \"True or not True\"\n",
      "    },\n",
      "    \"Step 4: Apply the logical operators\": {\n",
      "        \"Truth value of the expression after applying the logical operators\": \"The expression 'not True' evaluates to False. Then, 'True or False' evaluates to True.\",\n",
      "        \"Explanation of the logical rules applied\": \"The 'not' operator negates the truth value of True, and the 'or' operator returns True if at least one of the operands is True.\",\n",
      "        \"Expression after applying logical operators\": \"True\"\n",
      "    },\n",
      "    \"Step 5: Consider alternative interpretations\": {\n",
      "        \"Alternative ways to think about the logical expression\": \"We could also think of the expression as '( True or False ) or ( not True )', but this would not change the final result.\",\n",
      "        \"Impact of alternative interpretations on the overall truth value\": \"Alternative interpretations do not affect the overall truth value in this case.\",\n",
      "        \"Expression after considering alternative interpretations\": \"True\"\n",
      "    },\n",
      "    \"Step 6: Final evaluation\": {\n",
      "        \"Truth value of the final expression\": \"True\",\n",
      "        \"Explanation of the logical rules applied to arrive at the final answer\": \"\n",
      "        \"Final answer\": \"True\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "=====================\n",
      "True\n",
      "True because both components of the statement are true, and the logical operation between them is a conjunction and In Boolean logic, True âˆ§ True = True\n",
      "```\n",
      "{\n",
      "    \"Step 1: Analyze the statement\": {\n",
      "        \"Description\": \"Break down the statement into its logical components\",\n",
      "        \"Components\": [\n",
      "            \"False or True\",\n",
      "            \"not False or True\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 2: Evaluate 'False or True'\": {\n",
      "        \"Description\": \"Determine the truth value of 'False or True'\",\n",
      "        \"Truth Value\": \"True\"\n",
      "    },\n",
      "    \"Step 3: Evaluate 'not False or True'\": {\n",
      "        \"Description\": \"Determine the truth value of 'not False or True'\",\n",
      "        \"Truth Value\": \"True\"\n",
      "    },\n",
      "    \"Step 4: Analyze the logical operation between the two components\": {\n",
      "        \"Description\": \"Determine the logical operation between 'False or True' and 'not False or True'\",\n",
      "        \"Operation\": \"and\"\n",
      "    },\n",
      "    \"Step 5: Evaluate the entire statement\": {\n",
      "        \"Description\": \"Combine the truth values of the two components using the logical operation\",\n",
      "        \"Truth Value\": \"True\"\n",
      "    },\n",
      "    \"Step 6: Consider alternative perspectives\": {\n",
      "        \"Description\": \"Analyze the statement from different logical perspectives\",\n",
      "        \"Perspectives\": [\n",
      "            \"From a Boolean algebra perspective, the statement can be represented as (False âˆ¨ True) âˆ§ (Â¬False âˆ¨ True)\",\n",
      "            \"From a logical perspective, the statement can be seen as combining two tautologies with a conjunction\"\n",
      "        ]\n",
      "    },\n",
      "    \"Step 7: Justify the final answer\": {\n",
      "        \"Description\": \"Provide a clear explanation for the final answer\",\n",
      "        \"Justification\": \"\n",
      "    },\n",
      "    \"Final Answer\": {\n",
      "        \"Description\": \"The final truth value of the statement\",\n",
      "        \"Answer\": \"True\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "=====================\n",
      "True\n",
      "False\n",
      "Here's the filled JSON for the given task:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Step 1: Break down the statement into smaller parts\": {\n",
      "        \"Identify logical operators\": \"The logical operators in the statement are 'not', 'and'.\",\n",
      "        \"Identify truth values\": \"The truth values in the statement are True and False.\"\n",
      "    },\n",
      "    \"Step 2: Determine the order of operations\": {\n",
      "        \"Is 'not' applied first?\": \"Yes, 'not' is applied first.\",\n",
      "        \"Is 'and' applied from left to right?\": \"Yes, 'and' is applied from left to right.\"\n",
      "    },\n",
      "    \"Step 3: Evaluate 'not False'\": {\n",
      "        \"Truth value of 'not False'\": \"The truth value of 'not False' is True.\"\n",
      "    },\n",
      "    \"Step 4: Evaluate 'True and True'\": {\n",
      "        \"Truth value of 'True and True'\": \"The truth value of 'True and True' is True.\"\n",
      "    },\n",
      "    \"Step 5: Evaluate 'True and False'\": {\n",
      "        \"Truth value of 'True and False'\": \"The truth value of 'True and False' is False.\"\n",
      "    },\n",
      "    \"Step 6: Apply the order of operations to the entire statement\": {\n",
      "        \"Truth value of 'not False and True and False'\": \"First, 'not False' is evaluated as True. Then, 'True and True' is evaluated as True. Finally, 'True and False' is evaluated as False.\"\n",
      "    },\n",
      "    \"Step 7: Analyze the statement from different logical perspectives\": {\n",
      "        \"Alternative ways to evaluate the statement\": \"One alternative way to evaluate the statement is to consider the 'not' operator as having the highest precedence, followed by the 'and' operators having equal precedence and being evaluated from left to right.\"\n",
      "    },\n",
      "    \"Step 8: Conclusion\": {\n",
      "        \"Is the statement True or False?\": \"The statement is False.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "=====================\n",
      "True\n",
      "False\n",
      "Here's the filled JSON for the given reasoning structure:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Step 1: Break down the statement into smaller parts\": {\n",
      "        \"Identify the logical operations\": \"False or not True and True or True\",\n",
      "        \"Separate the operations\": [\"False or not True\", \"True or True\"]\n",
      "    },\n",
      "    \"Step 2: Evaluate 'not True'\": {\n",
      "        \"Definition of 'not'\": \"Logical negation\",\n",
      "        \"Apply negation to 'True'\": \"not True = False\"\n",
      "    },\n",
      "    \"Step 3: Evaluate 'False or False'\": {\n",
      "        \"Definition of 'or'\": \"Logical disjunction\",\n",
      "        \"Apply disjunction to 'False' and 'False'\": \"False or False = False\"\n",
      "    },\n",
      "    \"Step 4: Evaluate 'True or True'\": {\n",
      "        \"Definition of 'or'\": \"Logical disjunction\",\n",
      "        \"Apply disjunction to 'True' and 'True'\": \"True or True = True\"\n",
      "    },\n",
      "    \"Step 5: Combine the results of 'False or False' and 'True or True'\": {\n",
      "        \"Definition of 'and'\": \"Logical conjunction\",\n",
      "        \"Apply conjunction to results\": \"(False or False) and (True or True) = False and True\"\n",
      "    },\n",
      "    \"Step 6: Simplify the expression\": {\n",
      "        \"Apply order of operations\": \"Evaluate 'and' last\",\n",
      "        \"Simplify the expression\": \"False and True = False\"\n",
      "    },\n",
      "    \"Step 7: Determine the final answer\": {\n",
      "        \"Final evaluation\": \"False\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "=====================\n",
      "False\n",
      "justified by evaluating the expression step-by-step following the order of operations,\n",
      "```\n",
      "{\n",
      "    \"Step 1: Identify the logical operators and their order of operations\": \"The expression contains the logical operators 'or', 'not', and 'and'. According to the order of operations, 'not' is evaluated first, followed by 'and', and then 'or'.\",\n",
      "    \"Step 2: Evaluate the truth value of 'not True'\": \"The truth value of 'not True' is False.\",\n",
      "    \"Step 3: Evaluate the truth value of 'False'\": \"The truth value of 'False' is False.\",\n",
      "    \"Step 4: Apply the logical 'and' operator to 'not True' and 'False'\": \"False and False is False.\",\n",
      "    \"Step 5: Apply the logical 'or' operator to '( False )' and the result of Step 4\": \"False or False is False.\",\n",
      "    \"Step 6: Simplify the expression using basic logical rules (e.g., order of operations, De Morgan's laws)\": \"No simplification is needed, as the expression has already been evaluated.\",\n",
      "    \"Step 7: Analyze the expression from different logical perspectives (e.g., questioning assumptions about the order of operations)\": \"The expression has been evaluated correctly following the order of operations.\",\n",
      "    \"Step 8: Identify the core logical issue that needs to be addressed in evaluating the expression\": \"The core issue is applying the logical operators in the correct order.\",\n",
      "    \"Step 9: Determine if the problem requires applying specific logical rules or syntax, or if it's a conceptual issue of understanding the meaning of the expression\": \"The problem requires applying specific logical rules (order of operations).\",\n",
      "    \"Step 10: Justify the final answer using good notation and explanation\": \"\n",
      "    \"Is the final answer 'True' or 'False'\": \"False\"\n",
      "}\n",
      "```\n",
      "=====================\n",
      "True\n",
      "False\n",
      "```\n",
      "{\n",
      "    \"Step 1: Break down the statement into individual components\": {\n",
      "        \"Component 1\": \"True or False\",\n",
      "        \"Component 2\": \"not (True)\"\n",
      "    },\n",
      "    \"Step 2: Analyze Component 1 - 'True or False'\": {\n",
      "        \"Definition of 'or' operation\": \"The 'or' operation returns True if at least one of the operands is True.\",\n",
      "        \"Truth table for 'or' operation\": \"True or False = True, False or True = True, True or True = True, False or False = False\",\n",
      "        \"Result of 'True or False'\": \"True\"\n",
      "    },\n",
      "    \"Step 3: Analyze Component 2 - 'not (True)'\": {\n",
      "        \"Definition of 'not' operation\": \"The 'not' operation returns the opposite of the operand.\",\n",
      "        \"Truth table for 'not' operation\": \"not True = False, not False = True\",\n",
      "        \"Result of 'not (True)'\": \"False\"\n",
      "    },\n",
      "    \"Step 4: Combine the results of Component 1 and Component 2\": {\n",
      "        \"Logical operation to combine the results\": \"and\",\n",
      "        \"Result of combining the results\": \"True and False = False\"\n",
      "    },\n",
      "    \"Step 5: Evaluate the final result\": {\n",
      "        \"Is the final result True or False\": \"False\",\n",
      "        \"Justification for the final result\": \"The 'and' operation requires both operands to be True for the result to be True. Since one of the operands is False, the final result is False.\"\n",
      "    },\n",
      "    \"Step 6: Critical thinking - analyze from different logical perspectives\": {\n",
      "        \"Alternative ways to evaluate the statement\": \"Using De Morgan's laws or applying the 'not' operation to the entire expression\",\n",
      "        \"Potential pitfalls or assumptions\": \"Assuming the 'or' operation has higher precedence than the 'and' operation or forgetting to apply the 'not' operation correctly\"\n",
      "    },\n",
      "    \"Step 7: Conclusion\": {\n",
      "        \"Final answer\": \"False\",\n",
      "        \"Summary of reasoning\": \"The statement 'True or False and not (True)' is evaluated by breaking it down into individual components, analyzing each component using truth tables, and combining the results using logical operations. The final result is False.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "=====================\n",
      "True\n",
      "Not True and Not False\n",
      "```\n",
      "{\n",
      "    \"Understanding the Task\": {\n",
      "        \"Description\": \"Analyze the statement 'True or False or not True or False is' and identify the key components\",\n",
      "        \"Questions to Ask\": [\n",
      "            \"What is the statement to be evaluated?\",\n",
      "            \"What are the possible classifications (True, False, Not True, Not False)?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"The statement to be evaluated is 'True or False or not True or False is'.\",\n",
      "            \"The possible classifications are True, False, Not True, and Not False.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Breaking Down the Statement\": {\n",
      "        \"Description\": \"Identify the logical components of the statement\",\n",
      "        \"Questions to Ask\": [\n",
      "            \"Are there any logical operators (AND, OR, NOT) in the statement?\",\n",
      "            \"Are there any conditional statements or implications?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"Yes, the statement contains the logical operators 'OR' and 'NOT'.\",\n",
      "            \"No, there are no conditional statements or implications.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Analyzing Logical Perspectives\": {\n",
      "        \"Description\": \"Evaluate the statement from different logical perspectives\",\n",
      "        \"Questions to Ask\": [\n",
      "            \"What are the assumptions underlying the classification of statements as True or False?\",\n",
      "            \"Are there any alternative perspectives that could be used to evaluate the statement?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"The statement assumes a binary classification system where a statement can only be True or False.\",\n",
      "            \"Yes, alternative perspectives such as fuzzy logic or multi-valued logic could be used to evaluate the statement.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Identifying Key Assumptions\": {\n",
      "        \"Description\": \"Identify the key assumptions underlying the classification of statements\",\n",
      "        \"Questions to Ask\": [\n",
      "            \"What are the implicit assumptions in the statement?\",\n",
      "            \"Are there any explicit assumptions that need to be considered?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"The statement implicitly assumes that the classification system is binary and that the statement can only be True or False.\",\n",
      "            \"There are no explicit assumptions that need to be considered.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Evaluating Logical Rules vs. Semantic Interpretation\": {\n",
      "        \"Description\": \"Determine if the problem is a matter of applying logical rules or semantic interpretation\",\n",
      "        \"Questions to Ask\": [\n",
      "            \"Can the statement be evaluated using standard logical rules?\",\n",
      "            \"Is there a need for semantic interpretation or contextual understanding?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"No, the statement cannot be evaluated using standard logical rules due to the self-referential paradox.\",\n",
      "            \"Yes, semantic interpretation or contextual understanding is needed to resolve the paradox.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Considering Alternative Perspectives\": {\n",
      "        \"Description\": \"Imagine alternative perspectives that could be used to evaluate the statement\",\n",
      "        \"Questions to Ask\": [\n",
      "            \"What if the traditional notions of True and False are incorrect?\",\n",
      "            \"Are there any other frameworks or theories that could be applied to evaluate the statement?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"If traditional notions of True and False are incorrect, then the statement could be evaluated using alternative frameworks such as fuzzy logic or multi-valued logic.\",\n",
      "            \"Yes, other frameworks or theories such as paraconsistent logic or dialetheism could be applied to evaluate the statement.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Synthesizing Information\": {\n",
      "        \"Description\": \"Combine the information gathered to arrive at a conclusion\",\n",
      "        \"Questions to Ask\": [\n",
      "            \"What are the implications of the analysis?\",\n",
      "            \"Is there a clear conclusion that can be drawn?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"The analysis implies that the statement is self-referentially paradoxical and cannot be evaluated using standard logical rules.\",\n",
      "            \"No, there is no clear conclusion that can be drawn due to the paradoxical nature of the statement.\"\n",
      "        ]\n",
      "    },\n",
      "    \"Conclusion\": {\n",
      "        \"Description\": \"Arrive at a final conclusion based on the analysis\",\n",
      "        \"Questions to Ask\": [\n",
      "            \"Is the statement True, False, Not True, or Not False?\",\n",
      "            \"What is the justification for the conclusion?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"The statement is Not True and Not False.\",\n",
      "            \"The justification for the conclusion is that the statement is self-referentially paradoxical and cannot be evaluated using standard logical rules.\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "```\n",
      "=====================\n",
      "True\n",
      "False\n",
      "To solve the task, I will follow the first JSON reasoning structure.\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Step 1: Identify the initial value\":\n",
      "        \"Initial value\": \"False\",\n",
      "        \"Operation\": \"not False\",\n",
      "        \"Result\": \"True\"\n",
      "    ,\n",
      "    \"Step 2: Apply the first 'not' operator\":\n",
      "        \"Current value\": \"True\",\n",
      "        \"Operation\": \"not\",\n",
      "        \"Result\": \"False\"\n",
      "    ,\n",
      "    \"Step 3: Apply the second 'not' operator\":\n",
      "        \"Current value\": \"False\",\n",
      "        \"Operation\": \"not\",\n",
      "        \"Result\": \"True\"\n",
      "    ,\n",
      "    \"Step 4: Apply the third 'not' operator\":\n",
      "        \"Current value\": \"True\",\n",
      "        \"Operation\": \"not\",\n",
      "        \"Result\": \"False\"\n",
      "    ,\n",
      "    \"Step 5: Apply the fourth 'not' operator\":\n",
      "        \"Current value\": \"False\",\n",
      "        \"Operation\": \"not\",\n",
      "        \"Result\": \"True\"\n",
      "    ,\n",
      "    \"Step 6: Apply the fifth 'not' operator\":\n",
      "        \"Current value\": \"True\",\n",
      "        \"Operation\": \"not\",\n",
      "        \"Result\": \"False\"\n",
      "    ,\n",
      "    \"Step 7: Determine the final result\":\n",
      "        \"Final value\": \"False\",\n",
      "        \"Conclusion\": \"The final result is False.\"\n",
      "}\n",
      "```\n",
      "=====================\n",
      "True\n",
      "justified based on the correct application of logical operations in the given order\n",
      "Here's the filled JSON for the given reasoning structure:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Step 1: Identify the core logical operation\":\n",
      "        \"The core logical operations in the expression are AND, OR, and NOT.\",\n",
      "    \"Step 2: Break down the expression into smaller parts\":\n",
      "        \"The individual components of the expression are: True, ( False ), and not False.\",\n",
      "    \"Step 3: Evaluate the expression inside the parentheses\":\n",
      "        \"The truth value of the expression inside the parentheses is False.\",\n",
      "    \"Step 4: Apply the logical AND operation\":\n",
      "        \"The result of applying the logical AND operation to True and False is False.\",\n",
      "    \"Step 5: Evaluate the expression 'not False'\":\n",
      "        \"The truth value of the expression 'not False' is True.\",\n",
      "    \"Step 6: Apply the logical OR operation\":\n",
      "        \"The result of applying the logical OR operation to False and True is True.\",\n",
      "    \"Step 7: Analyze the order of operations\":\n",
      "        \"The order of operations in the expression is correct, following the standard order of operations for logical operators: parentheses, NOT, AND, OR.\",\n",
      "    \"Step 8: Simplify the expression (if possible)\":\n",
      "        \"The expression can be simplified to True or not False, but since the original expression is already evaluated, no further simplification is necessary.\",\n",
      "    \"Step 9: Justify the final answer\":\n",
      "        \"\n",
      "}\n",
      "```\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "for instance in new_ds:\n",
    "    if instance[\"answer_pred\"] != instance[\"target\"]:\n",
    "        print(instance[\"target\"])\n",
    "        print(instance[\"answer_pred\"])\n",
    "        print(instance[\"trajectory\"])\n",
    "        print(\"=====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30a98a25-0bfc-4aeb-8242-b40bedffe797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59bfb96334c447b8b548e11de820f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_ds.save_to_disk(here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-boolean_expressions/bbh_eval_refined\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f896b20a-b9ca-4770-8d0b-b37c9a472974",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# causal_judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "60f0dec8-135d-4ec6-b413-321e122d6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-causal_judgement/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "82137aca-da0f-4847-b1f2-4f6fdf0cd8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "4bfd0f92-5704-4319-8f03-e00261008556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No.', 'No.\"', None, 'Yes.'}"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "49f660c3-20bf-460d-b16d-5554e01c96d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36af6c385fb4f21b9983de52d39398d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "896afd9e-c33c-4bea-89a8-df22c7874e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No', None, 'Yes'}"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "a1e17cfe-56d5-460e-8062-ff241e6e131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def map_fn(instance):\n",
    "    if instance[\"answer_pred\"] == None:\n",
    "        text = \"The final answer is:\"\n",
    "        pattern = fr\"(?<={text}).*\"\n",
    "    \n",
    "        response = instance[\"trajectory\"]\n",
    "    \n",
    "        try:\n",
    "            answer, trajectory = re.search(pattern, response).group(0).strip(), re.sub(pattern, \"\", response).replace(text, \"\").strip()\n",
    "        except:\n",
    "            answer, trajectory = None, response\n",
    "    \n",
    "        return {\n",
    "            \"trajectory\": trajectory,\n",
    "            \"answer_pred\": answer\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"trajectory\": instance[\"trajectory\"],\n",
    "        \"answer_pred\": instance[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "eb154921-eca4-414b-b0cf-4c90c6b3a6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d23bfb425d84553887ff9655ceb82a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "2ddea4fa-2a0a-4dcd-a3af-4a8c366ae862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No', 'Yes'}"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "46a37879-f0fa-4be7-867f-268848ac8af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114dd8b4d57440d3ac84405f6c525b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "037a8c0e-46e2-444f-8b4a-911d78c594fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7058823529411765"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "43dae966-2a98-49e9-ae04-5f6e20a6e891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4332392d07b496aaa34182eeb6eb1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_ds.save_to_disk(os.path.join(par_dir, \"causal_judgement\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56710f05-faca-4518-b318-54739646e5d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# date_understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "71df491e-6a9a-424b-a3ad-6418d59e6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-date_understanding/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "021c7135-b8b8-4d77-a787-0c37e9df3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "6ab4ee2a-1ae6-41be-8e71-9e40d4d9ab57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(D).',\n",
       " '(D).\",',\n",
       " '01/11/2011.',\n",
       " '07/10/1972.',\n",
       " '10/22/2001',\n",
       " '11/29/2001.',\n",
       " '12/02/1962.',\n",
       " 'A.',\n",
       " 'B',\n",
       " 'B.',\n",
       " 'C.',\n",
       " 'D.',\n",
       " 'E (Though the date provided does not exactly match the calculated date of 12/30/2013).',\n",
       " 'E.',\n",
       " 'F.',\n",
       " None,\n",
       " 'already in the US format: 01/09/1987.\"'}"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "bf1e8c96-39e6-449f-827d-4b3d8c93355b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6136afac5f245deb7498f7beba78761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "41cf17a6-0769-48f7-9594-d7e0e4bb3ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01/11/2011',\n",
       " '07/10/1972',\n",
       " '10/22/2001',\n",
       " '11/29/2001',\n",
       " '12/02/1962',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'E Though the date provided does not exactly match the calculated date of 12/30/2013',\n",
       " 'F',\n",
       " None,\n",
       " 'already in the US format: 01/09/1987'}"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "a8731798-91af-4f87-aa9c-e75f8aac9dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 3\n",
       "})"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_none = new_ds.filter(lambda x: x[\"answer_pred\"] == None)\n",
    "ds_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "b3165a2f-ef46-42d2-8c22-f67922757d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16210c52646b4a4e918e92d36cfc1faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "710a4930-1b3b-4713-ba53-a90851d9cd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy', 0.888)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 1\n",
    "\n",
    "for instance in new_ds:\n",
    "    if instance[\"answer_pred\"] == instance[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')):\n",
    "        total += 1\n",
    "\n",
    "\"Accuracy\", total / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7e42df60-418f-400e-bbce-b27654f3ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(D)\n",
      "12/02/1962\n",
      "Jane and John married on Jan 2, 1958. It is their 5-year anniversary today. What is the date a month ago in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 12/02/2000\n",
      "(B) 12/02/2055\n",
      "(C) 12/01/1960\n",
      "(D) 12/02/1960\n",
      "(E) 05/02/1961\n",
      "(F) 11/18/1960\n",
      "==================================================\n",
      "(A)\n",
      "11/29/2001\n",
      "In the US, Thanksgiving is on the fourth Thursday of November. Today is the US Thanksgiving of 2001. What is the date one week from today in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 11/29/2002\n",
      "(B) 11/15/2002\n",
      "(C) 11/30/2002\n",
      "(D) 12/27/2002\n",
      "(E) 12/11/2002\n",
      "(F) 11/29/2078\n",
      "==================================================\n",
      "(F)\n",
      "10/22/2001\n",
      "In the US, Thanksgiving is on the fourth Thursday of November. Today is the US Thanksgiving of 2001. What is the date a month ago in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 11/22/2001\n",
      "(B) 10/21/2002\n",
      "(C) 07/21/2002\n",
      "(D) 10/22/1923\n",
      "(E) 10/15/2002\n",
      "(F) 10/22/2002\n",
      "==================================================\n",
      "(B)\n",
      "01/11/2011\n",
      "Yesterday, Jan 21, 2011, Jane ate 2 pizzas and 5 wings. What is the date 10 days ago in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 01/18/2011\n",
      "(B) 01/12/2011\n",
      "(C) 01/12/2069\n",
      "(D) 01/13/2011\n",
      "(E) 05/12/2010\n",
      "(F) 08/12/2010\n",
      "==================================================\n",
      "(F)\n",
      "already in the US format: 01/09/1987\n",
      "In the UK, people usually put the day before the month when formatting the date. Therefore, today is 02/01/1987 to them. What is the date one week from today in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 01/23/1987\n",
      "(B) 01/09/2023\n",
      "(C) 01/09/1948\n",
      "(D) 01/08/1987\n",
      "(E) 03/17/1987\n",
      "(F) 01/09/1987\n",
      "==================================================\n",
      "(D)\n",
      "07/10/1972\n",
      "Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date tomorrow in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 07/09/1923\n",
      "(B) 08/05/1972\n",
      "(C) 09/01/1972\n",
      "(D) 07/09/1972\n",
      "(E) 07/09/2007\n",
      "(F) 09/04/1972\n",
      "==================================================\n",
      "(E)\n",
      "E Though the date provided does not exactly match the calculated date of 12/30/2013\n",
      "2015 is coming in 36 hours. What is the date one year ago from today in MM/DD/YYYY?\n",
      "Options:\n",
      "(A) 12/09/2013\n",
      "(B) 01/19/2014\n",
      "(C) 12/28/2013\n",
      "(D) 07/29/2013\n",
      "(E) 12/29/2013\n",
      "(F) 02/28/2014\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for inst in new_ds:\n",
    "    if inst[\"answer_pred\"] and len(inst[\"answer_pred\"]) != 1:\n",
    "        print(inst[\"target\"])\n",
    "        print(inst[\"answer_pred\"])\n",
    "        print(inst[\"input\"])\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7a71e015-96fc-4387-841d-d0232bd7bbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(E)\n",
      "To solve the task, we will follow the step-by-step reasoning plan.\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Step 1: Identify the day, month, and year of the current date\": {\n",
      "        \"Day\": \"Since tomorrow is Tuesday, 7/9/1972's Monday is 7/8/1972's and today is 7/8/1972, but today is actually 7/8/1972, so today is Sunday 7/8/1972's day before which is Saturday 7/7/1972's day before which is Friday 7/6/1972's day before which is Thursday 7/5/1972's day before which is Wednesday 7/4/1972's day before which is Tuesday 7/3/1972's day before which is Monday 7/2/1972's day before which is Sunday 7/1/1972's day before which is Saturday 6/30/1972's day before which is Friday 6/29/1972's day before which is Thursday 6/28/1972's day before which is Wednesday 6/27/1972's day before which is Tuesday 6/26/1972's day before which is Monday 6/25/1972's day before which is Sunday 6/24/1972's day before which is Saturday 6/23/1972's day before which is Friday 6/22/1972's day before which is Thursday 6/21/1972's day before which is Wednesday 6/20/1972's day before which is Tuesday 6/19/1972's day before which is Monday 6/18/1972's day before which is Sunday 6/17/1972's day before which is Saturday 6/16/1972's day before which is Friday 6/15/1972's day before which is Thursday 6/14/1972's day before which is Wednesday 6/13/1972's day before which is Tuesday 6/12/1972's day before which is Monday 6/11/1972's day before which is Sunday 6/10/1972's day before which is Saturday 6/9/1972's day before which is Friday 6/8/1972's day before which is Thursday 6/7/1972's day before which is Wednesday 6/6/1972's day before which is Tuesday 6/5/1972's day before which is Monday 6/4/1972's day before which is Sunday 6/3/1972's day before which is Saturday 6/2/1972's day before which is Friday 6/1/1972's day before which is Thursday 5/31/1972's day before which is Wednesday 5/30/1972's day before which is Tuesday 5/29/1972's day before which is Monday 5/28/1972's day before which is Sunday 5/27/1972's day before which is Saturday 5/26/1972's day before which is Friday 5/25/1972's day before which is Thursday 5/24/1972's day before which is Wednesday 5/23/1972's day before which is Tuesday 5/22/1972's day before which is Monday 5/21/1972's day before which is Sunday 5/20/1972's day before which is Saturday 5/19/1972's day before which is Friday 5/18/1972's day before which is Thursday 5/17/1972's day before which is Wednesday 5/16/1972's day before which is Tuesday 5/15/1972's day before which is Monday 5/14/1972's day before which is Sunday 5/13/1972's day before which is Saturday 5/12/1972's day before which is Friday 5/11/1972's day before which is Thursday 5/10/1972's day before which is Wednesday 5/9/1972's day before which is Tuesday 5/8/1972's day before which is Monday 5/7/1972's day before which is Sunday 5/6/1972's day before which is Saturday 5/5/1972's day before which is Friday 5/4/1972's day before which is Thursday 5/3/1972's day before which is Wednesday 5/2/1972's day before which is Tuesday 5/1/1972's day before which is Monday 4/30/1972's day before which is Sunday 4/29/1972's day before which is Saturday 4/28/1972's day before which is Friday 4/27/1972's day before which is Thursday 4/26/1972's day before which is Wednesday 4/25/1972's day before which is Tuesday 4/24/1972's day before which is Monday 4/23/1972's day before which is Sunday 4/22/1972's day before which is Saturday 4/21/1972's day before which is Friday 4/20/1972's day before which is Thursday 4/19/1972's day before which is Wednesday 4/18/1972's day before which is Tuesday 4/17/1972's day before which is Monday 4/16/1972's day before which is Sunday 4/15/1972's day before which is Saturday 4/14/1972's day before which is Friday 4/13/1972's day before which is Thursday 4/12/1972's day before which is Wednesday 4/11/1972's day before which is Tuesday 4/10/1972's day before which is Monday 4/9/1972's day before which is Sunday 4/8/1972's day before which is Saturday 4/7/1972's day before which is Friday 4/6/1972's day before which is Thursday 4/5/1972's day before which is Wednesday 4/4/1972's day before which is Tuesday 4/3/1972's day before which is Monday 4/2/1972's day before which is Sunday 4/1/1972's day before which is Saturday 3/31/1972's day before which is Friday 3/30/1972's day before which is Thursday 3/29/1972's day before which is Wednesday 3/28/1972's day before which is Tuesday 3/27/1972's day before which is Monday 3/26/1972's day before which is Sunday 3/25/1972's day before which is Saturday 3/24/1972's day before which is Friday 3/23/1972's day before which is Thursday 3/22/1972's day before which is Wednesday 3/21/1972's day before which is Tuesday 3/20/1972's day before which is Monday 3/19/1972's day before which is Sunday 3/18/1972's day before which is Saturday 3/17/1972's day before which is Friday 3/16/1972's day before which is Thursday 3/15/1972's day before which is Wednesday 3/14/1972's day before which is Tuesday 3/13/1972's day before which is Monday 3/12/1972's day before which is Sunday 3/11/1972's day before which is Saturday 3/10/1972's day before which is Friday 3/9/1972's day before which is Thursday 3/8/1972's day before which is Wednesday 3/7/1972's day before which is Tuesday 3/6/1972's day before which is Monday 3/5/1972's day before which is Sunday 3/4/1972's day before which is Saturday 3/3/1972's day before which is Friday 3/2/1972's day before which is Thursday 3/1/1972's day before which is Wednesday 2/29/1972's day before which is Tuesday 2/28\n",
      "============================\n",
      "(B)\n",
      "To solve the task, we will follow the step-by-step reasoning plan.\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Step 1: Identify the given palindrome date in MMDDYYYY format\": \"02/02/2020\",\n",
      "    \"Step 2: Break down the date into its constituent parts (month, day, year)\": {\n",
      "        \"Month\": \"02\",\n",
      "        \"Day\": \"02\",\n",
      "        \"Year\": \"2020\"\n",
      "    },\n",
      "    \"Step 3: Determine the correct month and year for the date a month ago\": {\n",
      "        \"Previous month\": \"01\",\n",
      "        \"Previous year (if necessary)\": \"2020\"\n",
      "    },\n",
      "    \"Step 4: Apply the necessary date subtraction logic to find the date a month ago\": {\n",
      "        \"Number of days in the previous month\": \"31\",\n",
      "        \"Day of the previous month\": \"Since the day is 2, subtracting 2 from 2 and then going back to the previous month gives us 31 - 0 = 31, then 31 - 1 = 30, then 31 - 2 + 1 = 30. Since the day is 2, we get 31 - 1 = 31 - 2 + 1 = 30 + 1 - 2 =  31 - 1 = 30. Since the day is 2, we get 31 - 2 + 1 = 30. Since the day is 2, we get 31 - 2 + 1 = 30 + 1 - 2 = 30 - 1 + 1 = 30. Since the day is 2, we get 31 - 2 + 1 = 30 - 1 + 1 = 30 - 1 + 1 = 30 - 2 + 2 = 30 - 2 + 1 + 1 = 30 - 2 + 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 = 30 - 2 + 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 + 1 - 1 +\n",
      "============================\n",
      "(C)\n",
      "Here's the filled JSON for the given task:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Step 1: Identify the given date components\":\n",
      "        {\n",
      "            \"Month\": \"March (3rd month)\",\n",
      "            \"Day\": \"2nd day\",\n",
      "            \"Year\": \"1966\"\n",
      "        },\n",
      "    \"Step 2: Determine the number of days in the given month\":\n",
      "        {\n",
      "            \"Number of days in the given month\": \"31\",\n",
      "            \"Is the given month a leap month (February)\": \"No\",\n",
      "            \"Does the given year affect the number of days in February\": \"Yes, 1966 is not a leap year, but 1964 was\"\n",
      "        },\n",
      "    \"Step 3: Determine the previous month\":\n",
      "        {\n",
      "            \"Previous month name\": \"February\",\n",
      "            \"Previous month number\": \"2\"\n",
      "        },\n",
      "    \"Step 4: Calculate the number of days in the previous month\":\n",
      "        {\n",
      "            \"Number of days in the previous month\": \"28\",\n",
      "            \"Is the previous month a leap month (February)\": \"Yes\",\n",
      "            \"Does the given year affect the number of days in February\": \"No, 1966 is not a leap year\"\n",
      "        },\n",
      "    \"Step 5: Calculate the date a month ago\":\n",
      "        {\n",
      "            \"Day a month ago\": \"Since the day is 2, we subtract 2 from the number of days in the previous month and then add 1. 28 - 2 + 1 = 27, but since the day is 2, we simply subtract 2 from the number of days in the previous month and then add the day. 28 - 2 + 2 = 28. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month and then add the day - 1. 28 - 2 + 1 = 27. However, since the day is 2, we simply take the day as is and subtract 1 from the number of days in the previous month and then add the day - 1. 28 - 1 = 27. Then 27 - 2 + 2 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day - 1. 26 + 1 = 27, but since the day is 2, we simply take the day as is and subtract 1 from the number of days in the previous month. 28 - 1 = 27. Then we add the day - 2. 27 - 1 = 26 and then add 1. 26 + 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 2 = 26. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day - 1. 26 + 1 = 27, but since the day is 2, we simply take the day as is and subtract 1 from the number of days in the previous month. 28 - 1 = 27. Then we add the day - 2. 27 - 1 = 26 and then add 1. 26 + 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 1 = 27. However, since the day is 2, we simply take the day as is and subtract 1 from the number of days in the previous month. 28 - 1 = 27. Then we add the day - 2. 27 - 1 = 26 and then add 1. 26 + 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day - 1. 26 + 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 2 = 26. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 1 = 27. However, since the day is 2, we simply take the day as is and subtract 1 from the number of days in the previous month. 28 - 1 = 27. Then we add the day - 2. 27 - 1 = 26 and then add 1. 26 + 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 1 = 27. However, since the day is 2, we simply take the day as is and subtract 1 from the number of days in the previous month. 28 - 1 = 27. Then we add the day - 2. 27 - 1 = 26 and then add 1. 26 + 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 2 = 26. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number of days in the previous month. 28 - 2 = 26. Then we add the day. 26 + 2 - 1 = 27. However, since the day is 2, we simply take the day as is and subtract 2 from the number\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "for ins in ds_none:\n",
    "    print(ins[\"target\"])\n",
    "    print(ins[\"trajectory\"])\n",
    "    print(\"============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42902384-b596-4280-9966-8fa9e0e11ae6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# disambiguation_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "3b529475-dada-4c81-9a3e-909b3eb864fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-disambiguation_qa/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "f940e07e-333e-4f07-9438-d2a158fa225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "21133bee-e7ac-4fa4-9c26-bf7a9d011447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(B).', '(C).', 'A.', 'B.', 'C.'}"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "71ac8e8b-1d12-43d8-a23e-afd10f410619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa231d6f1444339976e2963e692b562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3724e230-574d-407c-8b07-cded9deb91ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "d4ac2278-e11d-4377-b8c2-1e79d9ac7c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9fd1ab14964675a320f502c9ca237c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2d42fa2e-575f-4a51-9d69-7994d6508b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy', 0.704)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "\n",
    "for instance in new_ds:\n",
    "    if instance[\"answer_pred\"] == instance[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')):\n",
    "        total += 1\n",
    "\n",
    "\"Accuracy\", total / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9db11f-2eca-4d16-8507-7bd9ed72282a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# dyck_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "658d2bab-9a0b-4026-860d-065c45489f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-dyck_languages/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "4d1bee9a-1738-4772-8848-846a0d0a0e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "83b0c8a1-bda9-418b-a47a-6e436bd7e166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 45\n",
       "})"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds = dataset.filter(lambda x: x[\"answer_pred\"] == None)\n",
    "new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "ce39708e-de95-4714-bb53-39a022278ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71263ece1c1648cbbc332f92a36d097d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "def map_fn(instance):\n",
    "    if instance[\"answer_pred\"] == None:\n",
    "        text = \"The final answer is:\"\n",
    "        pattern = fr\"(?<={text}).*\"\n",
    "    \n",
    "        response = instance[\"trajectory\"]\n",
    "    \n",
    "        try:\n",
    "            answer, trajectory = re.search(pattern, response).group(0).strip(), re.sub(pattern, \"\", response).replace(text, \"\").strip()\n",
    "        except:\n",
    "            answer, trajectory = None, response\n",
    "    \n",
    "        return {\n",
    "            \"trajectory\": trajectory,\n",
    "            \"answer_pred\": answer\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"trajectory\": instance[\"trajectory\"],\n",
    "        \"answer_pred\": instance[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "6545ea6d-2881-4fce-b8cc-83a0331fd457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719c8419312b486a854ef997fd907146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c6464-86e2-436f-8ed5-9d68c8bbeb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in new_ds:\n",
    "    print(instance[\"target\"])\n",
    "    print(instance[\"trajectory\"])\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887ffae8-8423-4dc0-8fbe-4731bb38186c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# formal_fallacies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "50da91f3-6deb-47c3-bccc-f19203134e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-formal_fallacies/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "a65b8587-c387-430c-8f87-4b7c42c65efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "6773264b-4bf0-4787-ae71-c0efc0704693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None, 'invalid.', 'valid.'}"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "a2f9e6a4-bd46-4019-8573-0c5ebe245c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4eff5714c194cbda29f41bdb548f24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5c905d17-ae78-4cb1-975c-914bad666a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None, 'invalid', 'valid'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "06f79005-f4dd-410b-af5f-21040d4f307f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24a3fb04e884106ac5f2c5d495048db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "def map_fn(instance):\n",
    "    if instance[\"answer_pred\"] == None:\n",
    "        text = \"The final answer is:\"\n",
    "        pattern = fr\"(?<={text}).*\"\n",
    "    \n",
    "        response = instance[\"trajectory\"]\n",
    "    \n",
    "        try:\n",
    "            answer, trajectory = re.search(pattern, response).group(0).strip(), re.sub(pattern, \"\", response).replace(text, \"\").strip()\n",
    "        except:\n",
    "            answer, trajectory = None, response\n",
    "    \n",
    "        return {\n",
    "            \"trajectory\": trajectory,\n",
    "            \"answer_pred\": answer\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"trajectory\": instance[\"trajectory\"],\n",
    "        \"answer_pred\": instance[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "f31dbef8-332e-4b1e-9813-161cdbd27f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'invalid', 'valid'}"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "f69daf40-4760-4774-a30c-3f3b285553bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6473e3fc3f0d4123b70d140f58eb23cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "50ffb33c-716f-440c-a116-c4bda9fafc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bf06f6ad5a4a8c81cc1749751ab73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "1383ba70-72f8-4efb-9d61-03a0282d207f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.728"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e488a9-5e7a-4ecd-b74b-ee26d852b43b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# geometric_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "8a5775a3-0f0a-424e-a737-b086e62f4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-geometric_shapes/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "e18c74b9-fb2e-4fcc-823e-76c55207597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "bc25565e-8bcb-423f-8d28-174ef3b1d389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(D).',\n",
       " '(D).\"',\n",
       " '(K) ellipse.\"',\n",
       " '(K).\"',\n",
       " 'A.',\n",
       " 'A.\"',\n",
       " 'B.',\n",
       " 'C.',\n",
       " 'D.',\n",
       " 'D.\"',\n",
       " 'E.',\n",
       " 'E.\",',\n",
       " 'F.',\n",
       " 'G.',\n",
       " 'H.',\n",
       " 'I.',\n",
       " 'I.\"',\n",
       " 'J.',\n",
       " 'K.',\n",
       " 'K.\"'}"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "b15078a8-d3c9-4670-b994-634351da72bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69bc9a266574f51815b62633e9ff9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "e20a9ea7-bd1b-474c-8b92-be9bdad0f407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'K ellipse'}"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "c8da6dbb-ca86-4cd4-b03f-8b9a0dc03389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9546a844564ca89d3152f518643583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    if \"K ellipse\" == instance[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"K\"\n",
    "        }\n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "6a94f9a2-b225-49a1-beed-9734e45ec7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K'}"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "2d1a35c7-e67f-4da9-8459-fbc63bb8cd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06502ab14b3e4d688b7cc83ed7951ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5fa31b0a-81c3-4a4b-847a-80b573d97eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffbbb0f612f40429a10ecb51f83d7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 167\n",
       "})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0f7bfa59-4f6a-41ec-9576-a8de5a881907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.672"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows + 1) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaefe78-ecbb-49ae-bd58-e000c8208c1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# hyperbaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "c97fe7eb-7986-459a-85bf-0e9e367a3722",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-hyperbaton/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "70035db6-c28e-4992-ad04-fc46c35ad8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "3c3bbb74-3ad1-461c-9bd2-3cacc2987799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'A\"',\n",
       " 'A.',\n",
       " 'B is incorrect and the correct answer is not among the options, it should be: Russian old-fashioned rectangular brown baby.',\n",
       " 'B.',\n",
       " 'Neither (A) nor (B) is correct; the correct order is: old brown circular Turkish wool car',\n",
       " 'Neither.'}"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "126ef57d-498d-4b30-9fe2-b55b3166bc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959863995d9c4870be691bad07bb148f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "1a4b6dbb-94f7-41ac-beba-b861305a247f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'B',\n",
       " 'B is incorrect and the correct answer is not among the options it should be: Russian old-fashioned rectangular brown baby',\n",
       " 'Neither',\n",
       " 'Neither A nor B is correct; the correct order is: old brown circular Turkish wool car'}"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "57e61e46-ee2a-4a0d-9605-b092b855f25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e8a7b4b9cf47b0a7274d32c3c51a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "77943f6b-0ef4-472b-8c75-164566e33273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffbbb0f612f40429a10ecb51f83d7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 167\n",
       "})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1a961021-7c00-427d-986d-becf7483f61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.672"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows + 1) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc2a84-f816-4975-b85d-f4a505c99639",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# logical_deduction_five_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "92d8f5eb-fa8f-47e8-abfa-dcc9962684eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-logical_deduction_five_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "c8eacea9-4afc-4783-907d-74397b343553",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "6cfe632f-200c-4cc2-adc4-767b6406854a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(D).\"', 'A.', 'B.', 'C.', 'D', 'D.', 'D.\"', 'E.'}"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "6ea098a1-449b-416c-801b-6ed0e49a219e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ef9adb48d14bfa9e645c11f6881e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "11b1f5dd-937c-4c45-b123-1ceac1875924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E'}"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "c9aab7a5-15a2-4db5-9c23-3dfa57c64939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76cadf2ab1384b2a8995b45dfa5684a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cf1bcc92-9f2e-4776-add6-e27e8e989d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db8dd8325944f59946b38a2b637d08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 229\n",
       "})"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "236bf5d3-3274-4079-a628-c7afdc1147fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.916"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef7c23-849a-4c8c-86ec-60f32a0b2428",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# logical_deduction_seven_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbb231c-9083-40ff-921e-a196229de3f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# logical_deduction_three_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "997292c0-b202-456f-ac2e-e612811c85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-logical_deduction_three_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "4e15206b-92e9-4cb9-beca-58323222878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "9e5aa80f-ed32-45e4-957a-86b4ff6dc784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A\"', 'A.', 'B.', 'C.', 'C.\"'}"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "9deaa30c-78f4-460b-aa3a-470e8b532ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f20314a08f64506bd5e3562492379b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "39f489b1-b835-47a2-8a2b-283005686943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C'}"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "cb43de52-b600-445c-86eb-86968fdac33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59cc396bdda4511aa574a9b178030d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "992a8366-d61d-4ac0-8e3f-54bdbabdab2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8bed7560284310a1d1cb407f3cc380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "1bfbeb97-d753-4c05-958c-92185d9249e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1915237-bce3-4e3b-b051-8d5eb37f9d01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# movie_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "d1974cb6-ad5a-4797-b836-5107b4b39e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-movie_recommendation/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "c621e330-d571-40ed-8276-5aed2ca64e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "772615e1-2fba-4dfb-9f90-e1551714abdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A.',\n",
       " 'B is not the answer, it is actually A.',\n",
       " 'B.',\n",
       " 'C.',\n",
       " 'D.',\n",
       " 'E.',\n",
       " None,\n",
       " 'None of the above.'}"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "a09a7372-c6cc-4b27-8e5d-f02bd646f95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcd888aad144d6aaa3fa4416d2b62f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "b8cddf57-5603-40d4-a8bb-b9db3d7f7104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'B',\n",
       " 'B is not the answer it is actually A',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " None,\n",
       " 'None of the above'}"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "24198ebc-d096-44ce-8102-7022ba27c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_fn(ins):\n",
    "    if ins[\"answer_pred\"] and \"B is not the answer\" in ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"A\"\n",
    "        }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "2f22a0a3-9a30-4456-93eb-f54f0f4c0822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', None, 'None of the above'}"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "fae5e1ae-b0b6-4ccc-ada7-fd6c710705db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bef5c9fcd045d0bb8b8e4a663cdc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "def map_fn(instance):\n",
    "    if instance[\"answer_pred\"] == None:\n",
    "        text = \"The final answer is:\"\n",
    "        pattern = fr\"(?<={text}).*\"\n",
    "    \n",
    "        response = instance[\"trajectory\"]\n",
    "    \n",
    "        try:\n",
    "            answer, trajectory = re.search(pattern, response).group(0).strip(), re.sub(pattern, \"\", response).replace(text, \"\").strip()\n",
    "        except:\n",
    "            answer, trajectory = None, response\n",
    "    \n",
    "        return {\n",
    "            \"trajectory\": trajectory,\n",
    "            \"answer_pred\": answer\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"trajectory\": instance[\"trajectory\"],\n",
    "        \"answer_pred\": instance[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "dfc2dbe3-9193-43ab-ae71-07dd567c6d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'B',\n",
       " 'B is not the answer it is actually A',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " None,\n",
       " 'None of the above'}"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "bdd7fd5b-8cff-4fca-acc4-226716a840c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cf82c6292b450ea54115b0de1db30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9ca30b67-e251-4c75-bfc1-85c852d42050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7fd61de0c34d6bb96ad5583f7c622b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 166\n",
       "})"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "35c7dc9c-798a-433a-86e2-0f50cd2ed7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c051add92a47059f14f829f6576b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "none = new_ds.filter(lambda x: x[\"answer_pred\"] == None)\n",
    "none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "578d5881-bc41-417f-b602-e9c7bb364fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(C)\n",
      "Here is the filled JSON for the above reasoning structure:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"Step 1: Identify genres, themes, and elements of given movies\":\n",
      "  {\n",
      "    \"Get Shorty genres\": [\"Comedy\", \"Crime\"],\n",
      "    \"Get Shorty themes\": [\"Hollywood satire\", \"Redemption\"],\n",
      "    \"Get Shorty elements\": [\"Mobsters\", \"Screenwriting\"],\n",
      "    \"Mr Holland's Opus genres\": [\"Drama\", \"Music\"],\n",
      "    \"Mr Holland's Opus themes\": [\"Perseverance\", \"Inspiration\"],\n",
      "    \"Mr Holland's Opus elements\": [\"Music teacher\", \"High school\"],\n",
      "    \"Stargate genres\": [\"Science Fiction\", \"Adventure\"],\n",
      "    \"Stargate themes\": [\"Exploration\", \"Ancient civilizations\"],\n",
      "    \"Stargate elements\": [\"Time travel\", \"Aliens\"],\n",
      "    \"Dances with Wolves genres\": [\"Western\", \"Drama\"],\n",
      "    \"Dances with Wolves themes\": [\"Cultural clash\", \"Self-discovery\"],\n",
      "    \"Dances with Wolves elements\": [\"Native Americans\", \"Frontier life\"]\n",
      "  },\n",
      "  \n",
      "  \"Step 2: Analyze movies from different perspectives\":\n",
      "  {\n",
      "    \"Genre analysis\": \"The movies span multiple genres, including comedy, drama, science fiction, and western.\",\n",
      "    \"Tone analysis\": \"The tone of the movies varies, with Get Shorty being comedic, Mr Holland's Opus being inspirational, Stargate being adventurous, and Dances with Wolves being epic.\",\n",
      "    \"Plot analysis\": \"The plots of the movies are diverse, but all involve a journey or transformation of some kind.\",\n",
      "    \"Other perspectives\": [\"Historical context\", \"Cultural significance\"]\n",
      "  },\n",
      "  \n",
      "  \"Step 3: Identify core theme, genre, or element connecting the movies\":\n",
      "  {\n",
      "    \"Core theme\": \"Transformation\",\n",
      "    \"Core genre\": \"None\",\n",
      "    \"Core element\": \"Journey\"\n",
      "  },\n",
      "  \n",
      "  \"Step 4: Evaluate options based on core theme, genre, or element\":\n",
      "  {\n",
      "    \"Option A (The Prime Gig) evaluation\": \"The Prime Gig is a comedy-drama that involves a transformation, but it lacks the epic scope of the other movies.\",\n",
      "    \"Option B (9 12 Weeks) evaluation\": \"9 1/2 Weeks is a romantic drama that involves a transformation, but it is more focused on relationships than the other movies.\",\n",
      "    \"Option C (The Usual Suspects) evaluation\": \"The Usual Suspects is a crime thriller that involves a transformation, but it is more focused on plot twists than the other movies.\",\n",
      "    \"Option D (It Happened One Night) evaluation\": \"It Happened One Night is a romantic comedy that involves a transformation, and it has a similar sense of journey and self-discovery as the other movies.\"\n",
      "  },\n",
      "  \n",
      "  \"Step 5: Consider underlying causes or factors contributing to similarities\":\n",
      "  {\n",
      "    \"Underlying causes\": [\"Influence of classic Hollywood films\"],\n",
      "    \"Factors contributing to similarities\": [\"Use of archetypal characters\", \"Exploration of universal themes\"]\n",
      "  },\n",
      "  \n",
      "  \"Step 6: Evaluate options based on underlying causes or factors\":\n",
      "  {\n",
      "    \"Option A (The Prime Gig) evaluation\": \"The Prime Gig is influenced by classic Hollywood films, but it lacks the timeless quality of the other movies.\",\n",
      "    \"Option B (9 12 Weeks) evaluation\": \"9 1/2 Weeks explores universal themes, but it is more focused on relationships than the other movies.\",\n",
      "    \"Option C (The Usual Suspects) evaluation\": \"The Usual Suspects uses archetypal characters, but it is more focused on plot twists than the other movies.\",\n",
      "    \"Option D (It Happened One Night) evaluation\": \"It Happened One Night is a classic Hollywood film that explores universal themes and uses archetypal characters, making it a strong match.\"\n",
      "  },\n",
      "  \n",
      "  \"Step 7: Consider relevant data or information (e.g., IMDB ratings, reviews, awards)\":\n",
      "  {\n",
      "    \"IMDB ratings\": [7.4, 7.5, 7.1, 8.1],\n",
      "    \"Reviews\": [\"Generally positive\", \"Mixed\", \"Positive\", \"Classic\"],\n",
      "    \"Awards\": [\"Several awards\", \"Few awards\", \"Some awards\", \"Many awards\"]\n",
      "  },\n",
      "  \n",
      "  \"Step 8: Evaluate options based on relevant data or information\":\n",
      "  {\n",
      "    \"Option A (The Prime Gig) evaluation\": \"The Prime Gig has a lower IMDB rating and fewer awards than the other movies.\",\n",
      "    \"Option B (9 12 Weeks) evaluation\": \"9 1/2 Weeks has a lower IMDB rating and fewer awards than the other movies.\",\n",
      "    \"Option C (The Usual Suspects) evaluation\": \"The Usual Suspects has a higher IMDB rating and more awards than the other movies, but it is not as highly regarded as It Happened One Night.\",\n",
      "    \"Option D (It Happened One Night) evaluation\": \"It Happened One Night has a high IMDB rating and many awards, making it a strong match.\"\n",
      "  },\n",
      "  \n",
      "  \"Step 9: Consider creative thinking and unconventional connections\":\n",
      "  {\n",
      "    \"Creative thinking ideas\": [\"Explore the use of symbolism in the movies\"],\n",
      "    \"Unconventional connections\": [\"Consider the influence of mythology on the movies\"]\n",
      "  },\n",
      "  \n",
      "  \"Step 10: Evaluate options based on creative thinking and unconventional connections\":\n",
      "  {\n",
      "    \"Option A (The Prime Gig) evaluation\": \"The Prime Gig does not have any obvious connections to mythology or symbolism.\",\n",
      "    \"Option B (9 12 Weeks) evaluation\": \"9 1/2 Weeks explores themes of desire and temptation, but it does not have any obvious connections to mythology or symbolism.\",\n",
      "    \"Option C (The Usual Suspects) evaluation\": \"The Usual Suspects uses symbolism and has connections to mythology, but it is not as richly layered as It Happened One Night.\",\n",
      "    \"Option D (It Happened One Night) evaluation\": \"It Happened One Night is a richly layered film that explores themes of identity and transformation, making it a strong match.\"\n",
      "  },\n",
      "  \n",
      "  \"Step 11: Consider expertise or knowledge required to find a similar movie\":\n",
      "  {\n",
      "    \"Expertise required\": \"Knowledge of film history and genres\",\n",
      "    \"Knowledge required\": \"Understanding of universal themes and archetypal characters\"\n",
      "  },\n",
      "  \n",
      "  \"Step 12: Evaluate options based on expertise or knowledge required\":\n",
      "  {\n",
      "    \"Option A (The Prime Gig) evaluation\": \"The Prime Gig requires some knowledge of film history and genres, but it is not as nuanced as the other movies.\",\n",
      "    \"Option B (9 12 Weeks) evaluation\": \"9 1/2 Weeks requires some understanding of universal themes and archetypal characters, but it is not as richly layered as the other movies.\",\n",
      "    \"Option C (The Usual Suspects) evaluation\": \"The Usual Suspects requires some knowledge of film history and genres, as well as understanding of universal themes and archetypal characters, but it is not as highly regarded as It Happened One Night.\",\n",
      "    \"Option D (It Happened One Night) evaluation\": \"It Happened One Night requires a deep understanding of film history and genres, as well as universal themes and archetypal characters, making it a strong match.\"\n",
      "  },\n",
      "  \n",
      "  \"Step 13: Consider the mix of genres and themes in the given movies\":\n",
      "  {\n",
      "    \"Mix of genres\": [\"Comedy\", \"Drama\", \"Science Fiction\", \"Western\"],\n",
      "    \"Mix of themes\": [\"Transformation\", \"Self-discovery\", \"Exploration\", \"Cultural clash\"]\n",
      "  },\n",
      "  \n",
      "  \"Step 14: Evaluate options based on the mix of genres and themes\":\n",
      "  {\n",
      "    \"Option A (The Prime Gig) evaluation\": \"The Prime Gig has a mix of genres and themes, but it is not as diverse as the other movies.\",\n",
      "    \"Option B (9 12 Weeks) evaluation\": \"9 1/2 Weeks has a mix of genres and themes, but it is more focused on relationships than the other movies.\",\n",
      "    \"Option C (The Usual Suspects) evaluation\": \"The Usual Suspects has a mix of genres and themes, but it is more focused on plot twists than the other movies.\",\n",
      "    \"Option D (It Happened One Night) evaluation\": \"It Happened One Night has a mix of genres and themes that is similar to the other movies, making it a strong match.\"\n",
      "  },\n",
      "  \n",
      "  \"Step 15: Consider alternative ways to think about finding a similar movie\n",
      "================================================================================\n",
      "(A)\n",
      "Here's the filled JSON for the given reasoning structure:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Step 1: Identify Key Features\":\n",
      "        \"List the key features of The Sword in the Stone, Fantasia, The Jungle Book, and Willy Wonka & the Chocolate Factory that can be used to find a similar movie (genres, themes, elements, etc.)\": \"The key features of these movies include fantasy, adventure, music, and family-friendly themes. They often feature magical or supernatural elements, memorable characters, and iconic storylines.\",\n",
      "        \"Key features to consider\": [\"Fantasy\", \"Adventure\", \"Music\", \"Family-friendly\", \"Magical or supernatural elements\", \"Memorable characters\"]\n",
      "    ,\n",
      "\n",
      "    \"Step 2: Analyze Movie Genres and Themes\":\n",
      "        \"Make a list of movie genres and themes found in The Sword in the Stone, Fantasia, The Jungle Book, and Willy Wonka & the Chocolate Factory\": \"The genres and themes found in these movies include fantasy, adventure, musical, and family. They often explore themes of friendship, growth, and self-discovery.\",\n",
      "        \"Apply the genres and themes to the options (A, B, C, D)\": [\"Option A: The Wizard of Oz (Fantasy, Adventure, Musical, Family)\", \"Option B: Captain Corelli's Mandolin (War, Drama, Romance)\", \"Option C: Timecrimes (Science Fiction, Thriller)\", \"Option D: Arlington Road (Thriller, Drama)\"]\n",
      "    ,\n",
      "\n",
      "    \"Step 3: Consider Alternative Perspectives\":\n",
      "        \"List alternative perspectives or viewpoints of film critics, audiences, or historians on The Sword in the Stone, Fantasia, The Jungle Book, and Willy Wonka & the Chocolate Factory\": \"Some critics view these movies as classics, praising their imagination and storytelling. Others see them as nostalgic, but dated. Historians may analyze their cultural significance and impact on the film industry.\",\n",
      "        \"Apply the alternative perspectives to the options (A, B, C, D)\": [\"Option A: The Wizard of Oz (Classic, Timeless, Iconic)\", \"Option B: Captain Corelli's Mandolin (Historical, Cultural, Romantic)\", \"Option C: Timecrimes (Original, Thrilling, Complex)\", \"Option D: Arlington Road (Suspenseful, Thought-provoking, Realistic)\"]\n",
      "    ,\n",
      "\n",
      "    \"Step 4: Critical Thinking\":\n",
      "        \"Analyze the options from different film-related perspectives (genre, director, era)\": \"From a genre perspective, Option A is the most similar. From a director's perspective, none of the options match the exact style of the original directors. From an era perspective, Option A is from the same era as some of the original movies.\",\n",
      "        \"Question assumptions about what makes a movie similar\": \"Is it the genre, the tone, the themes, or something else? Are we looking for an exact match or something that captures the essence of the originals?\",\n",
      "        \"Evaluate the evidence or information available about each option\": [\"Option A: The Wizard of Oz (Highly rated, widely popular, classic)\", \"Option B: Captain Corelli's Mandolin (Well-received, but not as widely known)\", \"Option C: Timecrimes (Original, but not as highly rated)\", \"Option D: Arlington Road (Well-received, but not as widely known)\"]\n",
      "    ,\n",
      "\n",
      "    \"Step 5: Creative Thinking\":\n",
      "        \"Generate innovative and out-of-the-box ideas to identify a movie that captures the essence of The Sword in the Stone, Fantasia, The Jungle Book, and Willy Wonka & the Chocolate Factory\": \"What if we combined the fantasy elements of The Sword in the Stone with the musical elements of Fantasia? Or what if we took the adventure elements of The Jungle Book and combined them with the whimsy of Willy Wonka?\",\n",
      "        \"List potential movies that come to mind\": [\"The Princess Bride\", \"The NeverEnding Story\", \"The Secret of Roan Inish\"]\n",
      "    ,\n",
      "\n",
      "    \"Step 6: Identify Core Theme or Element\":\n",
      "        \"Identify the core theme, genre, or element that ties The Sword in the Stone, Fantasia, The Jungle Book, and Willy Wonka & the Chocolate Factory together\": \"The core theme that ties these movies together is the power of imagination and the importance of exploring one's creativity.\",\n",
      "        \"Explain how this core theme or element is addressed in each option (A, B, C, D)\": [\"Option A: The Wizard of Oz (Features a young girl's journey through a fantastical land, highlighting the power of imagination)\", \"Option B: Captain Corelli's Mandolin (Does not explicitly address the power of imagination)\", \"Option C: Timecrimes (Features a complex, imaginative plot, but does not explicitly address the theme)\", \"Option D: Arlington Road (Does not explicitly address the power of imagination)\"]\n",
      "    ,\n",
      "\n",
      "    \"Step 7: Analyze Timelessness and Appeal\":\n",
      "        \"List the underlying causes or factors contributing to the timelessness and appeal of The Sword in the Stone, Fantasia, The Jungle Book, and Willy Wonka & the Chocolate Factory\": \"The timelessness and appeal of these movies can be attributed to their memorable characters, iconic storylines, and the way they tap into the viewer's imagination.\",\n",
      "        \"Explain how these factors are present in each option (A, B, C, D)\": [\"Option A: The Wizard of Oz (Features memorable characters, an iconic storyline, and taps into the viewer's imagination)\", \"Option B: Captain Corelli's Mandolin (Features memorable characters, but the storyline is not as iconic)\", \"Option C: Timecrimes (Features a complex plot, but the characters are not as memorable)\", \"Option D: Arlington Road (Features a suspenseful plot, but the characters are not as memorable)\"]\n",
      "    ,\n",
      "\n",
      "    \"Step 8: Evaluate Data and Information\":\n",
      "        \"List relevant data or information (IMDB ratings, reviews, awards) that can provide insights into the similarity between the options and The Sword in the Stone, Fantasia, The Jungle Book, and Willy Wonka & the Chocolate Factory\": \"IMDB ratings, Rotten Tomatoes scores, and awards won can provide insights into the similarity between the options and the original movies.\",\n",
      "        \"Evaluate the data and information for each option (A, B, C, D)\": [\"Option A: The Wizard of Oz (High IMDB rating, high Rotten Tomatoes score, numerous awards won)\", \"Option B: Captain Corelli's Mandolin (Lower IMDB rating, lower Rotten Tomatoes score, fewer awards won)\", \"Option C: Timecrimes (Lower IMDB rating, lower Rotten Tomatoes score, fewer awards won)\", \"Option D: Arlington Road (Lower IMDB rating, lower Rotten Tomatoes score, fewer awards won)\"]\n",
      "    ,\n",
      "\n",
      "    \"Step 9: Consider Expertise and Skill Set\":\n",
      "        \"Determine if finding a similar movie requires specific film-related expertise or skill set\": \"Finding a similar movie requires an understanding of film genres, themes, and elements, as well as the ability to analyze and evaluate data and information.\",\n",
      "        \"Explain how this expertise or skill set is relevant to each option (A, B, C, D)\": [\"Option A: The Wizard of Oz (Requires an understanding of classic films, fantasy genres, and musical elements)\", \"Option B: Captain Corelli's Mandolin (Requires an understanding of historical dramas, war films, and romantic elements)\", \"Option C: Timecrimes (Requires an understanding of science fiction, thrillers, and complex plots)\", \"Option D: Arlington Road (Requires an understanding of thrillers, dramas, and suspenseful plots)\"]\n",
      "    ,\n",
      "\n",
      "    \"Step 10: Design Challenge\":\n",
      "        \"Determine if finding a similar movie is a design challenge that requires creative solutions and innovation\": \"Finding a similar movie can be a design challenge that requires creative solutions and innovation, as it involves analyzing and evaluating various film elements and themes.\",\n",
      "        \"Explain how this design challenge is relevant to each option (A, B, C, D)\": [\"Option A: The Wizard of Oz (Requires creative thinking to understand how the classic film elements can be applied to a modern movie)\", \"Option B: Captain Corelli's Mandolin (Requires creative thinking to understand how the historical drama elements can be applied to a modern movie)\", \"Option C: Timecrimes (Requires creative thinking to understand how the science fiction elements can be applied to a modern movie)\", \"Option D: Arlington Road (Requires creative thinking to understand how the thriller elements can be applied to a modern movie)\"]\n",
      "    ,\n",
      "\n",
      "    \"Step 11: Target Audience\":\n",
      "        \"List the types of\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for n in none:\n",
    "    print(n[\"target\"])\n",
    "    print(n[\"trajectory\"])\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "462ba582-198e-4dee-b286-2a879c64e15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Find a movie similar to Minority Report, Shrek, Catch Me If You Can, Aladdin:\\nOptions:\\n(A) Monsters\\n(B) Inc\\n(C) Children of the Night\\n(D) The Incredible Shrinking Man\\n(E) Town & Country',\n",
       " 'target': 'Monsters, Inc',\n",
       " 'reasoning_formats': '\\n- If the answer is not multiple choice, [answer] should be the decided answer. (For eg: Q: not True or False. A: False)\\n- If the answer is multiple choice,\\n    - and the given choices are unlabelled options, [answer] should be the chosen option (For eg: Q: Where does the sun rise from? Options: - East, - West, - North. A: East)\\n    - and the given choices are labelled options, [answer] should be the letter corresponding to the chosen option (For eg: Q: Where does the sun rise from? Options: - A. West, - B. East, - C. North. A: B)',\n",
       " 'selected_modules': '1. How could I devise an experiment to help solve that problem?\\n2. Make a list of ideas for solving this problem, and apply them one by one to the problem to see if any progress can be made.\\n10. Critical Thinking: This style involves analyzing the problem from different perspectives, questioning assumptions, and evaluating the evidence or information available.\\n11. Try creative thinking, generate innovative and out-of-the-box ideas to solve the problem.\\n16. What is the core issue or problem that needs to be addressed?\\n17. What are the underlying causes or factors contributing to the problem?\\n20. Are there any relevant data or information that can provide insights into the problem?\\n25. Is the problem a technical or practical one that requires a specific expertise or skill set?\\n30. Is the problem a design challenge that requires creative solutions and innovation?\\n34. Given the problem specification and the current best solution, have a guess about other possible solutions.\\n35. Letâ€™s imagine the current best solution is totally wrong, what other ways are there to think about the problem specification?',\n",
       " 'adapted_modules': \"Here is the list of adapted reasoning module descriptions:\\n\\n1. How could I devise a movie comparison experiment to identify key similarities between Minority Report, Shrek, Catch Me If You Can, and Aladdin, and apply those findings to the given options?\\n\\n2. Make a list of movie genres, themes, or elements present in Minority Report, Shrek, Catch Me If You Can, and Aladdin, and apply them one by one to the options to see if any matches can be found.\\n\\n10. Analyze the given movies from different perspectives (e.g., genre, tone, director), question assumptions about what makes them similar, and evaluate the evidence or information available about each option.\\n\\n11. Generate innovative and out-of-the-box ideas about what makes a movie similar to Minority Report, Shrek, Catch Me If You Can, and Aladdin, and apply those ideas to the options.\\n\\n16. What is the core theme, genre, or element that connects Minority Report, Shrek, Catch Me If You Can, and Aladdin, and is it present in any of the options?\\n\\n17. What are the underlying factors contributing to the similarities between Minority Report, Shrek, Catch Me If You Can, and Aladdin, and do any of the options share those factors?\\n\\n20. Are there any relevant data or information (e.g., IMDB ratings, reviews, awards) that can provide insights into the similarities between the given movies and the options?\\n\\n25. Does finding a similar movie require specific expertise or knowledge about film genres, directors, or historical context?\\n\\n30. Is finding a similar movie a creative challenge that requires thinking outside the box and considering unconventional connections between the given movies and the options?\\n\\n34. Given the genres, themes, and elements present in Minority Report, Shrek, Catch Me If You Can, and Aladdin, have a guess about other possible movie similarities that might not be immediately apparent.\\n\\n35. Let's imagine that the obvious similarities between Minority Report, Shrek, Catch Me If You Can, and Aladdin are not the only connections â€“ what other ways are there to think about what makes a movie similar to these four?\",\n",
       " 'reasoning_structure': 'Here\\'s a step-by-step reasoning plan in JSON format for the task:\\n\\n```\\n{\\n  \"Step 1: Identify Key Elements in Minority Report, Shrek, Catch Me If You Can, and Aladdin\":\\n    {\\n      \"List genres\": [],\\n      \"List themes\": [],\\n      \"List notable elements (e.g. characters, plot twists)\": []\\n    },\\n  \\n  \"Step 2: Analyze Options from Different Perspectives\":\\n    {\\n      \"Analyze option (A) Monsters from genre perspective\": \"\",\\n      \"Analyze option (A) Monsters from tone perspective\": \"\",\\n      \"Analyze option (A) Monsters from director perspective\": \"\",\\n      \"Repeat analysis for options (B), (C), (D), and (E)\": []\\n    },\\n  \\n  \"Step 3: Question Assumptions and Evaluate Evidence\":\\n    {\\n      \"What are the assumptions about what makes a movie similar to Minority Report, Shrek, Catch Me If You Can, and Aladdin?\": [],\\n      \"What evidence is available to support or refute these assumptions?\": []\\n    },\\n  \\n  \"Step 4: Identify Core Theme, Genre, or Element\":\\n    {\\n      \"What is the core theme, genre, or element that connects Minority Report, Shrek, Catch Me If You Can, and Aladdin?\": \"\",\\n      \"Is this core theme, genre, or element present in any of the options?\": []\\n    },\\n  \\n  \"Step 5: Consider Underlying Factors and Unconventional Connections\":\\n    {\\n      \"What are the underlying factors contributing to the similarities between Minority Report, Shrek, Catch Me If You Can, and Aladdin?\": [],\\n      \"Are there any unconventional connections between the given movies and the options?\": []\\n    },\\n  \\n  \"Step 6: Evaluate Options Based on Data and Expertise\":\\n    {\\n      \"What relevant data or information (e.g. IMDB ratings, reviews, awards) is available for each option?\": [],\\n      \"Does finding a similar movie require specific expertise or knowledge about film genres, directors, or historical context?\": []\\n    },\\n  \\n  \"Step 7: Consider Creative and Out-of-the-Box Ideas\":\\n    {\\n      \"What innovative and out-of-the-box ideas can be applied to find a similar movie?\": [],\\n      \"Do any of the options match these creative ideas?\": []\\n    },\\n  \\n  \"Step 8: Make an Educated Guess\":\\n    {\\n      \"Based on the analysis, what is the most likely movie to be similar to Minority Report, Shrek, Catch Me If You Can, and Aladdin?\": \"\"\\n    }\\n}\\n```\\n\\nThis reasoning plan provides a step-by-step structure for solvers to follow and arrive at a conclusion. Each step builds on the previous one, allowing solvers to analyze the options from different perspectives, question assumptions, and evaluate evidence. The plan also encourages solvers to think creatively and consider unconventional connections between the given movies and the options.',\n",
       " 'reasoning': 'Here\\'s the filled JSON for the given reasoning structure:\\n\\n```\\n{\\n  \"Step 1: Identify Key Elements in Minority Report, Shrek, Catch Me If You Can, and Aladdin\":\\n    {\\n      \"List genres\": [\"Science Fiction\", \"Fantasy\", \"Comedy\", \"Action\", \"Adventure\"],\\n      \"List themes\": [\"Self-discovery\", \"Redemption\", \"Deception\", \"Friendship\", \"Good vs. Evil\"],\\n      \"List notable elements (e.g. characters, plot twists)\": [\"Unlikely heroes\", \"Mentor figures\", \"Fish-out-of-water stories\", \"High-stakes chases\", \"Magical or futuristic worlds\"]\\n    },\\n  \\n  \"Step 2: Analyze Options from Different Perspectives\":\\n    {\\n      \"Analyze option (A) Monsters from genre perspective\": \"Monsters is a Fantasy/Comedy film, which aligns with some of the genres found in the given movies.\",\\n      \"Analyze option (A) Monsters from tone perspective\": \"Monsters has a lighthearted and humorous tone, which is similar to Shrek and Aladdin.\",\\n      \"Analyze option (A) Monsters from director perspective\": \"Monsters was directed by Gareth Edwards, who is known for his work in the Fantasy and Science Fiction genres.\",\\n      \"Repeat analysis for options (B), (C), (D), and (E)\": [\\n        \"Option (B) Inc is a short film and does not have enough information to make a comparison.\",\\n        \"Option (C) Children of the Night is a Horror film and does not align with the genres of the given movies.\",\\n        \"Option (D) The Incredible Shrinking Man is a Science Fiction film, but its tone is more serious and does not match the lighthearted tone of some of the given movies.\",\\n        \"Option (E) Town & Country is a Romantic Comedy film and does not align with the genres of the given movies.\"\\n      ]\\n    },\\n  \\n  \"Step 3: Question Assumptions and Evaluate Evidence\":\\n    {\\n      \"What are the assumptions about what makes a movie similar to Minority Report, Shrek, Catch Me If You Can, and Aladdin?\": [\"Assuming a similar genre or tone is enough to make a movie similar\", \"Assuming a movie with a similar theme or notable element is enough to make it similar\"],\\n      \"What evidence is available to support or refute these assumptions?\": [\"The given movies have diverse genres and tones, but share common themes and notable elements\", \"Some options may have similar genres or tones, but lack the common themes and notable elements found in the given movies\"]\\n    },\\n  \\n  \"Step 4: Identify Core Theme, Genre, or Element\":\\n    {\\n      \"What is the core theme, genre, or element that connects Minority Report, Shrek, Catch Me If You Can, and Aladdin?\": \"The core theme that connects the given movies is the idea of self-discovery and redemption in a fantastical or extraordinary world.\",\\n      \"Is this core theme, genre, or element present in any of the options?\": [\"Option (A) Monsters has a similar theme of self-discovery and redemption in a fantastical world\"]\\n    },\\n  \\n  \"Step 5: Consider Underlying Factors and Unconventional Connections\":\\n    {\\n      \"What are the underlying factors contributing to the similarities between Minority Report, Shrek, Catch Me If You Can, and Aladdin?\": [\"The use of speculative elements to explore real-world issues\", \"The presence of unlikely heroes and mentor figures\"],\\n      \"Are there any unconventional connections between the given movies and the options?\": [\"Option (A) Monsters features a speculative element (monsters) to explore real-world issues (immigration and xenophobia)\"]\\n    },\\n  \\n  \"Step 6: Evaluate Options Based on Data and Expertise\":\\n    {\\n      \"What relevant data or information (e.g. IMDB ratings, reviews, awards) is available for each option?\": [\"Option (A) Monsters has a 7.4/10 IMDB rating and 72% Rotten Tomatoes score\", \"Option (B) Inc has limited information available\", \"Option (C) Children of the Night has a 4.8/10 IMDB rating and 22% Rotten Tomatoes score\", \"Option (D) The Incredible Shrinking Man has a 7.1/10 IMDB rating and 81% Rotten Tomatoes score\", \"Option (E) Town & Country has a 5.4/10 IMDB rating and 13% Rotten Tomatoes score\"],\\n      \"Does finding a similar movie require specific expertise or knowledge about film genres, directors, or historical context?\": [\"Yes, finding a similar movie requires knowledge of film genres, directors, and historical context to understand the themes and notable elements present in the given movies\"]\\n    },\\n  \\n  \"Step 7: Consider Creative and Out-of-the-Box Ideas\":\\n    {\\n      \"What innovative and out-of-the-box ideas can be applied to find a similar movie?\": [\"Considering movies that blend genres or use speculative elements to explore real-world issues\", \"Looking for movies with similar themes or notable elements, but in different genres or tones\"],\\n      \"Do any of the options match these creative ideas?\": [\"Option (A) Monsters matches the idea of using speculative elements to explore real-world issues\"]\\n    },\\n  \\n  \"Step 8: Make an Educated Guess\":\\n    {\\n      \"Based on the analysis, what is the most likely movie to be similar to Minority Report, Shrek, Catch Me If You Can, and Aladdin?\": \"Option (A) Monsters\"\\n    }\\n}\\n\\nThe final answer is A.',\n",
       " 'trajectory': 'Here\\'s the filled JSON for the given reasoning structure:\\n\\n```\\n{\\n  \"Step 1: Identify Key Elements in Minority Report, Shrek, Catch Me If You Can, and Aladdin\":\\n    {\\n      \"List genres\": [\"Science Fiction\", \"Fantasy\", \"Comedy\", \"Action\", \"Adventure\"],\\n      \"List themes\": [\"Self-discovery\", \"Redemption\", \"Deception\", \"Friendship\", \"Good vs. Evil\"],\\n      \"List notable elements (e.g. characters, plot twists)\": [\"Unlikely heroes\", \"Mentor figures\", \"Fish-out-of-water stories\", \"High-stakes chases\", \"Magical or futuristic worlds\"]\\n    },\\n  \\n  \"Step 2: Analyze Options from Different Perspectives\":\\n    {\\n      \"Analyze option (A) Monsters from genre perspective\": \"Monsters is a Fantasy/Comedy film, which aligns with some of the genres found in the given movies.\",\\n      \"Analyze option (A) Monsters from tone perspective\": \"Monsters has a lighthearted and humorous tone, which is similar to Shrek and Aladdin.\",\\n      \"Analyze option (A) Monsters from director perspective\": \"Monsters was directed by Gareth Edwards, who is known for his work in the Fantasy and Science Fiction genres.\",\\n      \"Repeat analysis for options (B), (C), (D), and (E)\": [\\n        \"Option (B) Inc is a short film and does not have enough information to make a comparison.\",\\n        \"Option (C) Children of the Night is a Horror film and does not align with the genres of the given movies.\",\\n        \"Option (D) The Incredible Shrinking Man is a Science Fiction film, but its tone is more serious and does not match the lighthearted tone of some of the given movies.\",\\n        \"Option (E) Town & Country is a Romantic Comedy film and does not align with the genres of the given movies.\"\\n      ]\\n    },\\n  \\n  \"Step 3: Question Assumptions and Evaluate Evidence\":\\n    {\\n      \"What are the assumptions about what makes a movie similar to Minority Report, Shrek, Catch Me If You Can, and Aladdin?\": [\"Assuming a similar genre or tone is enough to make a movie similar\", \"Assuming a movie with a similar theme or notable element is enough to make it similar\"],\\n      \"What evidence is available to support or refute these assumptions?\": [\"The given movies have diverse genres and tones, but share common themes and notable elements\", \"Some options may have similar genres or tones, but lack the common themes and notable elements found in the given movies\"]\\n    },\\n  \\n  \"Step 4: Identify Core Theme, Genre, or Element\":\\n    {\\n      \"What is the core theme, genre, or element that connects Minority Report, Shrek, Catch Me If You Can, and Aladdin?\": \"The core theme that connects the given movies is the idea of self-discovery and redemption in a fantastical or extraordinary world.\",\\n      \"Is this core theme, genre, or element present in any of the options?\": [\"Option (A) Monsters has a similar theme of self-discovery and redemption in a fantastical world\"]\\n    },\\n  \\n  \"Step 5: Consider Underlying Factors and Unconventional Connections\":\\n    {\\n      \"What are the underlying factors contributing to the similarities between Minority Report, Shrek, Catch Me If You Can, and Aladdin?\": [\"The use of speculative elements to explore real-world issues\", \"The presence of unlikely heroes and mentor figures\"],\\n      \"Are there any unconventional connections between the given movies and the options?\": [\"Option (A) Monsters features a speculative element (monsters) to explore real-world issues (immigration and xenophobia)\"]\\n    },\\n  \\n  \"Step 6: Evaluate Options Based on Data and Expertise\":\\n    {\\n      \"What relevant data or information (e.g. IMDB ratings, reviews, awards) is available for each option?\": [\"Option (A) Monsters has a 7.4/10 IMDB rating and 72% Rotten Tomatoes score\", \"Option (B) Inc has limited information available\", \"Option (C) Children of the Night has a 4.8/10 IMDB rating and 22% Rotten Tomatoes score\", \"Option (D) The Incredible Shrinking Man has a 7.1/10 IMDB rating and 81% Rotten Tomatoes score\", \"Option (E) Town & Country has a 5.4/10 IMDB rating and 13% Rotten Tomatoes score\"],\\n      \"Does finding a similar movie require specific expertise or knowledge about film genres, directors, or historical context?\": [\"Yes, finding a similar movie requires knowledge of film genres, directors, and historical context to understand the themes and notable elements present in the given movies\"]\\n    },\\n  \\n  \"Step 7: Consider Creative and Out-of-the-Box Ideas\":\\n    {\\n      \"What innovative and out-of-the-box ideas can be applied to find a similar movie?\": [\"Considering movies that blend genres or use speculative elements to explore real-world issues\", \"Looking for movies with similar themes or notable elements, but in different genres or tones\"],\\n      \"Do any of the options match these creative ideas?\": [\"Option (A) Monsters matches the idea of using speculative elements to explore real-world issues\"]\\n    },\\n  \\n  \"Step 8: Make an Educated Guess\":\\n    {\\n      \"Based on the analysis, what is the most likely movie to be similar to Minority Report, Shrek, Catch Me If You Can, and Aladdin?\": \"Option (A) Monsters\"\\n    }\\n}',\n",
       " 'answer_pred': 'A'}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds.filter(lambda x: len(x[\"target\"]) != 3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "78eec496-4a53-4147-9281-aecd3dda05ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows + 1) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "12fbea30-2318-40b3-b0f6-76837f27698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-penguins_in_a_table/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1e658acb-1702-4102-811a-ddc2ad524351",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "07f200cc-0878-44bc-a89c-c6c14b2dd662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(A) 37.',\n",
       " '(A).',\n",
       " '(B).',\n",
       " '(C).',\n",
       " '(D).',\n",
       " '(E).',\n",
       " 'A because there is only 1 penguin that meets both conditions (age < 8 years old and weight > 12 kg).\"',\n",
       " 'A.',\n",
       " 'A.\"',\n",
       " 'B.',\n",
       " 'C.',\n",
       " 'D.',\n",
       " 'E.',\n",
       " None,\n",
       " 'the option that matches the calculated cumulative weight, which is option (C).\"'}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d4f1ce67-b451-4353-96fe-f6aa24b1bf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837f28b9a62445ff9a1e7a0c0c358009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "18a17215-f387-4efb-a957-6267ddb51517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'A 37',\n",
       " 'A because there is only 1 penguin that meets both conditions age < 8 years old and weight > 12 kg',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " None,\n",
       " 'the option that matches the calculated cumulative weight which is option C'}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4603d71d-27c3-4900-acf6-5a881d79dcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d7ab84b7cb48c2a97a2d7057c88a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 138\n",
       "})"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4c8ba826-7e0e-4717-93cd-3d435697f1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8121b838bd2460486f3e1c42f8f9117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "none = new_ds.filter(lambda x: x[\"answer_pred\"] == None)\n",
    "none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490895bf-da42-4920-ba16-262a96a31630",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in none:\n",
    "    print(n[\"target\"])\n",
    "    print(n[\"trajectory\"])\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2cf4b0ce-c31e-4c32-9f62-126121953a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9657534246575342"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows + 3) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a3d5b0-4ba3-4989-b506-b7597bb4a044",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# penguins_in_a_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "57f52b5b-7902-4b5b-ad11-0b5f811a9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-penguins_in_a_table/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "44adbace-ace5-4f21-80da-332aed7b9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "b4282681-d060-4001-8e70-24deba130b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(A) 37.',\n",
       " '(A).',\n",
       " '(B).',\n",
       " '(C).',\n",
       " '(D).',\n",
       " '(E).',\n",
       " 'A because there is only 1 penguin that meets both conditions (age < 8 years old and weight > 12 kg).\"',\n",
       " 'A.',\n",
       " 'A.\"',\n",
       " 'B.',\n",
       " 'C.',\n",
       " 'D.',\n",
       " 'E.',\n",
       " None,\n",
       " 'the option that matches the calculated cumulative weight, which is option (C).\"'}"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "e7fa4f24-8807-4281-bad9-72f191f989c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a31c4bfe194e338199811ab05dfa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "8e62cf66-fb1e-4c9b-876e-b75a76e0362b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'A 37',\n",
       " 'A because there is only 1 penguin that meets both conditions age < 8 years old and weight > 12 kg',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " None,\n",
       " 'the option that matches the calculated cumulative weight which is option C'}"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "f538bbb0-0797-4c0a-a458-cd439737b1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199a7b956ce2477b95f7360fd78132be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    corr_A = [\"A 37\", \"A because there is only 1 penguin\"]\n",
    "    corr_B = [\"the option that matches the calculated\"]\n",
    "\n",
    "    if ins[\"answer_pred\"]:\n",
    "        for a in corr_A:\n",
    "            if a in ins[\"answer_pred\"]:\n",
    "                return {\n",
    "                    \"answer_pred\": \"A\"\n",
    "                }\n",
    "        for c in corr_B:\n",
    "            if c in ins[\"answer_pred\"]:\n",
    "                return {\n",
    "                    \"answer_pred\": \"C\"\n",
    "                }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "c24d502c-2bb7-42df-a1e2-4332b88edfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', None}"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "ac329c9d-fc7c-4864-bdbe-b85d7a0ba721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ca578d61ac4b23b0b4552819ce20b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "ac13448a-24a5-4b7e-8dae-ed94377f0423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2ada10e2d04444b2b0a7f53bfb8793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 141\n",
       "})"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4aaca755-6213-4528-adfd-2e9df22aadf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8121b838bd2460486f3e1c42f8f9117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "none = new_ds.filter(lambda x: x[\"answer_pred\"] == None)\n",
    "none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c15f03-873a-4a6a-a839-2fd0d0f3d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in none:\n",
    "    print(n[\"target\"])\n",
    "    print(n[\"trajectory\"])\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "4c3e2f82-39d5-44d4-b2b4-9b7242e76a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9657534246575342"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9937f8fa-d824-4cb8-b481-0bd2d77a48ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# reasoning_about_colored_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "e55f9164-86ac-4fc2-b4c1-29533aed1d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-reasoning_about_colored_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "8bcb5714-3da8-45b1-9466-97ed241a1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "e54c6db2-efcb-4408-8d48-6b29c1af6526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(A) yes.',\n",
       " '(A) zero.',\n",
       " '(A).',\n",
       " '(B).',\n",
       " '(D) three.',\n",
       " '(D).',\n",
       " '(E) four.',\n",
       " '(E).',\n",
       " '(F) five.\"',\n",
       " '(H).',\n",
       " '(I).',\n",
       " '(M).',\n",
       " '(O) black.',\n",
       " '(P) grey.',\n",
       " '(P).',\n",
       " 'A.',\n",
       " 'B.',\n",
       " 'C.',\n",
       " 'D.',\n",
       " 'E.',\n",
       " 'F.',\n",
       " 'G.',\n",
       " 'H.',\n",
       " 'I.',\n",
       " 'J.',\n",
       " 'K.',\n",
       " 'L.',\n",
       " 'M.',\n",
       " 'N or A.',\n",
       " 'N.',\n",
       " 'O.',\n",
       " 'P.',\n",
       " 'Q.',\n",
       " 'R.',\n",
       " 'indeed one of the available options.\"',\n",
       " 'verified to be correct.\",'}"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "da9c53df-cffb-4621-9b14-dc4a737976e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a162e252ebe4dd48142fb72803ab678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "2156f24c-f985-442c-8e9d-a896918707c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328bde585bbc42e199657dea43eb6414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):\n",
    "    sp = instance[\"answer_pred\"].split()\n",
    "    if len(sp) == 2:\n",
    "        return {\"answer_pred\": sp[0]}\n",
    "    else:\n",
    "        return {\"answer_pred\": instance[\"answer_pred\"]}\n",
    "\n",
    "new_ds = new_ds.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "823c20c7-8e6c-45a5-ba19-d303d0de3e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'N or A',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'indeed one of the available options',\n",
       " 'verified to be correct'}"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "271c492c-f7b9-4bae-9276-d3782f1abdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c42bdcf12a642afb9bd095a1998b074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a8ff6956-b339-41b4-becc-2d7f5ee8a57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81f688aa8e54f56b6d0e012a50f9cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 230\n",
       "})"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f97d1566-5301-4cca-8efb-6a6f08bdbde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6fcc74-c395-43c6-8c09-940bff3b1131",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ruin_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "7b52871f-2a9d-4268-89da-6deb12298804",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-ruin_names/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "b72f42b2-e3d4-404d-a45b-21ab4bab322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "8246fc05-e88f-45b4-981b-b43b96439c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A.',\n",
       " 'A. This option is the most likely to be a humorous edit, as it takes the original phrase and gives it a completely different meaning, implying that the panic is now related to technology or networking.\"',\n",
       " 'A.\"',\n",
       " 'B.',\n",
       " 'C, as it is the option that best matches the key features of a humorous edit, including an unexpected twist, use of wordplay, and subversion of the original meaning.\"',\n",
       " 'C.',\n",
       " 'C.\"',\n",
       " 'D.',\n",
       " 'D.\"',\n",
       " 'I.',\n",
       " None}"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "041d6c47-64f4-4557-90c1-e4643ed58fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622c759878f146ea821c19ce0948eef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "edc7c0e4-ba59-4bcc-8b79-9dd682ecf0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'A This option is the most likely to be a humorous edit as it takes the original phrase and gives it a completely different meaning implying that the panic is now related to technology or networking',\n",
       " 'B',\n",
       " 'C',\n",
       " 'C as it is the option that best matches the key features of a humorous edit including an unexpected twist use of wordplay and subversion of the original meaning',\n",
       " 'D',\n",
       " 'I',\n",
       " None}"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "bc251a36-2b61-4b6c-9c19-89c9acf2e03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7b2b7464d04412ad90d01c8c6ae9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    corr_A = [\"A This option is the most\"]\n",
    "    corr_B = [\"C as it is the option that best\"]\n",
    "\n",
    "    if ins[\"answer_pred\"]:\n",
    "        for a in corr_A:\n",
    "            if a in ins[\"answer_pred\"]:\n",
    "                return {\n",
    "                    \"answer_pred\": \"A\"\n",
    "                }\n",
    "        for c in corr_B:\n",
    "            if c in ins[\"answer_pred\"]:\n",
    "                return {\n",
    "                    \"answer_pred\": \"C\"\n",
    "                }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "ffff71ef-77e1-43f0-be6c-1ddcc31d40fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'I', None}"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "99dd79a6-22cb-4fe2-bb18-c7a68bb35898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ebc1ef86e442738dd3f1743f9d321f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "73dc04f4-c373-4068-8ce4-0841c0134c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(D)\n",
      "Here is the filled JSON for the above reasoning structure:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Step 1: Analyze the original phrase\":\n",
      "        \"Description\": \"Break down the original phrase 'black sabbath' into its linguistic components (e.g. phonetics, semantics, syntax)\",\n",
      "        \"Analysis\": \"The original phrase 'black sabbath' is a proper noun, referring to a British heavy metal band. The words 'black' and 'sabbath' have individual meanings, with 'black' referring to the color or darkness, and 'sabbath' referring to a day of rest or a meeting of witches.\",\n",
      "        \"Questions to consider\": [\n",
      "            \"What are the individual words and their meanings?\",\n",
      "            \"How do the words interact with each other?\",\n",
      "            \"Are there any idiomatic expressions or colloquialisms?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"The individual words are 'black' and 'sabbath'.\",\n",
      "            \"The words interact with each other to form a proper noun, referring to a specific entity.\",\n",
      "            \"There are no idiomatic expressions or colloquialisms in this phrase.\"\n",
      "        ]\n",
      "    ,\n",
      "\n",
      "    \"Step 2: Identify possible edit types\":\n",
      "        \"Description\": \"List possible types of edits that could be made to the original phrase (e.g. replacing or adding letters)\",\n",
      "        \"Analysis\": \"Possible edit types include replacing or adding letters, changing the word order, or using wordplay.\",\n",
      "        \"Questions to consider\": [\n",
      "            \"What types of edits would be most likely to result in a humorous effect?\",\n",
      "            \"Are there any common linguistic patterns or tropes that could be exploited for humor?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"Edits that result in a play on words or a clever twist are most likely to be humorous.\",\n",
      "            \"Common linguistic patterns or tropes that could be exploited for humor include puns, double meanings, and unexpected twists.\"\n",
      "        ]\n",
      "    ,\n",
      "\n",
      "    \"Step 3: Apply edits to the original phrase\":\n",
      "        \"Description\": \"Systematically apply each possible edit type to the original phrase and evaluate the results\",\n",
      "        \"Analysis\": \"Applying the edit types to the original phrase results in the following options: (A) black sabvbath, (B) black sabiath, (C) black sabbtath, (D) blank sabbath.\",\n",
      "        \"Questions to consider\": [\n",
      "            \"Does the edited phrase still make sense?\",\n",
      "            \"Is the edited phrase grammatically correct?\",\n",
      "            \"Does the edited phrase have a humorous effect?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"(A) black sabvbath: No, it does not make sense. No, it is not grammatically correct. No, it does not have a humorous effect.\",\n",
      "            \"(B) black sabiath: No, it does not make sense. No, it is not grammatically correct. No, it does not have a humorous effect.\",\n",
      "            \"(C) black sabbtath: No, it does not make sense. No, it is not grammatically correct. No, it does not have a humorous effect.\",\n",
      "            \"(D) blank sabbath: Yes, it makes sense. Yes, it is grammatically correct. Yes, it has a humorous effect.\"\n",
      "        ]\n",
      "    ,\n",
      "\n",
      "    \"Step 4: Evaluate options from different linguistic perspectives\":\n",
      "        \"Description\": \"Analyze each option from different linguistic perspectives (e.g. phonetic, semantic)\",\n",
      "        \"Analysis\": \"From a phonetic perspective, option (D) blank sabbath is the most similar to the original phrase. From a semantic perspective, option (D) blank sabbath is also the most similar, as it retains the meaning of the original phrase.\",\n",
      "        \"Questions to consider\": [\n",
      "            \"How does the edited phrase sound when spoken aloud?\",\n",
      "            \"Does the edited phrase have a different meaning than the original phrase?\",\n",
      "            \"Are there any cultural or historical connotations that could affect the humor?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"Option (D) blank sabbath sounds similar to the original phrase when spoken aloud.\",\n",
      "            \"Option (D) blank sabbath has a similar meaning to the original phrase, but with a clever twist.\",\n",
      "            \"There are no cultural or historical connotations that could affect the humor in this case.\"\n",
      "        ]\n",
      "    ,\n",
      "\n",
      "    \"Step 5: Consider creative and out-of-the-box ideas\":\n",
      "        \"Description\": \"Generate innovative and out-of-the-box ideas for what makes a humorous edit\",\n",
      "        \"Analysis\": \"A humorous edit could involve a play on words, a clever twist, or an unexpected surprise. In this case, option (D) blank sabbath uses a play on words to create a humorous effect.\",\n",
      "        \"Questions to consider\": [\n",
      "            \"What if the edit is not just a simple replacement or addition of letters?\",\n",
      "            \"Could the edit involve a play on words or a clever twist?\",\n",
      "            \"Are there any other forms of wordplay that could be used?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"The edit could involve a play on words, as in option (D) blank sabbath.\",\n",
      "            \"Yes, the edit could involve a clever twist, as in option (D) blank sabbath.\",\n",
      "            \"Other forms of wordplay that could be used include puns, double meanings, and unexpected twists.\"\n",
      "        ]\n",
      "    ,\n",
      "\n",
      "    \"Step 6: Identify the core characteristic of a humorous edit\":\n",
      "        \"Description\": \"Determine the core characteristic of a humorous edit that needs to be addressed in the options\",\n",
      "        \"Analysis\": \"The core characteristic of a humorous edit is that it uses a play on words, a clever twist, or an unexpected surprise to create a humorous effect.\",\n",
      "        \"Questions to consider\": [\n",
      "            \"Is the humor based on a play on words?\",\n",
      "            \"Is the humor based on a clever twist or surprise?\",\n",
      "            \"Is the humor based on a cultural or historical reference?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"Yes, the humor in option (D) blank sabbath is based on a play on words.\",\n",
      "            \"Yes, the humor in option (D) blank sabbath is based on a clever twist.\",\n",
      "            \"No, the humor in option (D) blank sabbath is not based on a cultural or historical reference.\"\n",
      "        ]\n",
      "    ,\n",
      "\n",
      "    \"Step 7: Consider relevant linguistic patterns or data\":\n",
      "        \"Description\": \"Research relevant linguistic patterns or data that can provide insights into what makes a humorous edit\",\n",
      "        \"Analysis\": \"Relevant linguistic patterns or data include the use of wordplay, puns, and double meanings in humor. In this case, option (D) blank sabbath uses a play on words to create a humorous effect.\",\n",
      "        \"Questions to consider\": [\n",
      "            \"Are there any linguistic patterns or tropes that are commonly used in humor?\",\n",
      "            \"Are there any cultural or historical patterns that could affect the humor?\",\n",
      "            \"Are there any linguistic theories or models that could be applied?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"Yes, linguistic patterns or tropes that are commonly used in humor include wordplay, puns, and double meanings.\",\n",
      "            \"No, there are no cultural or historical patterns that could affect the humor in this case.\",\n",
      "            \"Linguistic theories or models that could be applied include theories of humor, irony, and wordplay.\"\n",
      "        ]\n",
      "    ,\n",
      "\n",
      "    \"Step 8: Evaluate the options against the core characteristic and linguistic patterns\":\n",
      "        \"Description\": \"Evaluate each option against the core characteristic of a humorous edit and the relevant linguistic patterns or data\",\n",
      "        \"Analysis\": \"Option (D) blank sabbath meets the core characteristic of a humorous edit and uses a linguistic pattern or trope that is commonly used in humor.\",\n",
      "        \"Questions to consider\": [\n",
      "            \"Does the option meet the core characteristic of a humorous edit?\",\n",
      "            \"Does the option use a linguistic pattern or trope that is commonly used in humor?\",\n",
      "            \"Does the option have a cultural or historical reference that could affect the humor?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"Yes, option (D) blank sabbath meets the core characteristic of a humorous edit.\",\n",
      "            \"Yes, option (D) blank sabbath uses a linguistic pattern or trope that is commonly used in humor.\",\n",
      "            \"No, option (D) blank sabbath does not have a cultural or historical reference that could affect the humor.\"\n",
      "        ]\n",
      "    ,\n",
      "\n",
      "    \"Step 9: Make a final evaluation\":\n",
      "        \"Description\": \"Make a final evaluation of the options based on the analysis and evaluation\",\n",
      "        \"Analysis\": \"Based on the analysis and evaluation, option (D) blank sabbath is the most humorous edit of the original phrase.\",\n",
      "        \"Questions to\n"
     ]
    }
   ],
   "source": [
    "none_ds = new_ds.filter(lambda x: x[\"answer_pred\"] == None)\n",
    "print(none_ds[0][\"target\"])\n",
    "print(none_ds[0][\"trajectory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d67626fa-1a94-460e-8ba9-d61bc414bfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'N or A',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'indeed one of the available options',\n",
       " 'verified to be correct'}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fd27c209-a594-4843-b808-2260c0c4a13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa924cd3019b4e47ba20868884580240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 216\n",
       "})"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e58f817e-b49d-494b-bdb1-0815785182af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.864"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92b0fbd-276d-4f2d-a882-eb30f1142b0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# salient_translation_error_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "06cb1a67-554a-4685-a866-c2e0c126887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-salient_translation_error_detection/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "9e7bbce3-9d87-4002-9c7c-7aecf05d4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "ee1fc40e-bb0d-4b64-ae70-2b38836f9dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(A) Modifiers or Adjectives or (E) Dropped Content. However, since the question asks for a single option and (A) is listed first among the correct options, the answer would be A.\"',\n",
       " '(D) Named Entities.\",',\n",
       " '(D).',\n",
       " 'A.',\n",
       " 'B.',\n",
       " 'C.',\n",
       " 'D.',\n",
       " 'E.',\n",
       " 'F.'}"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "4d27472c-77b5-4af4-b635-e8069aed21e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7053b003a61d4fe6bbb67d787bd8f9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "cea10474-8ecc-483f-ba70-30b3685ac95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'A Modifiers or Adjectives or E Dropped Content However since the question asks for a single option and A is listed first among the correct options the answer would be A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'D Named Entities',\n",
       " 'E',\n",
       " 'F'}"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "bf83d97e-2542-437e-9284-453ebc524f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f07765a7c84de082d2896eeb6f141b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):\n",
    "    ls = instance[\"answer_pred\"].split()\n",
    "\n",
    "    if len(ls) >= 3:\n",
    "        return {\"answer_pred\": ls[0]}\n",
    "\n",
    "    return {\"answer_pred\": instance[\"answer_pred\"]}\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "07d251db-be96-4d2d-8297-0a3b1487930c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', 'F'}"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "a2419533-e4d8-45d8-a45f-0dd5a808a1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b210e32820c4639859b31a0507c59b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "4179c10d-55de-4de7-8eea-612bafe56c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfa4cbe15ad49b999f3d4dffd0c7aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 179\n",
       "})"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "31876c6b-23ea-48cb-ad29-50663c17dfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.716"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e7b8bc-37b7-4972-847f-347f35e9f190",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# snarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "7e79285b-b88d-4f08-990c-dbf61c3164e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-snarks/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "de7ee14d-2fc2-4519-8d52-8df6bffc24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "a6c58192-0d74-46a3-86ce-2b6c48b722a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A.',\n",
       " 'B (or A, as both statements are identical and sarcastic).',\n",
       " 'B.',\n",
       " 'No.'}"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "2cbe36ea-9aab-4edd-ae6a-6da8ff8e2e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7820d23f6a7a4d0bad58a7accfd7e6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "4db53705-ddfa-4e6a-8986-8d5e9d164a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'B or A as both statements are identical and sarcastic', 'No'}"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "512b3b51-6754-418f-985a-d3b3d16532d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which statement is sarcastic?\n",
      "Options:\n",
      "(A) The NB\n",
      "No\n",
      "(A)\n"
     ]
    }
   ],
   "source": [
    "no_ds = new_ds.filter(lambda x: x[\"answer_pred\"] == \"No\")\n",
    "print(no_ds[0][\"input\"])\n",
    "print(no_ds[0][\"answer_pred\"])\n",
    "print(no_ds[0][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "51556398-9585-411d-b926-08d25946ca92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf7907084a044a282182e7ee5199486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "04356af0-adc6-4ba8-8540-21ea6915fc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb89a25d49541588b0a0834af2b82f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 153\n",
       "})"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8f62283a-2a06-4dde-b5e9-6a5a142ec35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8595505617977528"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51614624-d1a7-43db-9c5e-a19c642352f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# sports_understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "1f313ffb-c077-44da-a40f-ca27cb34e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-sports_understanding/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "28e42721-9008-4899-b361-64cc358c31bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "45a4e18d-fed5-4fa1-b1ec-1a43f18d4ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False.',\n",
       " 'False.\"',\n",
       " 'High.',\n",
       " 'Implausible.',\n",
       " 'No.',\n",
       " None,\n",
       " 'Plausible but not confirmed.',\n",
       " 'Plausible but uncertain.',\n",
       " 'Plausible, but unconfirmed without concrete evidence or records.',\n",
       " 'Plausible.',\n",
       " 'The claim is plausible but unverifiable.',\n",
       " 'True.',\n",
       " 'True.\"',\n",
       " 'Uncertain.',\n",
       " 'Unlikely.',\n",
       " 'Yes.',\n",
       " 'yes.'}"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "826c199b-a24d-44ad-98d5-bf17791dc5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a999bbfde9fa4853945979a3c56b378b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "ab35bf9f-2679-4a63-a2f7-22aed24db11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False',\n",
       " 'High',\n",
       " 'Implausible',\n",
       " 'No',\n",
       " None,\n",
       " 'Plausible',\n",
       " 'Plausible but not confirmed',\n",
       " 'Plausible but uncertain',\n",
       " 'Plausible but unconfirmed without concrete evidence or records',\n",
       " 'The claim is plausible but unverifiable',\n",
       " 'True',\n",
       " 'Uncertain',\n",
       " 'Unlikely',\n",
       " 'Yes',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "22a4f79a-d5c2-4e93-9a88-93e18d4be135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 59\n",
       "})"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "none_ds = new_ds.filter(lambda x: x[\"answer_pred\"] == None)\n",
    "none_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "2a11938d-0331-4be4-bcac-1213c80c1c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "{\n",
      "    \"Understanding the context and terminology\": {\n",
      "        \"Key assumptions about the context\": \"The sentence is referring to a sports game, likely hockey or soccer, given the mention of a defender.\",\n",
      "        \"Key assumptions about the terminology\": \"The term 'Maradona' is likely being used to describe a move or action, possibly a reference to the famous Argentine soccer player Diego Maradona.\",\n",
      "        \"Potential impact on plausibility\": \"If the context is hockey, the sentence may be less plausible, as Maradona is a soccer legend. However, if the context is soccer, the sentence becomes more plausible.\"\n",
      "    },\n",
      "    \"Interpretation by different groups\": {\n",
      "        \"Hockey fans' interpretation\": \"Hockey fans may interpret the sentence as Travis Konecny performing a skillful move, but may be unfamiliar with the reference to Maradona.\",\n",
      "        \"Soccer fans' interpretation\": \"Soccer fans will likely recognize the reference to Maradona and interpret the sentence as Travis Konecny performing a clever or skillful move, reminiscent of Maradona's style.\",\n",
      "        \"Other possible interpretations\": \"Those unfamiliar with sports or the reference to Maradona may interpret the sentence as nonsensical or confusing.\"\n",
      "    },\n",
      "    \"Core issue affecting plausibility\": {\n",
      "        \"Description of the core issue\": \"The core issue is whether Travis Konecny, a hockey player, would be described as performing a 'Maradona' move, which is more commonly associated with soccer.\",\n",
      "        \"Why it affects plausibility\": \"This issue affects plausibility because it raises questions about the context and whether the term 'Maradona' is being used accurately or metaphorically.\"\n",
      "    },\n",
      "    \"Underlying factors contributing to plausibility\": {\n",
      "        \"Travis Konecny's sport\": \"Travis Konecny is a professional ice hockey player, which makes the sentence less plausible in a literal sense.\",\n",
      "        \"The term 'Maradona'\": \"The term 'Maradona' is closely associated with soccer and the legendary player Diego Maradona, which adds to the implausibility of the sentence in a hockey context.\",\n",
      "        \"Other underlying factors\": \"The sentence's plausibility also depends on the intended meaning and audience. If meant as a metaphor or analogy, the sentence might be more plausible.\"\n",
      "    },\n",
      "    \"Knowledge required for evaluation\": {\n",
      "        \"Specific knowledge of sports required\": \"Knowledge of hockey and soccer, as well as familiarity with Travis Konecny and Diego Maradona, is necessary to evaluate the sentence's plausibility.\",\n",
      "        \"General linguistic or conceptual issue\": \"Understanding the use of metaphors and analogies in language is also important in evaluating the sentence's plausibility.\"\n",
      "    },\n",
      "    \"Criteria for determining validity\": {\n",
      "        \"Clear criteria for validity\": \"A clear understanding of the context, the sports involved, and the intended meaning of the sentence is necessary to determine its validity.\",\n",
      "        \"Creative interpretation required\": \"Some creative interpretation may be required to understand the intended meaning behind the sentence, especially if it is meant as a metaphor or analogy.\"\n",
      "    },\n",
      "    \"Alternative explanations or interpretations\": {\n",
      "        \"Alternative explanations for the sentence\": \"One alternative explanation is that the sentence is using 'Maradona' as a metaphor for a skillful or clever move, rather than a literal reference to the soccer player.\",\n",
      "        \"Alternative interpretations of 'Maradona'\": \"Another interpretation is that 'Maradona' is being used to describe a specific type of move or action, rather than a reference to the player himself.\",\n",
      "        \"Alternative interpretations of Travis Konecny's actions\": \"Travis Konecny's actions could be interpreted as a clever or skillful move, regardless of whether it is directly comparable to Maradona's style.\"\n",
      "    },\n",
      "    \"Re-evaluating the initial interpretation\": {\n",
      "        \"Initial interpretation\": \"The initial interpretation was that the sentence is implausible because Travis Konecny is a hockey player and Maradona is a soccer legend.\",\n",
      "        \"Alternative ways of thinking about 'Maradona'\": \"Considering 'Maradona' as a metaphor or analogy for a skillful move, rather than a literal reference, offers an alternative way of thinking about the sentence.\",\n",
      "        \"Alternative ways of thinking about Travis Konecny's actions\": \"Focusing on the skill or cleverness of Travis Konecny's actions, rather than the specific sport or context, provides another way to re-evaluate the sentence.\"\n",
      "    },\n",
      "    \"Is the sentence plausible?\": \"The sentence is plausible if interpreted metaphorically or as an analogy, but less plausible if taken literally.\"\n",
      "}\n",
      "\n",
      "The final answer is: The sentence is plausible if interpreted metaphorically or as an analogy, but less plausible if taken literally.\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(none_ds[0][\"trajectory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "0298976d-ec6f-4c4b-93d1-64a0f8c9167c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9709e05b71a24aa896f763462a674e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "def map_fn(instance):\n",
    "    if instance[\"answer_pred\"] == None:\n",
    "        text = \"The final answer is:\"\n",
    "        pattern = fr\"(?<={text}).*\"\n",
    "    \n",
    "        response = instance[\"trajectory\"]\n",
    "    \n",
    "        try:\n",
    "            answer, trajectory = re.search(pattern, response).group(0).strip(), re.sub(pattern, \"\", response).replace(text, \"\").strip()\n",
    "        except:\n",
    "            answer, trajectory = None, response\n",
    "    \n",
    "        return {\n",
    "            \"trajectory\": trajectory,\n",
    "            \"answer_pred\": answer\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"trajectory\": instance[\"trajectory\"],\n",
    "        \"answer_pred\": instance[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "76e459d0-914c-4a26-8145-2ada6c4147b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa17ab5b2e0341a4b29e950c0f32377b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds.filter(lambda x: x[\"answer_pred\"] == None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "9e104726-530e-4dd3-9515-b317ba5147bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4520fee69c243bab095261f37dbd730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "5cd997da-3f95-4a81-b1e9-196cb3dfd783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False',\n",
       " 'High',\n",
       " 'Implausible',\n",
       " 'Impossible to determine',\n",
       " 'No',\n",
       " 'No the sentence Emmanuel Sanders got a base hit is not plausible',\n",
       " 'Plausible',\n",
       " 'Plausible but not confirmed',\n",
       " 'Plausible but not necessarily probable',\n",
       " 'Plausible but potentially exaggerated or metaphorical',\n",
       " 'Plausible but uncertain',\n",
       " 'Plausible but unconfirmed without concrete evidence or records',\n",
       " 'Somewhat plausible',\n",
       " \"The claim is likely implausible as a literal baseball play but without context it's difficult to say for certain\",\n",
       " 'The claim is plausible but unverifiable',\n",
       " 'The claim is plausible but unverified',\n",
       " \"The claim is uncertain and lacks specific evidence to support it but it is not entirely implausible given Curry's skills and abilities\",\n",
       " \"The sentence 'Jesus Luzardo was called for slashing' is plausible but there is limited information available to confirm its accuracy\",\n",
       " 'The sentence is partially plausible',\n",
       " 'The sentence is plausible',\n",
       " 'The sentence is plausible but lacks concrete evidence to confirm its accuracy',\n",
       " 'The sentence is plausible if interpreted metaphorically or as an analogy but less plausible if taken literally',\n",
       " \"The sentence is plausible in the context of ice hockey but it's unclear without more context\",\n",
       " 'The sentence is somewhat plausible',\n",
       " 'The sentence is somewhat plausible but unlikely',\n",
       " \"The statement is implausible in the context of Fernando Tatis Jr's profession as a baseball player but it becomes more plausible when considering alternative perspectives and sports contexts\",\n",
       " 'True',\n",
       " 'Uncertain',\n",
       " 'Uncertain due to lack of information',\n",
       " 'Unlikely',\n",
       " \"Without further evidence or context it's difficult to determine the plausibility of the claim\",\n",
       " 'Yes',\n",
       " 'Yes the sentence is plausible',\n",
       " 'uncertain',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "fc785acd-26cf-403a-84de-5e5e738c1228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db2581a57d748d5a32cb36860fb8f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plausible_yes = [\n",
    "    'Plausible',\n",
    "    'The sentence is plausible',\n",
    "    'Yes',\n",
    "    'Yes the sentence is plausible',\n",
    "    'True',\n",
    "    'yes'\n",
    "]\n",
    "implausible_no = [\n",
    "    'False',\n",
    "    'Implausible',\n",
    "    'No',\n",
    "    'No the sentence Emmanuel Sanders got a base hit is not plausible',\n",
    "    'Unlikely',\n",
    "    \"The statement is implausible in the context of Fernando Tatis Jr's profession as a baseball player but it becomes more plausible when considering alternative perspectives and sports contexts\"\n",
    "]\n",
    "indeterminate = [\n",
    "    'High',\n",
    "    'Impossible to determine',\n",
    "    'Plausible but not confirmed',\n",
    "    'Plausible but not necessarily probable',\n",
    "    'Plausible but potentially exaggerated or metaphorical',\n",
    "    'Plausible but uncertain',\n",
    "    'Plausible but unconfirmed without concrete evidence or records',\n",
    "    'Somewhat plausible',\n",
    "    \"The claim is likely implausible as a literal baseball play but without context it's difficult to say for certain\",\n",
    "    'The claim is plausible but unverifiable',\n",
    "    'The claim is plausible but unverified',\n",
    "    \"The claim is uncertain and lacks specific evidence to support it but it is not entirely implausible given Curry's skills and abilities\",\n",
    "    \"The sentence 'Jesus Luzardo was called for slashing' is plausible but there is limited information available to confirm its accuracy\",\n",
    "    'The sentence is partially plausible',\n",
    "    'The sentence is plausible but lacks concrete evidence to confirm its accuracy',\n",
    "    'The sentence is plausible if interpreted metaphorically or as an analogy but less plausible if taken literally',\n",
    "    \"The sentence is plausible in the context of ice hockey but it's unclear without more context\",\n",
    "    'The sentence is somewhat plausible',\n",
    "    'The sentence is somewhat plausible but unlikely',\n",
    "    'Uncertain',\n",
    "    'Uncertain due to lack of information',\n",
    "    \"Without further evidence or context it's difficult to determine the plausibility of the claim\",\n",
    "    'uncertain'\n",
    "]\n",
    "\n",
    "def map_fn(ins):\n",
    "    for yes in plausible_yes:\n",
    "        if yes == ins[\"answer_pred\"]:\n",
    "            return {\n",
    "                \"answer_pred\": \"yes\"\n",
    "            }\n",
    "\n",
    "    for no in implausible_no:\n",
    "        if no == ins[\"answer_pred\"]:\n",
    "            return {\n",
    "                \"answer_pred\": \"no\"\n",
    "            }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "94d51ac3-635f-4b67-9fca-62e04de6fe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'High',\n",
       " 'Impossible to determine',\n",
       " 'Plausible but not confirmed',\n",
       " 'Plausible but not necessarily probable',\n",
       " 'Plausible but potentially exaggerated or metaphorical',\n",
       " 'Plausible but uncertain',\n",
       " 'Plausible but unconfirmed without concrete evidence or records',\n",
       " 'Somewhat plausible',\n",
       " \"The claim is likely implausible as a literal baseball play but without context it's difficult to say for certain\",\n",
       " 'The claim is plausible but unverifiable',\n",
       " 'The claim is plausible but unverified',\n",
       " \"The claim is uncertain and lacks specific evidence to support it but it is not entirely implausible given Curry's skills and abilities\",\n",
       " \"The sentence 'Jesus Luzardo was called for slashing' is plausible but there is limited information available to confirm its accuracy\",\n",
       " 'The sentence is partially plausible',\n",
       " 'The sentence is plausible but lacks concrete evidence to confirm its accuracy',\n",
       " 'The sentence is plausible if interpreted metaphorically or as an analogy but less plausible if taken literally',\n",
       " \"The sentence is plausible in the context of ice hockey but it's unclear without more context\",\n",
       " 'The sentence is somewhat plausible',\n",
       " 'The sentence is somewhat plausible but unlikely',\n",
       " 'Uncertain',\n",
       " 'Uncertain due to lack of information',\n",
       " \"Without further evidence or context it's difficult to determine the plausibility of the claim\",\n",
       " 'no',\n",
       " 'uncertain',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "f50e1036-98fc-4269-ae31-b2090efa09c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53239fa30654a17ac59cea148fc87fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "66e680b2-b837-4173-ab20-c81d9d3f529e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108e14b37229454b85844b1345a66051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.732"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53b711-b627-43a7-91be-c9f975253230",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# temporal_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "4ff26847-c272-43bb-abed-981f71ecaa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-temporal_sequences/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "0736540f-c3cd-48d4-9368-3e986bb7c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "6f42588e-4736-4f9a-a6f3-7e1b1ee610a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(B).\"',\n",
       " '(D) 4pm to 5pm.',\n",
       " 'A or C, but since the format requires a single answer, we will choose one of the correct options.',\n",
       " 'A.',\n",
       " 'B.',\n",
       " 'Both (A) and (D).',\n",
       " 'C.',\n",
       " 'C.\"',\n",
       " 'D.'}"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "6f0e3bf1-6d3d-49a7-9ac9-b4e434a1ff95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc39fdf0e9d4732b04ea878c20ff029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "1935aa89-287e-4bd3-a7ed-a49ff4309be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'A or C but since the format requires a single answer we will choose one of the correct options',\n",
       " 'B',\n",
       " 'Both A and D',\n",
       " 'C',\n",
       " 'D',\n",
       " 'D 4pm to 5pm'}"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "e8b3a01c-9742-4e8f-84a5-acc7931bf3cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a437245b7b64fe7aa6aa93302664f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    if \"D 4pm to 5pm\" == ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"D\"\n",
    "        }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "b72f10e3-094c-4931-8860-44f88540812c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A',\n",
       " 'A or C but since the format requires a single answer we will choose one of the correct options',\n",
       " 'B',\n",
       " 'Both A and D',\n",
       " 'C',\n",
       " 'D'}"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "1a32c840-605b-411c-bf24-97dbe633004f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1760efdbad1840359dac274d73a3d0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "09500846-591e-400d-8e00-7a413f80b304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b69a438b5e42c591bdb2e866ed324a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 248\n",
       "})"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "ca942e52-b27c-46f6-96d6-607b757e8dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46999e93-5777-438d-82fc-23e1320a4ee5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# tracking_shuffled_objects_five_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "1f430e83-d257-42b1-80d6-86c00ff391f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-tracking_shuffled_objects_five_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "6e48f967-b3c6-4578-be6c-3c5f5978e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "3eaa6a24-46e7-4ea6-99e5-141257dff314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A.', 'A.\"', 'B.', 'C.', 'D.', 'E.'}"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "ee35345c-acaa-4b80-9a62-4f2d9e8e13bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574e1a0634e54304804ff910290111a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "cd9525e8-a803-4563-b7e2-257a7abd5b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E'}"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "0816914b-7391-4088-a844-c1cc8ce4ecf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a54c51bca964ef3a64d009446885075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "597c8af1-8fe8-47a9-8f2b-178a6f02d47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f268bdc3a9405a98798ee4939dc31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 248\n",
       "})"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "62a7fb50-a884-4c74-bd0b-3f55f1c488c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d96cc-2a17-42f2-be48-0c078e1ad4c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# tracking_shuffled_objects_seven_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "85ad5a89-1fea-43b1-aa46-6fb31c71bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-tracking_shuffled_objects_seven_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "c76badad-20e0-4edf-87c1-a8cc07f8dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "ba44c1a5-469b-46e4-a0e6-982650f725e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A.', 'B.', 'C.', 'D.', 'E.', 'F.', 'G) Izzi.', 'G.'}"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "f8d40d34-457a-4e9b-8090-ececac236f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfbb0e349c647aaa4f9b65f4647256d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "da59656d-c659-4b13-ac37-b46d014e5a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', 'F', 'G', 'G Izzi'}"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "8f3ccab0-aea1-4b1f-89e6-0d96898547c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c4d73553d44eb9926deab10e93b795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    if \"G Izzi\" == ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"G\"\n",
    "        }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "f1886c27-259f-4911-9dc1-01d652b88c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D', 'E', 'F', 'G'}"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "cfd5fbcd-138a-4b09-85b4-c63a2840fdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4245e46d7074c8e92d6c64c2a7e4f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "b2a5700e-3b85-403b-9072-57dc4cb9656b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00429139c33a4bdeaef643f33e7513f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 249\n",
       "})"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "b3ba3130-f32f-4165-a20d-6d596553a8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7380f-757f-4efe-a499-d5fcb8db1605",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# tracking_shuffled_objects_three_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "5e8b3d70-00c0-40bf-8930-2ff52cebbb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-tracking_shuffled_objects_three_objects/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "b7c037d5-2c4e-4c06-9d5d-e53014c787cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "2848ce35-ae10-413d-968e-e2b25260aeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A\"', 'A.', 'A.\"', 'B.', 'B.\"', 'C.', 'C.\"'}"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "4a9a977f-d0e1-4f15-ab88-45ceafeb4259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbedf5d2597404082cac7920d1f611e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "95073ba7-5b3d-471b-9bff-1df8c7e4ad8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C'}"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "adf5debc-b7bf-4e17-b4f5-66dc51998f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e6f8b0e93c42d689316ceb07672557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "56a0469d-5887-4f65-a900-49e2caab7508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85f89861d784517b9426640672ae657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].translate(str.maketrans(\"\", \"\", '()\"')) == x[\"answer_pred\"])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "f87ec911-3ac3-4e8a-93e3-30933431fc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows) / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080e9689-0a35-46be-944d-2f768b223465",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# web_of_lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "d0515e07-2539-4edc-a510-4802dd4f6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-web_of_lies/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "b4496e01-3aeb-4b9f-af54-883988fac6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "b423b1e8-babb-4821-a45e-da57918d936e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F.', 'False.', 'No.', None, 'T.', 'True.', 'True.\"', 'Yes.', 'true.', 'yes.'}"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "85d38cc7-4bbe-4324-9c2e-026c370bbf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa719b29baae49ff8ea272949de898ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.,()\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "3959a89e-3e55-4fcb-ae91-32540a492c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def map_fn(instance):\n",
    "    if instance[\"answer_pred\"] == None:\n",
    "        text = \"The final answer is:\"\n",
    "        pattern = fr\"(?<={text}).*\"\n",
    "    \n",
    "        response = instance[\"trajectory\"]\n",
    "    \n",
    "        try:\n",
    "            answer, trajectory = re.search(pattern, response).group(0).strip(), re.sub(pattern, \"\", response).replace(text, \"\").strip()\n",
    "        except:\n",
    "            answer, trajectory = None, response\n",
    "    \n",
    "        return {\n",
    "            \"trajectory\": trajectory,\n",
    "            \"answer_pred\": answer\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"trajectory\": instance[\"trajectory\"],\n",
    "        \"answer_pred\": instance[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "f02fcdc1-e8bf-4a9b-b908-0ed4addc27f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F', 'False', 'No', None, 'T', 'True', 'Yes', 'true', 'yes'}"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "302d6103-f81e-4933-996b-9393ee8ea7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No', 'Yes'}"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "1c1679ba-9686-4b4a-b877-658fb04d5bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb9bd0f536942299d087f7e1b10ecb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yes_ls = [\"True\", \"Yes\", \"true\", \"yes\", \"T\"]\n",
    "no_ls = [\"False\", \"No\", \"F\"]\n",
    "\n",
    "def map_fn(ins):\n",
    "    for yes in yes_ls:\n",
    "        if yes == ins[\"answer_pred\"]:\n",
    "            return {\n",
    "                \"answer_pred\": \"Yes\"\n",
    "            }\n",
    "\n",
    "    for no in no_ls:\n",
    "        if no == ins[\"answer_pred\"]:\n",
    "            return {\n",
    "                \"answer_pred\": \"No\"\n",
    "            }\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "0838f7fe-03a6-4702-ac01-649eecc40984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No', None, 'Yes'}"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "19300114-21e5-45e7-8d6f-07f68455c3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830c4fc851ad4e738d8eec8e8131ab0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "5e141fe7-20bb-4997-ac1d-beb2f13c2b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9728aed8e6814d26b79cbbc5e12a56a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.876"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "21cb3638-52d2-4297-afb1-7577340cd605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cc0a3eaed54816ba14e56d615850eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/142 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4d52a993fe495d968d41a000dec929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7a0fe617f24a148c657308758d15d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes_corr_ds = yes_ds.filter(lambda x: x[\"target\"] == \"Yes\")\n",
    "no_corr_ds = no_ds.filter(lambda x: x[\"target\"] == \"No\")\n",
    "none_ds = new_ds.filter(lambda x: x[\"answer_pred\"] == None)\n",
    "none_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "30131486-068c-412b-9e1e-885499a51352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Elanor lies. Millicent says Elanor tells the truth. Millie says Millicent lies. Michaela says Millie tells the truth. Kandi says Michaela lies. Does Kandi tell the truth?\n",
      "No\n",
      "```\n",
      "{\n",
      "    \"Step 1: Analyze Elanor's statement\": {\n",
      "        \"Assumption\": \"Elanor lies\",\n",
      "        \"Implication\": \"Elanor's statement is false, so the opposite of what Elanor says is true.\"\n",
      "    },\n",
      "    \"Step 2: Analyze Millicent's statement\": {\n",
      "        \"Statement\": \"Millicent says Elanor tells the truth\",\n",
      "        \"Assumption\": \"Millicent lies\",\n",
      "        \"Implication\": \"If Millicent says Elanor tells the truth, but Elanor actually lies, then Millicent's statement is false.\"\n",
      "    },\n",
      "    \"Step 3: Analyze Millie's statement\": {\n",
      "        \"Statement\": \"Millie says Millicent lies\",\n",
      "        \"Assumption\": \"Millie tells the truth\",\n",
      "        \"Implication\": \"If Millie says Millicent lies, and Millicent's statement is actually false, then Millie's statement is true.\"\n",
      "    },\n",
      "    \"Step 4: Analyze Michaela's statement\": {\n",
      "        \"Statement\": \"Michaela says Millie tells the truth\",\n",
      "        \"Assumption\": \"Michaela tells the truth\",\n",
      "        \"Implication\": \"If Michaela says Millie tells the truth, and Millie's statement is actually true, then Michaela's statement is true.\"\n",
      "    },\n",
      "    \"Step 5: Analyze Kandi's statement\": {\n",
      "        \"Statement\": \"Kandi says Michaela lies\",\n",
      "        \"Assumption\": \"Kandi lies\",\n",
      "        \"Implication\": \"If Kandi says Michaela lies, but Michaela's statement is actually true, then Kandi's statement is false.\"\n",
      "    },\n",
      "    \"Step 6: Create a truth table or diagram\": {\n",
      "        \"Columns\": [\"Elanor\", \"Millicent\", \"Millie\", \"Michaela\", \"Kandi\"],\n",
      "        \"Rows\": [\"T/T/T/T/T\", \"T/T/T/T/F\", \"T/T/T/F/T\", \"T/T/T/F/F\", \n",
      "                 \"T/T/F/T/T\", \"T/T/F/T/F\", \"T/T/F/F/T\", \"T/T/F/F/F\",\n",
      "                 \"T/F/T/T/T\", \"T/F/T/T/F\", \"T/F/T/F/T\", \"T/F/T/F/F\",\n",
      "                 \"T/F/F/T/T\", \"T/F/F/T/F\", \"T/F/F/F/T\", \"T/F/F/F/F\",\n",
      "                 \"F/T/T/T/T\", \"F/T/T/T/F\", \"F/T/T/F/T\", \"F/T/T/F/F\",\n",
      "                 \"F/T/F/T/T\", \"F/T/F/T/F\", \"F/T/F/F/T\", \"F/T/F/F/F\",\n",
      "                 \"F/F/T/T/T\", \"F/F/T/T/F\", \"F/F/T/F/T\", \"F/F/T/F/F\",\n",
      "                 \"F/F/F/T/T\", \"F/F/F/T/F\", \"F/F/F/F/T\", \"F/F/F/F/F\"],\n",
      "        \"Values\": [\"F/F/T/T/F\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",\n"
     ]
    }
   ],
   "source": [
    "print(none_ds[0][\"input\"])\n",
    "print(none_ds[0][\"target\"])\n",
    "print(none_ds[0][\"trajectory\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda62f9-f223-4c31-8dca-9bc3c9869fa1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# word_sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "f19600b8-10d1-4ab4-b337-960bc092c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-word_sorting/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "0602cf7b-e30b-4d1c-9cb2-f4cedcfc2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "0b50e8b9-5058-4c4c-bf95-645d22909893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.[]\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "55b444b7-ae2e-47e6-b164-d3c31e320a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 124\n",
       "})"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = new_ds.filter(lambda x: x[\"answer_pred\"]==None)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "7d565ed8-8cb6-49b8-bee1-2ae1d9d79911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def map_fn(instance):\n",
    "    if instance[\"answer_pred\"] == None:\n",
    "        text = \"The final answer is:\"\n",
    "        pattern = fr\"(?<={text}).*\"\n",
    "    \n",
    "        response = instance[\"trajectory\"]\n",
    "    \n",
    "        try:\n",
    "            answer, trajectory = re.search(pattern, response).group(0).strip(), re.sub(pattern, \"\", response).replace(text, \"\").strip()\n",
    "        except:\n",
    "            answer, trajectory = None, response\n",
    "    \n",
    "        return {\n",
    "            \"trajectory\": trajectory,\n",
    "            \"answer_pred\": answer\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"trajectory\": instance[\"trajectory\"],\n",
    "        \"answer_pred\": instance[\"answer_pred\"]\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "330a5810-9ad7-4865-bd22-a9595d534045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = new_ds.filter(lambda x: x[\"answer_pred\"]==None)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "bf928ad1-1eb3-44fa-a9d6-eaac72c9bbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agile blackguard butt clapeyron cognoscenti flamboyant geophysical lift lightfooted manumitted mathieu meager purposive reconnaissance sawbelly scribe seaworthy wiseacre woodcut yves'"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds[\"target\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "82644eb0-41d0-4388-a0af-2b2202048d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.[]\"'))\n",
    "    }\n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d590011-51ce-4725-9ca4-c46c0b933f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "b18750af-4aa4-44a9-953c-9c338cfb0665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['skimpy', 'zoroaster']"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'[skimpy, zoroaster]'.strip(\"[]\").split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "070392e1-4ca6-4794-854e-43b9fad65ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1d5e1bdf4c4009a8b6e01551ae2de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "9322fe15-97e4-4874-b2b3-3276bec9bcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfca5e873a74bf3be6ce9c0a10f3d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"].lower() == x[\"answer_pred\"].lower())\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "f3bb4297-87c7-4eff-b2f8-204b78377a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8341691a1f9b40d5bc0e3675c30c16f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'target', 'reasoning_formats', 'selected_modules', 'adapted_modules', 'reasoning_structure', 'reasoning', 'trajectory', 'answer_pred'],\n",
       "    num_rows: 245\n",
       "})"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wro = new_ds.filter(lambda x: x[\"target\"].lower() != x[\"answer_pred\"].lower())\n",
    "wro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "2878a31d-9270-4990-9a90-aad6cac20f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abbas average bridesmaid catsup charm coddle dogfish hypothalamus inconvertible inequity integral invocable memorandum multiplet phloem region scherzo shutout therewith trumpery\n",
      "abbas average bridesmaid catsup charm coddle dogfish hypothalamus inequity inconvertible integral invocable memorandum multiplet phloem region scherzo shutout therewith trumpery\n"
     ]
    }
   ],
   "source": [
    "index = 11\n",
    "print(wro[index][\"target\"])\n",
    "print(wro[index][\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "8b6f67e3-c288-45f8-8644-3f9781a1cab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr.num_rows) / dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3ed3a-991a-4e55-9c18-b5e0464c799c",
   "metadata": {},
   "source": [
    "# multistep_arithmetic_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "deef90b6-1ce8-461b-a5d2-81740edfbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-multistep_arithmetic_two/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "20d3cfd8-597d-4960-af11-1bc0b15e5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "7ceabbfa-0cdd-4e5a-b7ae-249d87d9ba6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e35ecc1a9d423c9fe87308b4fe6ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.[]\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "9cf7bdff-568d-44ba-bd0e-624cd9bd05e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-1',\n",
       " '-10',\n",
       " '-1008',\n",
       " '-11',\n",
       " '-110',\n",
       " '-113',\n",
       " '-114',\n",
       " '-11520',\n",
       " '-13',\n",
       " '-1343',\n",
       " '-144',\n",
       " '-147',\n",
       " '-15',\n",
       " '-151',\n",
       " '-160',\n",
       " '-168',\n",
       " '-169',\n",
       " '-17',\n",
       " '-170',\n",
       " '-17238',\n",
       " '-18',\n",
       " '-19',\n",
       " '-192',\n",
       " '-196',\n",
       " '-1960',\n",
       " '-1968',\n",
       " '-2',\n",
       " '-20',\n",
       " '-21',\n",
       " '-2146',\n",
       " '-217',\n",
       " '-22',\n",
       " '-23',\n",
       " '-24',\n",
       " '-240',\n",
       " '-25',\n",
       " '-26',\n",
       " '-262',\n",
       " '-264',\n",
       " '-2646',\n",
       " '-284',\n",
       " '-3',\n",
       " '-30',\n",
       " '-32',\n",
       " '-320',\n",
       " '-33',\n",
       " '-330',\n",
       " '-340',\n",
       " '-3400',\n",
       " '-343',\n",
       " '-35',\n",
       " '-36',\n",
       " '-37',\n",
       " '-38',\n",
       " '-3850',\n",
       " '-39',\n",
       " '-391',\n",
       " '-39960',\n",
       " '-4',\n",
       " '-43',\n",
       " '-46',\n",
       " '-48',\n",
       " '-5',\n",
       " '-50',\n",
       " '-51',\n",
       " '-52',\n",
       " '-5463',\n",
       " '-55',\n",
       " '-554',\n",
       " '-57',\n",
       " '-59',\n",
       " '-6',\n",
       " '-60',\n",
       " '-61',\n",
       " '-658',\n",
       " '-7',\n",
       " '-73',\n",
       " '-76',\n",
       " '-8',\n",
       " '-80',\n",
       " '-81',\n",
       " '-83',\n",
       " '-8304',\n",
       " '-84',\n",
       " '-8840',\n",
       " '-89',\n",
       " '-9',\n",
       " '-90',\n",
       " '-97',\n",
       " '-99',\n",
       " '0',\n",
       " '10',\n",
       " '101',\n",
       " '107',\n",
       " '11',\n",
       " '1168',\n",
       " '12',\n",
       " '120',\n",
       " '123',\n",
       " '14',\n",
       " '140',\n",
       " '15',\n",
       " '150',\n",
       " '16',\n",
       " '1608',\n",
       " '17',\n",
       " '176',\n",
       " '18',\n",
       " '181',\n",
       " '1980',\n",
       " '2',\n",
       " '20',\n",
       " '211',\n",
       " '216',\n",
       " '220',\n",
       " '2240',\n",
       " '237',\n",
       " '24',\n",
       " '25',\n",
       " '251472',\n",
       " '26',\n",
       " '2652',\n",
       " '27',\n",
       " '3',\n",
       " '30',\n",
       " '31',\n",
       " '312',\n",
       " '32',\n",
       " '3255',\n",
       " '33',\n",
       " '330',\n",
       " '34',\n",
       " '3420',\n",
       " '343',\n",
       " '346',\n",
       " '35',\n",
       " '36',\n",
       " '360',\n",
       " '365',\n",
       " '3692',\n",
       " '37',\n",
       " '38',\n",
       " '38556',\n",
       " '4',\n",
       " '40',\n",
       " '41',\n",
       " '416',\n",
       " '42',\n",
       " '44',\n",
       " '443',\n",
       " '45',\n",
       " '464',\n",
       " '474',\n",
       " '48',\n",
       " '49',\n",
       " '5',\n",
       " '52',\n",
       " '522',\n",
       " '54',\n",
       " '55',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '63',\n",
       " '630',\n",
       " '65',\n",
       " '68',\n",
       " '702',\n",
       " '7056',\n",
       " '72',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '8',\n",
       " '83',\n",
       " '84',\n",
       " '867',\n",
       " '88',\n",
       " '89',\n",
       " '94',\n",
       " '976',\n",
       " None,\n",
       " 'accurate',\n",
       " 'reasonable and accurate, as the calculations were performed correctly',\n",
       " 'reasonable and correct based on the given expression'}"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "9b8a661b-d943-45b3-baae-085928896d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491f48bc9a3f4123a4673bb90c1e0288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurate\n",
      "Here's the filled JSON for the above reasoning structure:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Step 1: Identify the core mathematical operations\":\n",
      "        \"The main operations are addition, subtraction, and multiplication inside the parentheses, followed by subtraction of the results of the two parentheses.\",\n",
      "\n",
      "    \"Step 2: Break down the expression into smaller parts\":\n",
      "        \"The expression can be broken down into two parts inside the parentheses: (1 + 2 * -1 - -8) and (-8 - 2 - -1 + 6).\",\n",
      "\n",
      "    \"Step 3: Evaluate expressions inside parentheses\":\n",
      "        {\n",
      "            \"Parenthesis 1\": \"1 + 2 * -1 - -8\",\n",
      "            \"Parenthesis 2\": \"-8 - 2 - -1 + 6\"\n",
      "        },\n",
      "\n",
      "    \"Step 4: Simplify expressions inside parentheses\":\n",
      "        {\n",
      "            \"Parenthesis 1\": \"Apply order of operations (PEMDAS): 1 + 2 * -1 - -8 = 1 + (-2) + 8\",\n",
      "            \"Parenthesis 2\": \"Apply order of operations (PEMDAS): -8 - 2 - -1 + 6 = -8 - 2 + 1 + 6\"\n",
      "        },\n",
      "\n",
      "    \"Step 5: Combine like terms inside parentheses\":\n",
      "        {\n",
      "            \"Parenthesis 1\": \"Combine constants and like terms: 1 + (-2) + 8 = 7\",\n",
      "            \"Parenthesis 2\": \"Combine constants and like terms: -8 - 2 + 1 + 6 = -3\"\n",
      "        },\n",
      "\n",
      "    \"Step 6: Evaluate the expressions inside parentheses\":\n",
      "        {\n",
      "            \"Parenthesis 1\": \"The final value is 7\",\n",
      "            \"Parenthesis 2\": \"The final value is -3\"\n",
      "        },\n",
      "\n",
      "    \"Step 7: Subtract the results of the two parentheses\":\n",
      "        \"Subtract the result of Parenthesis 2 from the result of Parenthesis 1: 7 - (-3) = 7 + 3 = 10\",\n",
      "\n",
      "    \"Step 8: Final evaluation\":\n",
      "        \"The final expression is evaluated, and the result is 10\",\n",
      "\n",
      "    \"Step 9: Critical thinking check\":\n",
      "        \"The calculations have been double-checked, and the order of operations was followed correctly. \n",
      "}\n",
      "```\n",
      "================================================================================\n",
      "reasonable and correct based on the given expression\n",
      "Here's the filled JSON for the given reasoning structure:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Step 1: Identify the core mathematical operation or concept\":\n",
      "        \"The main mathematical concept in the given expression is order of operations (PEMDAS/BODMAS) involving addition, subtraction, and multiplication.\",\n",
      "\n",
      "    \"Step 2: Determine the type of problem\":\n",
      "        \"The problem is a basic arithmetic one that requires simple calculation skills and following the order of operations.\",\n",
      "\n",
      "    \"Step 3: Break down the expression into smaller parts\":\n",
      "        \"The expression can be broken down into smaller parts by solving the innermost parentheses first, which are (7 + 7 * 3 - 3) and (-3 + 4 - -6 + -3).\",\n",
      "\n",
      "    \"Step 4: Identify the order of operations\":\n",
      "        \"The correct order of operations to follow is PEMDAS/BODMAS: Parentheses, Exponents, Multiplication and Division (from left to right), and Addition and Subtraction (from left to right).\",\n",
      "\n",
      "    \"Step 5: Simplify the expression\":\n",
      "        \"The expression can be simplified by following the order of operations and combining like terms. First, evaluate the expressions inside the parentheses.\",\n",
      "\n",
      "    \"Step 6: Evaluate the innermost parentheses\":\n",
      "        \"For the first set of parentheses: 7 * 3 = 21, then 7 + 21 = 28, and finally 28 - 3 = 25. For the second set of parentheses: -3 + 4 = 1, then 1 - -6 = 7, and finally 7 + -3 = 4.\",\n",
      "\n",
      "    \"Step 7: Evaluate the next level of parentheses\":\n",
      "        \"Now that the innermost parentheses have been evaluated, the expression becomes (25) - (4).\",\n",
      "\n",
      "    \"Step 8: Combine the results\":\n",
      "        \"The results of the previous steps combine to form the final expression: 25 - 4.\",\n",
      "\n",
      "    \"Step 9: Perform any final calculations\":\n",
      "        \"The final calculation is 25 - 4 = 21.\",\n",
      "\n",
      "    \"Step 10: Verify the solution\":\n",
      "        \"\n",
      "}\n",
      "```\n",
      "================================================================================\n",
      "reasonable and accurate, as the calculations were performed correctly\n",
      "Here's the filled JSON for the given reasoning structure:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Step 1: Identify the core mathematical operations\":\n",
      "        \"The primary operations involved in the expression are addition, subtraction, and multiplication.\",\n",
      "\n",
      "    \"Step 2: Break down the expression into smaller parts\":\n",
      "        \"The expression can be broken down into smaller parts by solving the innermost parentheses first, which are (-5 + 1 - 2 - -3) and (-9 * 3 + 9 + -1).\",\n",
      "\n",
      "    \"Step 3: Simplify the expression inside the innermost parentheses\":\n",
      "        \"Evaluating the expression inside the innermost parentheses, we get: -5 + 1 - 2 - -3 = -5 + 1 - 2 + 3 = -3.\",\n",
      "\n",
      "    \"Step 4: Simplify the expression inside the second set of parentheses\":\n",
      "        \"Evaluating the expression inside the second set of parentheses, we get: -9 * 3 + 9 + -1 = -27 + 9 - 1 = -19.\",\n",
      "\n",
      "    \"Step 5: Combine like terms and follow the order of operations\":\n",
      "        \"The results from steps 3 and 4 will be multiplied together, following the correct order of operations.\",\n",
      "\n",
      "    \"Step 6: Multiply the results from steps 3 and 4\":\n",
      "        \"Multiplying the simplified expressions from steps 3 and 4, we get: -3 * -19 = 57.\",\n",
      "\n",
      "    \"Step 7: Final calculation\":\n",
      "        \"The final result of the expression is 57.\",\n",
      "\n",
      "    \"Step 8: Verify the calculation\":\n",
      "        \"\n",
      "}\n",
      "```\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    corr_ls = [\"accurate\", \"reasonable and accurate, as the calculations were performed correctly\", \"reasonable and correct based on the given expression\"]\n",
    "\n",
    "    for x in corr_ls:\n",
    "        if x == ins[\"answer_pred\"]:\n",
    "            print(ins[\"answer_pred\"])\n",
    "            print(ins[\"trajectory\"])\n",
    "            print(\"=\"*80)\n",
    "    if ins[\"answer_pred\"] == corr_ls[0]:\n",
    "        return {\n",
    "            \"answer_pred\": \"10\"\n",
    "        }\n",
    "\n",
    "    if ins[\"answer_pred\"] == corr_ls[2]:\n",
    "        return {\n",
    "            \"answer_pred\": \"21\"\n",
    "        }\n",
    "\n",
    "    if ins[\"answer_pred\"] == corr_ls[1]:\n",
    "        return {\n",
    "            \"answer_pred\": \"57\"\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "    \n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "3587f8fe-81a8-4e86-9857-adc3929fdef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "8dabf29d-64e7-4188-bf07-3060a4537615",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_name = \"sachithgunasekara/self-discover-original-bbh-eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "9fbd67b3-0132-45fa-b501-1bce5c4eeef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9003cca84404ea1a133f9a8ca084948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177f875c2c26489b8ac3ff278ed64597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef64b4f0b314565b043a077ee972d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7e0e9ba9204ce6bc02c7fb552c5414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/15.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/sachithgunasekara/self-discover-original-bbh-eval/commit/22d78ce471624cea56e4f2866f837d9c08adf9c2', commit_message='Upload dataset', commit_description='', oid='22d78ce471624cea56e4f2866f837d9c08adf9c2', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))\n",
    "\n",
    "new_ds.push_to_hub(hub_name, cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057c8d98-d8ae-4ff8-93a4-6ad53b9858c0",
   "metadata": {},
   "source": [
    "# navigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "8ad4d223-4247-4f4d-aff5-6a71f59780db",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-navigate/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "0649d73e-b374-4453-9379-d39d3ddb10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "652ee422-f4c9-4109-96bf-97eceeca2a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No.', 'Yes.'}"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "09feb30c-8509-4ee1-ada8-44061390cad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bfde631a444134b69f68e00d04cd88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.[]\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "61b95f31-bc19-420d-9d93-7ef5d4010f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No', 'Yes'}"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "2940870d-4362-4e95-96dd-0432a09cf389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f4a4d1d9434f5d996cc3521f54879f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.972"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "112f62af-31f1-4de3-853d-fc4d6ed6c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_name = \"sachithgunasekara/self-discover-original-bbh-eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "5f4281aa-c8c8-4c59-9146-35962e16c2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe605e570e34e55ae40b539e66cffc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b50778fe83c4b45a159c918d75ad441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3c4f011cce4f17ac76ebf1b975a892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfa9ee867894e2eb40565cc74dd9a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/16.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/sachithgunasekara/self-discover-original-bbh-eval/commit/a863fabda7b72c58c74921dfe556d0750f9fc558', commit_message='Upload dataset', commit_description='', oid='a863fabda7b72c58c74921dfe556d0750f9fc558', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))\n",
    "\n",
    "new_ds.push_to_hub(hub_name, cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d8d9c7-392c-4a4d-a705-427e8f54fb6d",
   "metadata": {},
   "source": [
    "# object_counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "9dd967f3-8ff3-4b2d-8c78-2251a39c4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_dir = here(\"struct_vs_unstruct/data/original/non_self_synthesis/bbh/bbh-object_counting/bbh_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "9d7f380b-92b1-4622-b33e-a2ef3db1b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(chk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "e2d71572-f273-4cc6-943e-151f84b4dd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10.',\n",
       " '11.',\n",
       " '11.\"',\n",
       " '12.',\n",
       " '12.\"',\n",
       " '13.',\n",
       " '14.',\n",
       " '14.\"',\n",
       " '15.',\n",
       " '16.',\n",
       " '16.\"',\n",
       " '17.',\n",
       " '18.\"',\n",
       " '19.',\n",
       " '2.',\n",
       " '2.\"',\n",
       " '3.',\n",
       " '3.\"',\n",
       " '4.',\n",
       " '4.\"',\n",
       " '5.',\n",
       " '5.\"',\n",
       " '6.',\n",
       " '6.\"',\n",
       " '7.',\n",
       " '7.\"',\n",
       " '8.',\n",
       " '8.\"',\n",
       " '9.',\n",
       " '9.\"',\n",
       " 'based on the accurate count of the number of animals in the given list, using the defined definition of \\'animal\\' and categorization.\"',\n",
       " 'determined based on the step-by-step analysis.\"'}"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "43bf39a0-78ed-4f86-ab37-19c50fc2ebee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50c96432d50417da9ac36762eca0be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_fn(instance):    \n",
    "    return {\n",
    "        \"answer_pred\": instance[\"answer_pred\"].translate(str.maketrans(\"\", \"\", '.[]\"')) if instance[\"answer_pred\"] else None\n",
    "    }\n",
    "\n",
    "new_ds = dataset.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "b39491e3-d9d9-4bb8-a2c9-c6c4f6c177b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " \"based on the accurate count of the number of animals in the given list, using the defined definition of 'animal' and categorization\",\n",
       " 'determined based on the step-by-step analysis'}"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_ds[\"answer_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "a68c8197-0bc8-4ce7-acb9-ada4c7a38342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb30d51fde8246a8960ee3a7eb44528f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "based on the accurate count of the number of animals in the given list, using the defined definition of 'animal' and categorization\n",
      "```\n",
      "{\n",
      "    \"Step 1: Define the definition of 'animal' to be used for counting\":\n",
      "        {\n",
      "            \"Definition\": \"A living organism that feeds on organic matter, typically having specialized sense organs and nervous system and able to respond rapidly to stimuli.\",\n",
      "            \"Justification\": \"This definition encompasses a wide range of living creatures, including mammals, birds, fish, and invertebrates, which will be used to identify and count the animals in the given list.\"\n",
      "        },\n",
      "    \"Step 2: Identify the objects in the list that are living creatures\":\n",
      "        {\n",
      "            \"Living creatures\": [\"snail\", \"duck\", \"cat\", \"fish\", \"chicken\", \"cow\", \"mice\", \"rabbit\"],\n",
      "            \"Non-living objects\": [\"chair\", \"toaster\", \"ovens\"]\n",
      "        },\n",
      "    \"Step 3: Exclude non-living objects from the list\":\n",
      "        {\n",
      "            \"Updated list\": [\"snail\", \"duck\", \"cat\", \"fish\", \"chicken\", \"cow\", \"mice\", \"rabbit\"]\n",
      "        },\n",
      "    \"Step 4: Categorize the living creatures into groups (e.g., mammals, birds, aquatic animals)\":\n",
      "        {\n",
      "            \"Categories\": {\n",
      "                \"Mammals\": [\"cat\", \"cow\", \"mice\", \"rabbit\"],\n",
      "                \"Birds\": [\"duck\", \"chicken\"],\n",
      "                \"Aquatic animals\": [\"fish\"],\n",
      "                \"Invertebrates\": [\"snail\"]\n",
      "            },\n",
      "            \"Categorization justification\": \"The categorization is based on the biological classification of the living creatures, with mammals, birds, aquatic animals, and invertebrates being distinct groups.\"\n",
      "        },\n",
      "    \"Step 5: Count the number of animals in each category\":\n",
      "        {\n",
      "            \"Category counts\": {\n",
      "                \"Mammals\": 5,\n",
      "                \"Birds\": 2,\n",
      "                \"Aquatic animals\": 1,\n",
      "                \"Invertebrates\": 1\n",
      "            }\n",
      "        },\n",
      "    \"Step 6: Calculate the total number of animals\":\n",
      "        {\n",
      "            \"Total count\": \"9\",\n",
      "            \"Calculation justification\": \"The total count is the sum of the number of animals in each category: 5 (mammals) + 2 (birds) + 1 (aquatic animals) + 1 (invertebrates) = 9.\"\n",
      "        },\n",
      "    \"Step 7: Consider any complexities or edge cases in the definition of 'animal'\":\n",
      "        {\n",
      "            \"Complexities\": [\"The definition of 'animal' may not include certain organisms, such as bacteria or protozoa.\"],\n",
      "            \"Resolution\": \"However, in the context of this task, the definition of 'animal' is sufficient to identify and count the living creatures in the given list.\"\n",
      "        },\n",
      "    \"Step 8: Verify the accuracy of the count\":\n",
      "        {\n",
      "            \"Verification method\": \"Re-counting the number of animals in each category and verifying that the total count matches the sum of the category counts.\",\n",
      "            \"Verification result\": \"The total count of 9 is verified to be accurate.\"\n",
      "        },\n",
      "    \"Step 9: Provide the final answer\":\n",
      "        {\n",
      "            \"Final answer\": \"9\",\n",
      "            \"Justification\": \"\n",
      "        }\n",
      "}\n",
      "```\n",
      "================================================================================\n",
      "determined based on the step-by-step analysis\n",
      "```\n",
      "{\n",
      "    \"Step 1: Categorization System\":\n",
      "        \"Description\": \"Devising a categorization system to help count the total number of vegetables\",\n",
      "        \"Questions to Answer\": [\n",
      "            \"What constitutes a single vegetable unit in the given list?\",\n",
      "            \"Are there any subcategories within the list (e.g., root vegetables, leafy greens)?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"A single vegetable unit is defined by its botanical classification or culinary use.\",\n",
      "            \"Yes, there are subcategories: root vegetables (potato, carrots, onion, garlic) and cruciferous vegetables (cauliflower, broccoli).\"\n",
      "        ],\n",
      "        \"Notes\": \"The categorization system will help in identifying and counting individual vegetables.\"\n",
      "    ,\n",
      "\n",
      "    \"Step 2: Simplify the List\":\n",
      "        \"Description\": \"Removing any irrelevant details from the list of vegetables\",\n",
      "        \"Questions to Answer\": [\n",
      "            \"Are there any non-vegetable items in the list that need to be excluded?\",\n",
      "            \"Are there any duplicate or redundant entries in the list?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"No, there are no non-vegetable items in the list.\",\n",
      "            \"No, there are no duplicate or redundant entries in the list.\"\n",
      "        ],\n",
      "        \"Notes\": \"The list only contains vegetables, and each entry is unique.\"\n",
      "    ,\n",
      "\n",
      "    \"Step 3: Break Down the List\":\n",
      "        \"Description\": \"Breaking down the list into individual types of vegetables\",\n",
      "        \"Questions to Answer\": [\n",
      "            \"What are the distinct types of vegetables in the list?\",\n",
      "            \"Are there any vegetables that can be grouped together (e.g., multiple carrots)?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"The distinct types of vegetables are: potato, carrots, cauliflower, onion, garlic, and broccoli.\",\n",
      "            \"Yes, there are multiple carrots (2), garlics (3), and heads of broccoli (2).\"\n",
      "        ],\n",
      "        \"Notes\": \"Each type of vegetable is identified, and multiples are noted.\"\n",
      "    ,\n",
      "\n",
      "    \"Step 4: Define a Single Vegetable Unit\":\n",
      "        \"Description\": \"Defining what constitutes a single vegetable unit in the given list\",\n",
      "        \"Questions to Answer\": [\n",
      "            \"Is a single vegetable unit defined by its botanical classification or culinary use?\",\n",
      "            \"Are there any special cases or exceptions in the list (e.g., a head of broccoli vs. a single broccoli floret)?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"A single vegetable unit is defined by its botanical classification or culinary use.\",\n",
      "            \"Yes, a head of broccoli is considered a single unit, and a single garlic bulb is considered a single unit.\"\n",
      "        ],\n",
      "        \"Notes\": \"The definition of a single vegetable unit is clarified, considering both botanical and culinary perspectives.\"\n",
      "    ,\n",
      "\n",
      "    \"Step 5: Count Each Type of Vegetable\":\n",
      "        \"Description\": \"Counting each type of vegetable and tallying the total number\",\n",
      "        \"Questions to Answer\": [\n",
      "            \"How many of each type of vegetable are present in the list?\",\n",
      "            \"Are there any vegetables that need to be counted in a special way (e.g., a bunch of garlic vs. individual cloves)?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"There is 1 potato, 2 carrots, 1 cauliflower, 1 onion, 3 garlics, and 2 heads of broccoli.\",\n",
      "            \"No, each vegetable can be counted as is, without special considerations.\"\n",
      "        ],\n",
      "        \"Notes\": \"Each type of vegetable is counted, and the total number is tallied.\"\n",
      "    ,\n",
      "\n",
      "    \"Step 6: Calculate the Total Number of Vegetables\":\n",
      "        \"Description\": \"Calculating the total number of vegetables\",\n",
      "        \"Questions to Answer\": [\n",
      "            \"What is the total number of vegetables in the list?\",\n",
      "            \"Are there any errors or discrepancies in the count that need to be addressed?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"The total number of vegetables is 1 + 2 + 1 + 1 + 3 + 2 = 10.\",\n",
      "            \"No, the count appears to be accurate.\"\n",
      "        ],\n",
      "        \"Notes\": \"The total number of vegetables is calculated, and the count is verified.\"\n",
      "    ,\n",
      "\n",
      "    \"Conclusion\":\n",
      "        \"Description\": \"Arriving at the final answer\",\n",
      "        \"Questions to Answer\": [\n",
      "            \"What is the final count of vegetables in the list?\"\n",
      "        ],\n",
      "        \"Answers\": [\n",
      "            \"The final count of vegetables is 10.\"\n",
      "        ],\n",
      "        \"Notes\": \"\n",
      "}\n",
      "```\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def map_fn(ins):\n",
    "    corr_ls = [\"based on the accurate count of the number\", \"determined based on the step-by-step\"]\n",
    "\n",
    "    for x in corr_ls:\n",
    "        if x in ins[\"answer_pred\"]:\n",
    "            print(ins[\"answer_pred\"])\n",
    "            print(ins[\"trajectory\"])\n",
    "            print(\"=\"*80)\n",
    "    if corr_ls[0] in ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"9\"\n",
    "        }\n",
    "\n",
    "    if corr_ls[1] in ins[\"answer_pred\"]:\n",
    "        return {\n",
    "            \"answer_pred\": \"10\"\n",
    "        }\n",
    "        \n",
    "    return {\n",
    "        \"answer_pred\": ins[\"answer_pred\"]\n",
    "    }\n",
    "    \n",
    "\n",
    "new_ds = new_ds.map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "c8a77d25-07fc-440b-b200-ab3d66f89c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a74a9ef4164cd9aff47d277002874b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.884"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = new_ds.filter(lambda x: x[\"target\"] == x[\"answer_pred\"])\n",
    "corr.num_rows / new_ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "2f296a92-10c8-4137-9489-473cab7a118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_name = \"sachithgunasekara/self-discover-original-bbh-eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "40888b67-21c7-4547-9d40-05b9f3fbc312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80830d734f574a55860074146c5078d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c67e6090fc409aac79c9941d20bbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1a4a0fd981429c8f62e86772645b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8404483b99a40a2803642bdbc3cf256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/16.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/sachithgunasekara/self-discover-original-bbh-eval/commit/7ab1ac8f4be95cddd9c19c028b45494ca802c675', commit_message='Upload dataset', commit_description='', oid='7ab1ac8f4be95cddd9c19c028b45494ca802c675', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_string, end_string = \"non_self_synthesis/bbh/\", \"/bbh_eval\"\n",
    "cat = str(chk_dir)[str(chk_dir).find(start_string) + len(start_string) + 4:str(chk_dir).find(end_string)]\n",
    "new_ds.save_to_disk(os.path.join(par_dir, cat))\n",
    "\n",
    "new_ds.push_to_hub(hub_name, cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90eb71a-537f-4e67-ba84-d8ed746cd606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
